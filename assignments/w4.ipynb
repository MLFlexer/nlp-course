{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXtHLHN3tVs2",
        "outputId": "a4a5aed0-4c2c-4ecb-8650-77301948cfa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.17.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "# this is week 4 test\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preamble\n",
        "import sys\n",
        "sys.path.append('..')"
      ],
      "metadata": {
        "id": "N12ZL_vQtkwL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "dataset = load_dataset(\"copenlu/answerable_tydiqa\")\n",
        "\n",
        "train_set = dataset[\"train\"]\n",
        "validation_set = dataset[\"validation\"]\n",
        "\n",
        "df_train = train_set.to_pandas()\n",
        "df_val = validation_set.to_pandas()\n",
        "\n",
        "print(len(df_train))\n",
        "print(len(df_val))\n",
        "\n",
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "1f7OFSVfty8u",
        "outputId": "07d8591f-7274-468c-a6a6-208c9300bcbf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116067\n",
            "13325\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            question_text document_title  language  \\\n",
              "0            Milloin Charles Fort syntyi?   Charles Fort   finnish   \n",
              "1             “ダン” ダニエル・ジャドソン・キャラハンの出身はどこ   ダニエル・J・キャラハン  japanese   \n",
              "2  వేప చెట్టు యొక్క శాస్త్రీయ నామం ఏమిటి?            వేప    telugu   \n",
              "3      চেঙ্গিস খান কোন বংশের রাজা ছিলেন ?    চেঙ্গিজ খান   bengali   \n",
              "4        రెయ్యలగడ్ద గ్రామ విస్తీర్ణత ఎంత?     రెయ్యలగడ్ద    telugu   \n",
              "\n",
              "                                         annotations  \\\n",
              "0  {'answer_start': [18], 'answer_text': ['6. elo...   \n",
              "1  {'answer_start': [35], 'answer_text': ['カリフォルニ...   \n",
              "2  {'answer_start': [12], 'answer_text': ['Azadir...   \n",
              "3  {'answer_start': [414], 'answer_text': ['বোরজি...   \n",
              "4  {'answer_start': [259], 'answer_text': ['27 హె...   \n",
              "\n",
              "                                  document_plaintext  \\\n",
              "0  Charles Hoy Fort (6. elokuuta (joidenkin lähte...   \n",
              "1  “ダン”こと、ダニエル・ジャドソン・キャラハンは1890年7月26日、カリフォルニア州サンフ...   \n",
              "2  వేప (లాటిన్ Azadirachta indica, syn. Melia aza...   \n",
              "3  চেঙ্গিজ খান (মঙ্গোলীয়: Чингис Хаан  আ-ধ্ব-ব: ...   \n",
              "4  రెయ్యలగడ్ద, విశాఖపట్నం జిల్లా, గంగరాజు మాడుగుల...   \n",
              "\n",
              "                                        document_url  \n",
              "0       https://fi.wikipedia.org/wiki/Charles%20Fort  \n",
              "1  https://ja.wikipedia.org/wiki/%E3%83%80%E3%83%...  \n",
              "2  https://te.wikipedia.org/wiki/%E0%B0%B5%E0%B1%...  \n",
              "3  https://bn.wikipedia.org/wiki/%E0%A6%9A%E0%A7%...  \n",
              "4  https://te.wikipedia.org/wiki/%E0%B0%B0%E0%B1%...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba12352c-d317-47f1-80d6-36b200d89df6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question_text</th>\n",
              "      <th>document_title</th>\n",
              "      <th>language</th>\n",
              "      <th>annotations</th>\n",
              "      <th>document_plaintext</th>\n",
              "      <th>document_url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Milloin Charles Fort syntyi?</td>\n",
              "      <td>Charles Fort</td>\n",
              "      <td>finnish</td>\n",
              "      <td>{'answer_start': [18], 'answer_text': ['6. elo...</td>\n",
              "      <td>Charles Hoy Fort (6. elokuuta (joidenkin lähte...</td>\n",
              "      <td>https://fi.wikipedia.org/wiki/Charles%20Fort</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>“ダン” ダニエル・ジャドソン・キャラハンの出身はどこ</td>\n",
              "      <td>ダニエル・J・キャラハン</td>\n",
              "      <td>japanese</td>\n",
              "      <td>{'answer_start': [35], 'answer_text': ['カリフォルニ...</td>\n",
              "      <td>“ダン”こと、ダニエル・ジャドソン・キャラハンは1890年7月26日、カリフォルニア州サンフ...</td>\n",
              "      <td>https://ja.wikipedia.org/wiki/%E3%83%80%E3%83%...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>వేప చెట్టు యొక్క శాస్త్రీయ నామం ఏమిటి?</td>\n",
              "      <td>వేప</td>\n",
              "      <td>telugu</td>\n",
              "      <td>{'answer_start': [12], 'answer_text': ['Azadir...</td>\n",
              "      <td>వేప (లాటిన్ Azadirachta indica, syn. Melia aza...</td>\n",
              "      <td>https://te.wikipedia.org/wiki/%E0%B0%B5%E0%B1%...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>চেঙ্গিস খান কোন বংশের রাজা ছিলেন ?</td>\n",
              "      <td>চেঙ্গিজ খান</td>\n",
              "      <td>bengali</td>\n",
              "      <td>{'answer_start': [414], 'answer_text': ['বোরজি...</td>\n",
              "      <td>চেঙ্গিজ খান (মঙ্গোলীয়: Чингис Хаан  আ-ধ্ব-ব: ...</td>\n",
              "      <td>https://bn.wikipedia.org/wiki/%E0%A6%9A%E0%A7%...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>రెయ్యలగడ్ద గ్రామ విస్తీర్ణత ఎంత?</td>\n",
              "      <td>రెయ్యలగడ్ద</td>\n",
              "      <td>telugu</td>\n",
              "      <td>{'answer_start': [259], 'answer_text': ['27 హె...</td>\n",
              "      <td>రెయ్యలగడ్ద, విశాఖపట్నం జిల్లా, గంగరాజు మాడుగుల...</td>\n",
              "      <td>https://te.wikipedia.org/wiki/%E0%B0%B0%E0%B1%...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba12352c-d317-47f1-80d6-36b200d89df6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ba12352c-d317-47f1-80d6-36b200d89df6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ba12352c-d317-47f1-80d6-36b200d89df6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-322aeac7-cc27-402b-af9a-003aea9ee438\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-322aeac7-cc27-402b-af9a-003aea9ee438')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-322aeac7-cc27-402b-af9a-003aea9ee438 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get train and validation data for each language\n",
        "df_train_bengali = df_train[df_train['language'] == 'bengali']\n",
        "df_train_arabic = df_train[df_train['language'] == 'arabic']\n",
        "df_train_indonesian = df_train[df_train['language'] == 'indonesian']\n",
        "\n",
        "df_val_bengali = df_val[df_val['language'] == 'bengali']\n",
        "df_val_arabic = df_val[df_val['language'] == 'arabic']\n",
        "df_val_indonesian = df_val[df_val['language'] == 'indonesian']\n",
        "\n",
        "\n",
        "# For testing\n",
        "df_train_english = df_train[df_train['language'] == 'english']\n",
        "df_val_english = df_val[df_val['language'] == 'english']"
      ],
      "metadata": {
        "id": "O5CJ2hXEt2m9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text_with_answer(row):\n",
        "  start = row[\"annotations\"][\"answer_start\"][0]\n",
        "\n",
        "  if start == -1:\n",
        "    return pd.Series([row[\"document_plaintext\"], \"\", \"\"])\n",
        "  end = row[\"annotations\"][\"answer_start\"][0] + len(row[\"annotations\"][\"answer_text\"][0])\n",
        "  before = row[\"document_plaintext\"][:start]\n",
        "  after = row[\"document_plaintext\"][end:]\n",
        "  return pd.Series([before, row[\"annotations\"][\"answer_text\"][0], after])"
      ],
      "metadata": {
        "id": "D0sbXplquHQs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_english[[\"before\", \"answer\", \"after\"]] = df_train_english.apply(split_text_with_answer, axis=1)\n",
        "#df_train_english.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SBSr6vouqOB",
        "outputId": "fc171b88-6327-4a66-b624-b89334c985ec"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-e020da73293f>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_train_english[[\"before\", \"answer\", \"after\"]] = df_train_english.apply(split_text_with_answer, axis=1)\n",
            "<ipython-input-6-e020da73293f>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_train_english[[\"before\", \"answer\", \"after\"]] = df_train_english.apply(split_text_with_answer, axis=1)\n",
            "<ipython-input-6-e020da73293f>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_train_english[[\"before\", \"answer\", \"after\"]] = df_train_english.apply(split_text_with_answer, axis=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "2A-xo9SKyjvJ",
        "outputId": "d1747e2e-2ea3-4a65-847a-a8fe0b391cdc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.34.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import AutoTokenizer\n",
        "# mbert_tokeniser = AutoTokenizer.from_pretrained(\"bert-base-multilingual-uncased\")"
      ],
      "metadata": {
        "id": "QGghbYczyqKl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"from transformers import BertTokenizer, TFBertModel\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased')\n",
        "model = TFBertModel.from_pretrained(\"bert-base-multilingual-uncased\")\n",
        "text = \"Replace me by any text you'd like.\"\n",
        "encoded_input = tokenizer(text, return_tensors='tf')\n",
        "output = model(encoded_input)\n",
        "print(output)\"\"\""
      ],
      "metadata": {
        "id": "Ygm7JadrD3i1",
        "outputId": "f01f6eea-a105-48fa-8a79-e46edc2fdfdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'from transformers import BertTokenizer, TFBertModel\\ntokenizer = BertTokenizer.from_pretrained(\\'bert-base-multilingual-uncased\\')\\nmodel = TFBertModel.from_pretrained(\"bert-base-multilingual-uncased\")\\ntext = \"Replace me by any text you\\'d like.\"\\nencoded_input = tokenizer(text, return_tensors=\\'tf\\')\\noutput = model(encoded_input)\\nprint(output)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"def tokenize_before_after(row, tokenizer):\n",
        "  before_tokens = tokenizer.tokenize(row[\"before\"])\n",
        "  answer_tokens = tokenizer.tokenize(row[\"answer\"])\n",
        "  after_tokens = tokenizer.tokenize(row[\"after\"])\n",
        "  return pd.Series([before_tokens, answer_tokens, after_tokens])\"\"\""
      ],
      "metadata": {
        "id": "2ZzVfe_evQ4M",
        "outputId": "19000698-602d-4ba3-c914-a0eca7421163",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'def tokenize_before_after(row, tokenizer):\\n  before_tokens = tokenizer.tokenize(row[\"before\"])\\n  answer_tokens = tokenizer.tokenize(row[\"answer\"])\\n  after_tokens = tokenizer.tokenize(row[\"after\"])\\n  return pd.Series([before_tokens, answer_tokens, after_tokens])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_tokenizer(row):\n",
        "  before_tokens = row[\"before\"].split()\n",
        "  answer_tokens = row[\"answer\"].split()\n",
        "  after_tokens = row[\"after\"].split()\n",
        "  return pd.Series([before_tokens, answer_tokens, after_tokens])"
      ],
      "metadata": {
        "id": "9tJakjM8-TcT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bpemb\n",
        "from bpemb import BPEmb\n",
        "\n",
        "# Load English model with 25k word-pieces\n",
        "bpemb_id = BPEmb(lang='eng', dim=100, vs=25000)\n",
        "\n",
        "# Extract the embeddings\n",
        "pretrained_embeddings = bpemb_id.emb.vectors\n",
        "\n",
        "tokenizer = bpemb_id"
      ],
      "metadata": {
        "id": "On89TVmgOJCB",
        "outputId": "f0a79c81-39a9-4c9c-8fb2-fce42e32488b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bpemb in /usr/local/lib/python3.10/dist-packages (0.3.4)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from bpemb) (4.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bpemb) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bpemb) (2.31.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from bpemb) (0.1.99)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from bpemb) (4.66.1)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim->bpemb) (1.11.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->bpemb) (6.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def BPEmb_tokenize_before_after(row, BPEmb_tokenizer):\n",
        "  before_tokens = BPEmb_tokenizer.encode(row[\"before\"])\n",
        "  answer_tokens = BPEmb_tokenizer.encode(row[\"answer\"])\n",
        "  after_tokens = BPEmb_tokenizer.encode(row[\"after\"])\n",
        "  return pd.Series([before_tokens, answer_tokens, after_tokens])"
      ],
      "metadata": {
        "id": "uhl6hgKaMvdP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_english[[\"before_tokens\", \"answer_tokens\", \"after_tokens\"]] = df_train_english.apply(lambda row: BPEmb_tokenize_before_after(row, tokenizer), axis=1)\n",
        "# df_train_english[[\"before_tokens\", \"answer_tokens\", \"after_tokens\"]] = df_train_english.apply(simple_tokenizer, axis=1)\n",
        "df_train_english.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        },
        "id": "Kyp-GtoYzKBW",
        "outputId": "8d028fd2-382f-46e5-a380-9507c12b6f67"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-1dffa2a88cca>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_train_english[[\"before_tokens\", \"answer_tokens\", \"after_tokens\"]] = df_train_english.apply(lambda row: BPEmb_tokenize_before_after(row, tokenizer), axis=1)\n",
            "<ipython-input-14-1dffa2a88cca>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_train_english[[\"before_tokens\", \"answer_tokens\", \"after_tokens\"]] = df_train_english.apply(lambda row: BPEmb_tokenize_before_after(row, tokenizer), axis=1)\n",
            "<ipython-input-14-1dffa2a88cca>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_train_english[[\"before_tokens\", \"answer_tokens\", \"after_tokens\"]] = df_train_english.apply(lambda row: BPEmb_tokenize_before_after(row, tokenizer), axis=1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         question_text  \\\n",
              "26            When was quantum field theory developed?   \n",
              "43   Who was the first Nobel prize winner for Liter...   \n",
              "112               When is the dialectical method used?   \n",
              "123                               Who invented Hangul?   \n",
              "125                          What do Grasshoppers eat?   \n",
              "\n",
              "                            document_title language  \\\n",
              "26                    Quantum field theory  english   \n",
              "43   List of Nobel laureates in Literature  english   \n",
              "112                              Dialectic  english   \n",
              "123                       Origin of Hangul  english   \n",
              "125                            Grasshopper  english   \n",
              "\n",
              "                                           annotations  \\\n",
              "26   {'answer_start': [159], 'answer_text': ['1920s']}   \n",
              "43   {'answer_start': [610], 'answer_text': ['Sully...   \n",
              "112  {'answer_start': [129], 'answer_text': ['disco...   \n",
              "123  {'answer_start': [88], 'answer_text': ['Sejong...   \n",
              "125  {'answer_start': [0], 'answer_text': ['Grassho...   \n",
              "\n",
              "                                    document_plaintext  \\\n",
              "26   Quantum field theory naturally began with the ...   \n",
              "43   The Nobel Prize in Literature (Swedish: Nobelp...   \n",
              "112  Dialectic or dialectics (Greek: διαλεκτική, di...   \n",
              "123  Hangul was personally created and promulgated ...   \n",
              "125  Grasshoppers are plant-eaters, with a few spec...   \n",
              "\n",
              "                                          document_url  \\\n",
              "26   https://en.wikipedia.org/wiki/Quantum%20field%...   \n",
              "43   https://en.wikipedia.org/wiki/List%20of%20Nobe...   \n",
              "112            https://en.wikipedia.org/wiki/Dialectic   \n",
              "123  https://en.wikipedia.org/wiki/Origin%20of%20Ha...   \n",
              "125          https://en.wikipedia.org/wiki/Grasshopper   \n",
              "\n",
              "                                                before  \\\n",
              "26   Quantum field theory naturally began with the ...   \n",
              "43   The Nobel Prize in Literature (Swedish: Nobelp...   \n",
              "112  Dialectic or dialectics (Greek: διαλεκτική, di...   \n",
              "123  Hangul was personally created and promulgated ...   \n",
              "125                                                      \n",
              "\n",
              "                                                answer  \\\n",
              "26                                               1920s   \n",
              "43                                     Sully Prudhomme   \n",
              "112  discourse between two or more people holding d...   \n",
              "123                                   Sejong the Great   \n",
              "125  Grasshoppers are plant-eaters, with a few spec...   \n",
              "\n",
              "                                                 after  \\\n",
              "26                                              .[8]:1   \n",
              "43    of France.[3] Each recipient receives a medal...   \n",
              "112  . Dialectic resembles debate, but the concept ...   \n",
              "123  .[1][2] Sejong's scholarly institute, the Hall...   \n",
              "125  . They protect themselves from predators by ca...   \n",
              "\n",
              "                                         before_tokens  \\\n",
              "26   [▁quantum, ▁field, ▁theory, ▁naturally, ▁began...   \n",
              "43   [▁the, ▁nobel, ▁prize, ▁in, ▁literature, ▁(, s...   \n",
              "112  [▁dialect, ic, ▁or, ▁dialect, ics, ▁(, greek, ...   \n",
              "123  [▁hang, ul, ▁was, ▁personally, ▁created, ▁and,...   \n",
              "125                                                 []   \n",
              "\n",
              "                                         answer_tokens  \\\n",
              "26                                          [▁0000, s]   \n",
              "43                          [▁sul, ly, ▁prud, hom, me]   \n",
              "112  [▁discourse, ▁between, ▁two, ▁or, ▁more, ▁peop...   \n",
              "123                          [▁se, jong, ▁the, ▁great]   \n",
              "125  [▁grass, hop, pers, ▁are, ▁plant, -, e, aters,...   \n",
              "\n",
              "                                          after_tokens  \n",
              "26                                   [▁., [, 0, ], :0]  \n",
              "43   [▁of, ▁france, ., [, 0, ], ▁each, ▁recipient, ...  \n",
              "112  [▁., ▁dialect, ic, ▁resembles, ▁debate, ,, ▁bu...  \n",
              "123  [▁., [, 0, ][, 0, ], ▁se, jong, ', s, ▁scholar...  \n",
              "125  [▁., ▁they, ▁protect, ▁themselves, ▁from, ▁pre...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-67e62bae-41ce-4ca4-94bc-2159eaac2c96\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question_text</th>\n",
              "      <th>document_title</th>\n",
              "      <th>language</th>\n",
              "      <th>annotations</th>\n",
              "      <th>document_plaintext</th>\n",
              "      <th>document_url</th>\n",
              "      <th>before</th>\n",
              "      <th>answer</th>\n",
              "      <th>after</th>\n",
              "      <th>before_tokens</th>\n",
              "      <th>answer_tokens</th>\n",
              "      <th>after_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>When was quantum field theory developed?</td>\n",
              "      <td>Quantum field theory</td>\n",
              "      <td>english</td>\n",
              "      <td>{'answer_start': [159], 'answer_text': ['1920s']}</td>\n",
              "      <td>Quantum field theory naturally began with the ...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Quantum%20field%...</td>\n",
              "      <td>Quantum field theory naturally began with the ...</td>\n",
              "      <td>1920s</td>\n",
              "      <td>.[8]:1</td>\n",
              "      <td>[▁quantum, ▁field, ▁theory, ▁naturally, ▁began...</td>\n",
              "      <td>[▁0000, s]</td>\n",
              "      <td>[▁., [, 0, ], :0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Who was the first Nobel prize winner for Liter...</td>\n",
              "      <td>List of Nobel laureates in Literature</td>\n",
              "      <td>english</td>\n",
              "      <td>{'answer_start': [610], 'answer_text': ['Sully...</td>\n",
              "      <td>The Nobel Prize in Literature (Swedish: Nobelp...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/List%20of%20Nobe...</td>\n",
              "      <td>The Nobel Prize in Literature (Swedish: Nobelp...</td>\n",
              "      <td>Sully Prudhomme</td>\n",
              "      <td>of France.[3] Each recipient receives a medal...</td>\n",
              "      <td>[▁the, ▁nobel, ▁prize, ▁in, ▁literature, ▁(, s...</td>\n",
              "      <td>[▁sul, ly, ▁prud, hom, me]</td>\n",
              "      <td>[▁of, ▁france, ., [, 0, ], ▁each, ▁recipient, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>When is the dialectical method used?</td>\n",
              "      <td>Dialectic</td>\n",
              "      <td>english</td>\n",
              "      <td>{'answer_start': [129], 'answer_text': ['disco...</td>\n",
              "      <td>Dialectic or dialectics (Greek: διαλεκτική, di...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Dialectic</td>\n",
              "      <td>Dialectic or dialectics (Greek: διαλεκτική, di...</td>\n",
              "      <td>discourse between two or more people holding d...</td>\n",
              "      <td>. Dialectic resembles debate, but the concept ...</td>\n",
              "      <td>[▁dialect, ic, ▁or, ▁dialect, ics, ▁(, greek, ...</td>\n",
              "      <td>[▁discourse, ▁between, ▁two, ▁or, ▁more, ▁peop...</td>\n",
              "      <td>[▁., ▁dialect, ic, ▁resembles, ▁debate, ,, ▁bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>Who invented Hangul?</td>\n",
              "      <td>Origin of Hangul</td>\n",
              "      <td>english</td>\n",
              "      <td>{'answer_start': [88], 'answer_text': ['Sejong...</td>\n",
              "      <td>Hangul was personally created and promulgated ...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Origin%20of%20Ha...</td>\n",
              "      <td>Hangul was personally created and promulgated ...</td>\n",
              "      <td>Sejong the Great</td>\n",
              "      <td>.[1][2] Sejong's scholarly institute, the Hall...</td>\n",
              "      <td>[▁hang, ul, ▁was, ▁personally, ▁created, ▁and,...</td>\n",
              "      <td>[▁se, jong, ▁the, ▁great]</td>\n",
              "      <td>[▁., [, 0, ][, 0, ], ▁se, jong, ', s, ▁scholar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>What do Grasshoppers eat?</td>\n",
              "      <td>Grasshopper</td>\n",
              "      <td>english</td>\n",
              "      <td>{'answer_start': [0], 'answer_text': ['Grassho...</td>\n",
              "      <td>Grasshoppers are plant-eaters, with a few spec...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Grasshopper</td>\n",
              "      <td></td>\n",
              "      <td>Grasshoppers are plant-eaters, with a few spec...</td>\n",
              "      <td>. They protect themselves from predators by ca...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[▁grass, hop, pers, ▁are, ▁plant, -, e, aters,...</td>\n",
              "      <td>[▁., ▁they, ▁protect, ▁themselves, ▁from, ▁pre...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67e62bae-41ce-4ca4-94bc-2159eaac2c96')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-67e62bae-41ce-4ca4-94bc-2159eaac2c96 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-67e62bae-41ce-4ca4-94bc-2159eaac2c96');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4cef009b-0434-48cd-b3f5-f3b487fa29ee\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4cef009b-0434-48cd-b3f5-f3b487fa29ee')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4cef009b-0434-48cd-b3f5-f3b487fa29ee button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = df_train_english.apply(lambda row: len(row[\"before_tokens\"]) + len(row[\"answer\"]) + len(row[\"after_tokens\"]), axis=1).max()\n",
        "print(max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYWlMj4225jD",
        "outputId": "92a2a68b-7331-46f3-d833-be5cc1a0a331"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_english[\"text_pad\"] = df_train_english.apply(lambda row: [\"[PAD]\"] * (max_len - (len(row[\"before_tokens\"]) + len(row[\"answer\"]) + len(row[\"after_tokens\"]))), axis=1)\n",
        "#df_train_english.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQ6WgTpW2OLi",
        "outputId": "c81b16dd-2aef-477b-c49a-4a2277beff18"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-cc718dcdef7b>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_train_english[\"text_pad\"] = df_train_english.apply(lambda row: [\"[PAD]\"] * (max_len - (len(row[\"before_tokens\"]) + len(row[\"answer\"]) + len(row[\"after_tokens\"]))), axis=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_BIO_tags_text(row):\n",
        "  before = [\"O\"] * len(row[\"before_tokens\"])\n",
        "  if len(row[\"answer_tokens\"]) == 0:\n",
        "    answer = []\n",
        "  else:\n",
        "    answer = [\"B\"] + [\"I\"] * (len(row[\"answer_tokens\"]) - 1)\n",
        "  after = [\"O\"] * len(row[\"after_tokens\"])\n",
        "  pad = [\"O\"] * len(row[\"text_pad\"])\n",
        "  return before + answer + after + pad"
      ],
      "metadata": {
        "id": "ggw6f0rtzixZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_english[\"BIO_tags_text\"] = df_train_english.apply(create_BIO_tags_text, axis=1)\n",
        "#df_train_english.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSlTHquE0NzR",
        "outputId": "01bd3b55-eab2-4d77-fc46-1e67370ff16e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-b19b1d6eb093>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_train_english[\"BIO_tags_text\"] = df_train_english.apply(create_BIO_tags_text, axis=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_lengts_not_eq = df_train_english[df_train_english.apply(lambda row: not (len(row[\"before_tokens\"]) + len(row[\"answer_tokens\"]) + len(row[\"after_tokens\"]) + len(row[\"text_pad\"]) == len(row[\"BIO_tags_text\"])), axis=1)]\n",
        "#df_lengts_not_eq"
      ],
      "metadata": {
        "id": "Gyu1W8im0eq9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize question:\n",
        "# tokenizer = mbert_tokeniser\n",
        "# df_train_english[\"question_tokens\"] = df_train_english.apply(lambda row: tokenizer.tokenize(row[\"question_text\"]), axis=1)\n",
        "df_train_english[\"question_tokens\"] = df_train_english.apply(lambda row: row[\"question_text\"].split(), axis=1)\n",
        "#df_train_english.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zukN6sz06uNW",
        "outputId": "8de581ff-eb04-42cc-b8c8-ed65c9111994"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-d7483d0d7550>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_train_english[\"question_tokens\"] = df_train_english.apply(lambda row: row[\"question_text\"].split(), axis=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len_questions = df_train_english.apply(lambda row: len(row[\"question_tokens\"]), axis=1).max()\n",
        "print(max_len_questions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpTHTQ9G7yav",
        "outputId": "7bfba2ec-a6c0-43b7-8b16-cef41587e3f8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_english[\"question_pad\"] = df_train_english.apply(lambda row: [\"[PAD]\"] * (max_len_questions - len(row[\"question_tokens\"])), axis=1)\n",
        "#df_train_english.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpN1ido58AWO",
        "outputId": "9b3b728a-dc7b-4d0e-bcca-a2f5c41dbb52"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-289d7fdfd640>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_train_english[\"question_pad\"] = df_train_english.apply(lambda row: [\"[PAD]\"] * (max_len_questions - len(row[\"question_tokens\"])), axis=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_english[\"BIO_tags_question\"] = df_train_english.apply(lambda row: [\"O\"] * max_len_questions, axis=1)\n",
        "#df_train_english.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpKGYOZm8PB8",
        "outputId": "f9c5477a-bbe0-4bf7-b9af-ae87a3aaaafc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-c1a084ec7cd6>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_train_english[\"BIO_tags_question\"] = df_train_english.apply(lambda row: [\"O\"] * max_len_questions, axis=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_english[\"merged_BIO\"] = df_train_english.apply(lambda row: row[\"BIO_tags_text\"] + row[\"BIO_tags_question\"], axis=1)\n",
        "#df_train_english.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUest-IQ8kVy",
        "outputId": "867f2698-d948-42dc-bff7-16ee2262e3cd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-ca49f9b253d9>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_train_english[\"merged_BIO\"] = df_train_english.apply(lambda row: row[\"BIO_tags_text\"] + row[\"BIO_tags_question\"], axis=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_english[\"merged_tokens\"] = df_train_english.apply(lambda row: row[\"before_tokens\"] + row[\"answer_tokens\"] + row[\"after_tokens\"] + row[\"text_pad\"] + row[\"question_tokens\"] + row[\"question_pad\"], axis=1)\n",
        "#df_train_english.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QmQ5MkQ829I",
        "outputId": "eee29615-104f-4186-ce2b-d28a38a3eebf"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-864bc71f6821>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_train_english[\"merged_tokens\"] = df_train_english.apply(lambda row: row[\"before_tokens\"] + row[\"answer_tokens\"] + row[\"after_tokens\"] + row[\"text_pad\"] + row[\"question_tokens\"] + row[\"question_pad\"], axis=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_lengts_not_eq = df_train_english[df_train_english.apply(lambda row: not (len(row[\"merged_BIO\"])) == len(row[\"merged_tokens\"]), axis=1)]\n",
        "#df_lengts_not_eq"
      ],
      "metadata": {
        "id": "-Jt4enh79nUb"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def BIO_tags_to_labels(row):\n",
        "  # Create a dictionary to map the strings to numbers\n",
        "  mapping = {\"B\": 2, \"O\": 0, \"I\": 1}\n",
        "\n",
        "  # Use a list comprehension to convert the strings to numbers\n",
        "  return [mapping[char] for char in row[\"merged_BIO\"]]"
      ],
      "metadata": {
        "id": "xyO55f60UyZC"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_english[\"BIO_labels\"] = df_train_english.apply(BIO_tags_to_labels, axis=1)\n",
        "#df_train_english.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40lW_pHKVBhX",
        "outputId": "f8ab4fb4-6279-43ba-dc28-a946a047dee7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-bd3e41d9a529>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_train_english[\"BIO_labels\"] = df_train_english.apply(BIO_tags_to_labels, axis=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Format of merged vector:\n",
        "[before] + [answer] + [after] + [padding] + [question] + [padding]"
      ],
      "metadata": {
        "id": "UlEWdylt-VIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bpemb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTuk-zk4OD7n",
        "outputId": "3ff736e0-29dd-4663-eda6-0aba16976550"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bpemb in /usr/local/lib/python3.10/dist-packages (0.3.4)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from bpemb) (4.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bpemb) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bpemb) (2.31.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from bpemb) (0.1.99)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from bpemb) (4.66.1)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim->bpemb) (1.11.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->bpemb) (6.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bpemb import BPEmb\n",
        "\n",
        "PADID = 25000 - 1\n",
        "# Load English model with 25k word-pieces\n",
        "bpemb_id = BPEmb(lang='eng', dim=100, vs=PADID + 1)\n",
        "\n",
        "# Extract the embeddings\n",
        "pretrained_embeddings = bpemb_id.emb.vectors"
      ],
      "metadata": {
        "id": "355PFmoxOATk"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Following code is taken from lab 4"
      ],
      "metadata": {
        "id": "lrfwIPDeNkqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "from math import log\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "import torch\n",
        "import random\n",
        "from math import log\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import ExponentialLR, CyclicLR\n",
        "from typing import List, Tuple, AnyStr\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import matplotlib.pyplot as plt\n",
        "from copy import deepcopy\n",
        "from datasets import load_dataset, load_metric\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import torch.nn.functional as F\n",
        "import heapq"
      ],
      "metadata": {
        "id": "RhWbOsUhMt5V"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_embeddings.shape[0] - 1"
      ],
      "metadata": {
        "id": "PbuYzz88t0oM",
        "outputId": "311e39a9-e0bc-4b9b-e015-f070efb405ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24999"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "class BiLSTM(nn.Module):\n",
        "    \"\"\"\n",
        "    Basic BiLSTM-CRF network\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            pretrained_embeddings: torch.tensor,\n",
        "            lstm_dim: int,\n",
        "            dropout_prob: float = 0.1,\n",
        "            n_classes: int = 2\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initializer for basic BiLSTM network\n",
        "        :param pretrained_embeddings: A tensor containing the pretrained BPE embeddings\n",
        "        :param lstm_dim: The dimensionality of the BiLSTM network\n",
        "        :param dropout_prob: Dropout probability\n",
        "        :param n_classes: The number of output classes\n",
        "        \"\"\"\n",
        "\n",
        "        # First thing is to call the superclass initializer\n",
        "        super(BiLSTM, self).__init__()\n",
        "\n",
        "        # We'll define the network in a ModuleDict, which makes organizing the model a bit nicer\n",
        "        # The components are an embedding layer, a 2 layer BiLSTM, and a feed-forward output layer\n",
        "        self.model = nn.ModuleDict({\n",
        "            'embeddings': nn.Embedding.from_pretrained(pretrained_embeddings, padding_idx=pretrained_embeddings.shape[0] - 1),\n",
        "            'bilstm': nn.LSTM(\n",
        "                pretrained_embeddings.shape[1],  # input size\n",
        "                lstm_dim,  # hidden size\n",
        "                2,  # number of layers\n",
        "                batch_first=True,\n",
        "                dropout=dropout_prob,\n",
        "                bidirectional=True),\n",
        "            'ff': nn.Linear(2*lstm_dim, n_classes),\n",
        "        })\n",
        "        self.n_classes = n_classes\n",
        "        self.loss = nn.CrossEntropyLoss()\n",
        "        # Initialize the weights of the model\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        all_params = list(self.model['bilstm'].named_parameters()) + \\\n",
        "                     list(self.model['ff'].named_parameters())\n",
        "        for n,p in all_params:\n",
        "            if 'weight' in n:\n",
        "                nn.init.xavier_normal_(p)\n",
        "            elif 'bias' in n:\n",
        "                nn.init.zeros_(p)\n",
        "\n",
        "    def forward(self, inputs, input_lens, hidden_states = None, labels = None):\n",
        "        \"\"\"\n",
        "        Defines how tensors flow through the model\n",
        "        :param inputs: (b x sl) The IDs into the vocabulary of the input samples\n",
        "        :param input_lens: (b) The length of each input sequence\n",
        "        :param labels: (b) The label of each sample\n",
        "        :return: (loss, logits) if `labels` is not None, otherwise just (logits,)\n",
        "        \"\"\"\n",
        "\n",
        "        # Get embeddings (b x sl x edim)\n",
        "        embeds = self.model['embeddings'](inputs)\n",
        "\n",
        "        # Pack padded: This is necessary for padded batches input to an RNN - https://stackoverflow.com/questions/51030782/why-do-we-pack-the-sequences-in-pytorch\n",
        "        lstm_in = nn.utils.rnn.pack_padded_sequence(\n",
        "            embeds,\n",
        "            input_lens.cpu(),\n",
        "            batch_first=True,\n",
        "            enforce_sorted=False\n",
        "        )\n",
        "\n",
        "        # Pass the packed sequence through the BiLSTM\n",
        "        if hidden_states:\n",
        "            lstm_out, hidden = self.model['bilstm'](lstm_in, hidden_states)\n",
        "        else:\n",
        "            lstm_out, hidden = self.model['bilstm'](lstm_in)\n",
        "\n",
        "        # Unpack the packed sequence --> (b x sl x 2*lstm_dim)\n",
        "        lstm_out, lengths = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True)\n",
        "\n",
        "        # Get logits (b x seq_len x n_classes)\n",
        "        logits = self.model['ff'](lstm_out)\n",
        "        outputs = (logits, lengths)\n",
        "        if labels is not None:\n",
        "            loss = self.loss(logits.reshape(-1, self.n_classes), labels.reshape(-1))\n",
        "            outputs =  outputs + (loss,)\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "BmV4glRF-out"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(\n",
        "    model: nn.Module,\n",
        "    train_dl: DataLoader,\n",
        "    valid_dl: DataLoader,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    n_epochs: int,\n",
        "    device: torch.device,\n",
        "    scheduler=None,\n",
        "):\n",
        "    \"\"\"\n",
        "    The main training loop which will optimize a given model on a given dataset\n",
        "    :param model: The model being optimized\n",
        "    :param train_dl: The training dataset\n",
        "    :param valid_dl: A validation dataset\n",
        "    :param optimizer: The optimizer used to update the model parameters\n",
        "    :param n_epochs: Number of epochs to train for\n",
        "    :param device: The device to train on\n",
        "    :return: (model, losses) The best model and the losses per iteration\n",
        "    \"\"\"\n",
        "\n",
        "  # Keep track of the loss and best accuracy\n",
        "    losses = []\n",
        "    learning_rates = []\n",
        "    best_f1 = 0.0\n",
        "\n",
        "    # Iterate through epochs\n",
        "    for ep in range(n_epochs):\n",
        "\n",
        "        loss_epoch = []\n",
        "\n",
        "        #Iterate through each batch in the dataloader\n",
        "        for batch in tqdm(train_dl):\n",
        "            # VERY IMPORTANT: Make sure the model is in training mode, which turns on\n",
        "            # things like dropout and layer normalization\n",
        "            model.train()\n",
        "\n",
        "            # VERY IMPORTANT: zero out all of the gradients on each iteration -- PyTorch\n",
        "            # keeps track of these dynamically in its computation graph so you need to explicitly\n",
        "            # zero them out\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Place each tensor on the GPU\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            input_ids = batch[0]\n",
        "            seq_lens = batch[1]\n",
        "            labels = batch[2]\n",
        "\n",
        "            # Pass the inputs through the model, get the current loss and logits\n",
        "            logits, lengths, loss = model(input_ids, seq_lens, labels=labels)\n",
        "            losses.append(loss.item())\n",
        "            loss_epoch.append(loss.item())\n",
        "\n",
        "            # Calculate all of the gradients and weight updates for the model\n",
        "            loss.backward()\n",
        "\n",
        "            # Optional: clip gradients\n",
        "            #torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Finally, update the weights of the model\n",
        "            optimizer.step()\n",
        "            if scheduler != None:\n",
        "                scheduler.step()\n",
        "                learning_rates.append(scheduler.get_last_lr()[0])\n",
        "\n",
        "        # Perform inline evaluation at the end of the epoch\n",
        "        f1 = evaluate(model, valid_dl)\n",
        "        print(f'Validation F1: {f1}, train loss: {sum(loss_epoch) / len(loss_epoch)}')\n",
        "\n",
        "        # Keep track of the best model based on the accuracy\n",
        "        if f1 > best_f1:\n",
        "            torch.save(model.state_dict(), 'best_model')\n",
        "            best_f1 = f1\n",
        "\n",
        "    return losses, learning_rates"
      ],
      "metadata": {
        "id": "bbA2efabMhtm"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def evaluate(model: nn.Module, valid_dl: DataLoader):\n",
        "    \"\"\"\n",
        "    Evaluates the model on the given dataset\n",
        "    :param model: The model under evaluation\n",
        "    :param valid_dl: A `DataLoader` reading validation data\n",
        "    :return: The accuracy of the model on the dataset\n",
        "    \"\"\"\n",
        "    # VERY IMPORTANT: Put your model in \"eval\" mode -- this disables things like\n",
        "    # layer normalization and dropout\n",
        "    model.eval()\n",
        "    labels_all = []\n",
        "    preds_all = []\n",
        "\n",
        "    # ALSO IMPORTANT: Don't accumulate gradients during this process\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(valid_dl, desc='Evaluation'):\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            input_ids = batch[0]\n",
        "            seq_lens = batch[1]\n",
        "            labels = batch[2]\n",
        "            hidden_states = None\n",
        "\n",
        "            logits, _, _ = model(input_ids, seq_lens, hidden_states=hidden_states, labels=labels)\n",
        "            preds_all.extend(torch.argmax(logits, dim=-1).reshape(-1).detach().cpu().numpy())\n",
        "            labels_all.extend(labels.reshape(-1).detach().cpu().numpy())\n",
        "\n",
        "    P, R, F1, _ = precision_recall_fscore_support(labels_all, preds_all, average='macro')\n",
        "    print(confusion_matrix(labels_all, preds_all))\n",
        "    return F1\n",
        "\n"
      ],
      "metadata": {
        "id": "x5lp1LigNtEd"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_dim = 128\n",
        "dropout_prob = 0.1\n",
        "batch_size = 8\n",
        "lr = 1e-2\n",
        "n_epochs = 10\n",
        "n_workers = 0  # set to a larger number if you run your code in colab\n",
        "\n",
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "# Create the model\n",
        "model = BiLSTM(\n",
        "    pretrained_embeddings=torch.FloatTensor(pretrained_embeddings),\n",
        "    lstm_dim=lstm_dim,\n",
        "    dropout_prob=dropout_prob,\n",
        "    n_classes=3\n",
        "  ).to(device)"
      ],
      "metadata": {
        "id": "OumBhBN3NvLf"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch_bilstm(input_data: Tuple) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Combines multiple data samples into a single batch\n",
        "    :param input_data: The combined input_ids, seq_lens, and labels for the batch\n",
        "    :return: A tuple of tensors (input_ids, seq_lens, labels)\n",
        "    \"\"\"\n",
        "    input_ids = [i[0][0] for i in input_data]\n",
        "    seq_lens = [len(i) for i in input_data]\n",
        "    labels = [i[2] for i in input_data]\n",
        "\n",
        "    max_length = max([len(i) for i in input_ids])\n",
        "\n",
        "    # Pad all of the input samples to the max length (25000 is the ID of the [PAD] token)\n",
        "    # input_ids = [(i + [25000] * (max_length - len(i))) for i in input_ids]\n",
        "\n",
        "    # Make sure each sample is max_length long\n",
        "    assert (all(len(i) == max_length for i in input_ids))\n",
        "    return torch.tensor(input_ids), torch.tensor(seq_lens), torch.tensor(labels)"
      ],
      "metadata": {
        "id": "OOJiSlm1OqVJ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"def collate_batch_bilstm(input_data: Tuple) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "    input_ids = [tokenizer.encode_ids_with_eos(i[0][0]) for i in input_data]\n",
        "    seq_lens = [len(i) for i in input_ids]\n",
        "    labels = [i[2] for i in input_data]\n",
        "\n",
        "    max_length = max([len(i) for i in input_ids])\n",
        "\n",
        "    input_ids = [(i + [0] * (max_length - len(i))) for i in input_ids]\n",
        "    labels = [(i + [0] * (max_length - len(i))) for i in labels] # 0 is the id of the O tag\n",
        "\n",
        "    assert (all(len(i) == max_length for i in input_ids))\n",
        "    assert (all(len(i) == max_length for i in labels))\n",
        "    return torch.tensor(input_ids), torch.tensor(seq_lens), torch.tensor(labels)\"\"\""
      ],
      "metadata": {
        "id": "spAX4fRUayHT",
        "outputId": "b0e3cc68-88c0-4e65-920d-d5f9c947d96e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'def collate_batch_bilstm(input_data: Tuple) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\\n    input_ids = [tokenizer.encode_ids_with_eos(i[0][0]) for i in input_data]\\n    seq_lens = [len(i) for i in input_ids]\\n    labels = [i[2] for i in input_data]\\n\\n    max_length = max([len(i) for i in input_ids])\\n\\n    input_ids = [(i + [0] * (max_length - len(i))) for i in input_ids]\\n    labels = [(i + [0] * (max_length - len(i))) for i in labels] # 0 is the id of the O tag\\n\\n    assert (all(len(i) == max_length for i in input_ids))\\n    assert (all(len(i) == max_length for i in labels))\\n    return torch.tensor(input_ids), torch.tensor(seq_lens), torch.tensor(labels)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_batch_bilstm(text: List, tokenizer, max_len=512) -> Tuple[List, List]:\n",
        "    \"\"\"\n",
        "    Creates a tokenized batch for input to a bilstm model\n",
        "    :param text: A list of sentences to tokenize\n",
        "    :param tokenizer: A tokenization function to use (i.e. fasttext)\n",
        "    :return: Tokenized text as well as the length of the input sequence\n",
        "    \"\"\"\n",
        "    # Some light preprocessing\n",
        "    #input_ids = [tokenizer.encode_ids_with_eos(t)[:max_len] for t in text]\n",
        "    input_ids = [tokenizer.embed(t) for t in text]\n",
        "\n",
        "\n",
        "    return input_ids, [len(ids) for ids in input_ids]"
      ],
      "metadata": {
        "id": "3LmTjqCyYJiq"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This will load the dataset and process it lazily in the __getitem__ function\n",
        "class ClassificationDatasetReader(Dataset):\n",
        "  def __init__(self, df):\n",
        "    self.df = df\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    row = self.df.values[idx]\n",
        "    # Calls the text_to_batch function\n",
        "    input_ids,seq_lens = row[0], len(row[0])\n",
        "    label = row[1]\n",
        "    return input_ids, seq_lens, label"
      ],
      "metadata": {
        "id": "0TRIcTQEYHR1"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_process_df(df, tokenizer):\n",
        "  df[[\"before\", \"answer\", \"after\"]] = df.apply(split_text_with_answer, axis=1)\n",
        "  df[[\"before_tokens\", \"answer_tokens\", \"after_tokens\"]] = df.apply(lambda row: BPEmb_tokenize_before_after(row, tokenizer), axis=1)\n",
        "  max_len = df.apply(lambda row: len(row[\"before_tokens\"]) + len(row[\"answer_tokens\"]) + len(row[\"after_tokens\"]), axis=1).max()\n",
        "  df[\"text_pad\"] = df.apply(lambda row: [\"[PAD]\"] * (max_len - (len(row[\"before_tokens\"]) + len(row[\"answer_tokens\"]) + len(row[\"after_tokens\"]))), axis=1)\n",
        "  df[\"BIO_tags_text\"] = df.apply(create_BIO_tags_text, axis=1)\n",
        "  df[\"question_tokens\"] = df.apply(lambda row: tokenizer.encode(row[\"question_text\"]), axis=1)\n",
        "  max_len_questions = df.apply(lambda row: len(row[\"question_tokens\"]), axis=1).max()\n",
        "  df[\"question_pad\"] = df.apply(lambda row: [\"[PAD]\"] * (max_len_questions - len(row[\"question_tokens\"])), axis=1)\n",
        "  df[\"BIO_tags_question\"] = df.apply(lambda row: [\"O\"] * max_len_questions, axis=1)\n",
        "  df[\"merged_BIO\"] = df.apply(lambda row: row[\"BIO_tags_text\"] + row[\"BIO_tags_question\"], axis=1)\n",
        "  df[\"merged_tokens\"] = df.apply(lambda row: row[\"before_tokens\"] + row[\"answer_tokens\"] + row[\"after_tokens\"] + row[\"text_pad\"] + row[\"question_tokens\"] + row[\"question_pad\"], axis=1)\n",
        "  df[\"BIO_labels\"] = df.apply(BIO_tags_to_labels, axis=1)\n",
        "  df[\"flatten_merged_tokens\"] = df.apply(lambda row: ' '.join(row[\"merged_tokens\"]), axis=1)\n",
        "  res_df = pd.DataFrame({\n",
        "    'text':(df[\"merged_tokens\"]),\n",
        "    'answerable':(df[\"BIO_labels\"])\n",
        "    })\n",
        "  return df, res_df"
      ],
      "metadata": {
        "id": "wrgtb3X0QvHp"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_emb(row, embedder):\n",
        "  before_tokens = embedder.encode_ids(row[\"before\"])\n",
        "  answer_tokens = embedder.encode_ids(row[\"answer\"])\n",
        "  after_tokens = embedder.encode_ids(row[\"after\"])\n",
        "  return pd.Series([before_tokens, answer_tokens, after_tokens])\n",
        "\n",
        "def create_BIO_labels_text(row):\n",
        "  before = [0] * len(row[\"before_emb\"])\n",
        "  if len(row[\"answer_emb\"]) == 0:\n",
        "    answer = []\n",
        "  else:\n",
        "    answer = [2] + [1] * (len(row[\"answer_emb\"]) - 1)\n",
        "  after = [0] * len(row[\"after_emb\"])\n",
        "  pad = [0] * len(row[\"text_pad\"])\n",
        "  return before + answer + after + pad\n",
        "\n",
        "\n",
        "\n",
        "def pre_process_df(df, tokenizer):\n",
        "  df[[\"before\", \"answer\", \"after\"]] = df.apply(split_text_with_answer, axis=1)\n",
        "  df[[\"before_emb\", \"answer_emb\", \"after_emb\"]] = df.apply(lambda row: make_emb(row, tokenizer), axis=1)\n",
        "  max_len = df.apply(lambda row: len(row[\"before_emb\"]) + len(row[\"answer_emb\"]) + len(row[\"after_emb\"]), axis=1).max()\n",
        "  df[\"text_pad\"] = df.apply(lambda row: [PADID] * (max_len - (len(row[\"before_emb\"]) + len(row[\"answer_emb\"]) + len(row[\"after_emb\"]))), axis=1)\n",
        "  df[\"BIO_labels_text\"] = df.apply(create_BIO_labels_text, axis=1)\n",
        "\n",
        "\n",
        "  df[\"question_emb\"] = df.apply(lambda row: tokenizer.encode_ids(row[\"question_text\"]), axis=1)\n",
        "  max_len_questions = df.apply(lambda row: len(row[\"question_emb\"]), axis=1).max()\n",
        "  df[\"question_pad\"] = df.apply(lambda row: [PADID] * (max_len_questions - len(row[\"question_emb\"])), axis=1)\n",
        "  df[\"BIO_labels_question\"] = df.apply(lambda row: [0] * max_len_questions, axis=1)\n",
        "  print(df.head())\n",
        "  # df[\"merged_BIO\"] = df.apply(lambda row: row[\"BIO_tags_text\"] + row[\"BIO_tags_question\"], axis=1)\n",
        "\n",
        "  df[\"merged_emb\"] = df.apply(lambda row: row[\"question_emb\"] + row[\"question_pad\"] + row[\"before_emb\"] + row[\"answer_emb\"] + row[\"after_emb\"] + row[\"text_pad\"], axis=1)\n",
        "  df[\"BIO_labels\"] = df.apply(lambda row: row[\"BIO_labels_question\"] + row[\"BIO_labels_text\"], axis=1)\n",
        "  #df[\"flatten_merged_tokens\"] = df.apply(lambda row: ' '.join(row[\"merged_tokens\"]), axis=1)\n",
        "  res_df = pd.DataFrame({\n",
        "    'text':(df[\"merged_emb\"]),\n",
        "    'answerable':(df[\"BIO_labels\"])\n",
        "    })\n",
        "  return df, res_df"
      ],
      "metadata": {
        "id": "64QuvquxVbcd"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = bpemb_id\n",
        "english_train, english_train_merged = pre_process_df(df_train_english, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeHErObSSDSe",
        "outputId": "9bf2e71f-3cd1-4ede-a8a1-44a18008fca7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-55bbb6f573b0>:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[[\"before\", \"answer\", \"after\"]] = df.apply(split_text_with_answer, axis=1)\n",
            "<ipython-input-42-55bbb6f573b0>:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[[\"before_emb\", \"answer_emb\", \"after_emb\"]] = df.apply(lambda row: make_emb(row, tokenizer), axis=1)\n",
            "<ipython-input-42-55bbb6f573b0>:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[[\"before_emb\", \"answer_emb\", \"after_emb\"]] = df.apply(lambda row: make_emb(row, tokenizer), axis=1)\n",
            "<ipython-input-42-55bbb6f573b0>:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[[\"before_emb\", \"answer_emb\", \"after_emb\"]] = df.apply(lambda row: make_emb(row, tokenizer), axis=1)\n",
            "<ipython-input-42-55bbb6f573b0>:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"text_pad\"] = df.apply(lambda row: [PADID] * (max_len - (len(row[\"before_emb\"]) + len(row[\"answer_emb\"]) + len(row[\"after_emb\"]))), axis=1)\n",
            "<ipython-input-42-55bbb6f573b0>:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"BIO_labels_text\"] = df.apply(create_BIO_labels_text, axis=1)\n",
            "<ipython-input-42-55bbb6f573b0>:27: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"question_emb\"] = df.apply(lambda row: tokenizer.encode_ids(row[\"question_text\"]), axis=1)\n",
            "<ipython-input-42-55bbb6f573b0>:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"question_pad\"] = df.apply(lambda row: [PADID] * (max_len_questions - len(row[\"question_emb\"])), axis=1)\n",
            "<ipython-input-42-55bbb6f573b0>:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"BIO_labels_question\"] = df.apply(lambda row: [0] * max_len_questions, axis=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         question_text  \\\n",
            "26            When was quantum field theory developed?   \n",
            "43   Who was the first Nobel prize winner for Liter...   \n",
            "112               When is the dialectical method used?   \n",
            "123                               Who invented Hangul?   \n",
            "125                          What do Grasshoppers eat?   \n",
            "\n",
            "                            document_title language  \\\n",
            "26                    Quantum field theory  english   \n",
            "43   List of Nobel laureates in Literature  english   \n",
            "112                              Dialectic  english   \n",
            "123                       Origin of Hangul  english   \n",
            "125                            Grasshopper  english   \n",
            "\n",
            "                                           annotations  \\\n",
            "26   {'answer_start': [159], 'answer_text': ['1920s']}   \n",
            "43   {'answer_start': [610], 'answer_text': ['Sully...   \n",
            "112  {'answer_start': [129], 'answer_text': ['disco...   \n",
            "123  {'answer_start': [88], 'answer_text': ['Sejong...   \n",
            "125  {'answer_start': [0], 'answer_text': ['Grassho...   \n",
            "\n",
            "                                    document_plaintext  \\\n",
            "26   Quantum field theory naturally began with the ...   \n",
            "43   The Nobel Prize in Literature (Swedish: Nobelp...   \n",
            "112  Dialectic or dialectics (Greek: διαλεκτική, di...   \n",
            "123  Hangul was personally created and promulgated ...   \n",
            "125  Grasshoppers are plant-eaters, with a few spec...   \n",
            "\n",
            "                                          document_url  \\\n",
            "26   https://en.wikipedia.org/wiki/Quantum%20field%...   \n",
            "43   https://en.wikipedia.org/wiki/List%20of%20Nobe...   \n",
            "112            https://en.wikipedia.org/wiki/Dialectic   \n",
            "123  https://en.wikipedia.org/wiki/Origin%20of%20Ha...   \n",
            "125          https://en.wikipedia.org/wiki/Grasshopper   \n",
            "\n",
            "                                                before  \\\n",
            "26   Quantum field theory naturally began with the ...   \n",
            "43   The Nobel Prize in Literature (Swedish: Nobelp...   \n",
            "112  Dialectic or dialectics (Greek: διαλεκτική, di...   \n",
            "123  Hangul was personally created and promulgated ...   \n",
            "125                                                      \n",
            "\n",
            "                                                answer  \\\n",
            "26                                               1920s   \n",
            "43                                     Sully Prudhomme   \n",
            "112  discourse between two or more people holding d...   \n",
            "123                                   Sejong the Great   \n",
            "125  Grasshoppers are plant-eaters, with a few spec...   \n",
            "\n",
            "                                                 after  \\\n",
            "26                                              .[8]:1   \n",
            "43    of France.[3] Each recipient receives a medal...   \n",
            "112  . Dialectic resembles debate, but the concept ...   \n",
            "123  .[1][2] Sejong's scholarly institute, the Hall...   \n",
            "125  . They protect themselves from predators by ca...   \n",
            "\n",
            "                                         before_tokens  ...  \\\n",
            "26   [▁quantum, ▁field, ▁theory, ▁naturally, ▁began...  ...   \n",
            "43   [▁the, ▁nobel, ▁prize, ▁in, ▁literature, ▁(, s...  ...   \n",
            "112  [▁dialect, ic, ▁or, ▁dialect, ics, ▁(, greek, ...  ...   \n",
            "123  [▁hang, ul, ▁was, ▁personally, ▁created, ▁and,...  ...   \n",
            "125                                                 []  ...   \n",
            "\n",
            "                                     BIO_tags_question  \\\n",
            "26   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
            "43   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
            "112  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
            "123  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
            "125  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
            "\n",
            "                                            merged_BIO  \\\n",
            "26   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
            "43   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
            "112  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
            "123  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
            "125  [B, I, I, I, I, I, I, I, I, I, I, I, I, I, I, ...   \n",
            "\n",
            "                                         merged_tokens  \\\n",
            "26   [▁quantum, ▁field, ▁theory, ▁naturally, ▁began...   \n",
            "43   [▁the, ▁nobel, ▁prize, ▁in, ▁literature, ▁(, s...   \n",
            "112  [▁dialect, ic, ▁or, ▁dialect, ics, ▁(, greek, ...   \n",
            "123  [▁hang, ul, ▁was, ▁personally, ▁created, ▁and,...   \n",
            "125  [▁grass, hop, pers, ▁are, ▁plant, -, e, aters,...   \n",
            "\n",
            "                                            BIO_labels  \\\n",
            "26   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
            "43   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
            "112  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
            "123  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
            "125  [2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
            "\n",
            "                                            before_emb  \\\n",
            "26   [8062, 1316, 2355, 10284, 1046, 97, 7, 2147, 2...   \n",
            "43   [7, 7878, 3526, 26, 3608, 64, 19829, 202, 2494...   \n",
            "112  [5623, 36, 127, 5623, 539, 64, 16590, 24948, 2...   \n",
            "123  [5908, 98, 73, 10609, 1648, 34, 23443, 175, 10...   \n",
            "125                                                 []   \n",
            "\n",
            "                                            answer_emb  \\\n",
            "26                                         [52, 24920]   \n",
            "43                        [9923, 74, 21032, 9528, 979]   \n",
            "112  [17180, 528, 336, 127, 407, 662, 5259, 1175, 2...   \n",
            "123                               [125, 22519, 7, 954]   \n",
            "125  [6041, 6700, 6519, 154, 2534, 24940, 24913, 98...   \n",
            "\n",
            "                                             after_emb  \\\n",
            "26                           [896, 0, 24925, 0, 11005]   \n",
            "43   [27, 1764, 24935, 0, 24925, 0, 882, 9179, 9310...   \n",
            "112  [896, 5623, 36, 14432, 5992, 24934, 276, 7, 25...   \n",
            "123  [896, 0, 24925, 0, 24925, 0, 125, 22519, 24937...   \n",
            "125  [896, 326, 3395, 3024, 130, 14408, 101, 24500,...   \n",
            "\n",
            "                                       BIO_labels_text  \\\n",
            "26   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
            "43   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
            "112  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
            "123  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
            "125  [2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
            "\n",
            "                                          question_emb  \\\n",
            "26            [391, 73, 8062, 1316, 2355, 1818, 24967]   \n",
            "43   [305, 73, 7, 266, 7878, 3526, 4791, 72, 3608, ...   \n",
            "112          [391, 80, 7, 5623, 200, 1938, 483, 24967]   \n",
            "123                       [305, 8476, 5908, 98, 24967]   \n",
            "125         [1294, 549, 6041, 6700, 6519, 6122, 24967]   \n",
            "\n",
            "                                   BIO_labels_question  \n",
            "26   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
            "43   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
            "112  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
            "123  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
            "125  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
            "\n",
            "[5 rows x 26 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-55bbb6f573b0>:34: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"merged_emb\"] = df.apply(lambda row: row[\"question_emb\"] + row[\"question_pad\"] + row[\"before_emb\"] + row[\"answer_emb\"] + row[\"after_emb\"] + row[\"text_pad\"], axis=1)\n",
            "<ipython-input-42-55bbb6f573b0>:35: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"BIO_labels\"] = df.apply(lambda row: row[\"BIO_labels_question\"] + row[\"BIO_labels_text\"], axis=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_train_merged"
      ],
      "metadata": {
        "id": "BLJUolC0XlsO",
        "outputId": "3b326fa8-f67d-4453-a36a-f80cc5a72840",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text  \\\n",
              "26      [391, 73, 8062, 1316, 2355, 1818, 24967, 24999...   \n",
              "43      [305, 73, 7, 266, 7878, 3526, 4791, 72, 3608, ...   \n",
              "112     [391, 80, 7, 5623, 200, 1938, 483, 24967, 2499...   \n",
              "123     [305, 8476, 5908, 98, 24967, 24999, 24999, 249...   \n",
              "125     [1294, 549, 6041, 6700, 6519, 6122, 24967, 249...   \n",
              "...                                                   ...   \n",
              "116000  [1294, 73, 9472, 10355, 24937, 11121, 2083, 43...   \n",
              "116012  [305, 154, 7, 607, 434, 1689, 2080, 15550, 249...   \n",
              "116027  [305, 73, 12097, 7243, 72, 7, 266, 1401, 3627,...   \n",
              "116055  [305, 1818, 7, 266, 5809, 1291, 19766, 6076, 2...   \n",
              "116066  [1294, 80, 7, 792, 27, 5335, 21485, 24934, 154...   \n",
              "\n",
              "                                               answerable  \n",
              "26      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "43      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "112     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "123     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "125     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "...                                                   ...  \n",
              "116000  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "116012  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "116027  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "116055  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "116066  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "\n",
              "[7389 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c9ee3702-951b-420c-bef9-1fcb848afe22\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>answerable</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>[391, 73, 8062, 1316, 2355, 1818, 24967, 24999...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>[305, 73, 7, 266, 7878, 3526, 4791, 72, 3608, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>[391, 80, 7, 5623, 200, 1938, 483, 24967, 2499...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>[305, 8476, 5908, 98, 24967, 24999, 24999, 249...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>[1294, 549, 6041, 6700, 6519, 6122, 24967, 249...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116000</th>\n",
              "      <td>[1294, 73, 9472, 10355, 24937, 11121, 2083, 43...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116012</th>\n",
              "      <td>[305, 154, 7, 607, 434, 1689, 2080, 15550, 249...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116027</th>\n",
              "      <td>[305, 73, 12097, 7243, 72, 7, 266, 1401, 3627,...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116055</th>\n",
              "      <td>[305, 1818, 7, 266, 5809, 1291, 19766, 6076, 2...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116066</th>\n",
              "      <td>[1294, 80, 7, 792, 27, 5335, 21485, 24934, 154...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7389 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c9ee3702-951b-420c-bef9-1fcb848afe22')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c9ee3702-951b-420c-bef9-1fcb848afe22 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c9ee3702-951b-420c-bef9-1fcb848afe22');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-43eaddb1-fa9d-48f6-9961-3ccef9f793b9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-43eaddb1-fa9d-48f6-9961-3ccef9f793b9')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-43eaddb1-fa9d-48f6-9961-3ccef9f793b9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = bpemb_id\n",
        "english_val, english_val_merged = pre_process_df(df_val_english, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sozfR2m4SoUr",
        "outputId": "d76edf6f-491c-42a2-d8fd-e151a2b40b52"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-55bbb6f573b0>:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[[\"before\", \"answer\", \"after\"]] = df.apply(split_text_with_answer, axis=1)\n",
            "<ipython-input-42-55bbb6f573b0>:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[[\"before\", \"answer\", \"after\"]] = df.apply(split_text_with_answer, axis=1)\n",
            "<ipython-input-42-55bbb6f573b0>:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[[\"before\", \"answer\", \"after\"]] = df.apply(split_text_with_answer, axis=1)\n",
            "<ipython-input-42-55bbb6f573b0>:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[[\"before_emb\", \"answer_emb\", \"after_emb\"]] = df.apply(lambda row: make_emb(row, tokenizer), axis=1)\n",
            "<ipython-input-42-55bbb6f573b0>:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[[\"before_emb\", \"answer_emb\", \"after_emb\"]] = df.apply(lambda row: make_emb(row, tokenizer), axis=1)\n",
            "<ipython-input-42-55bbb6f573b0>:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[[\"before_emb\", \"answer_emb\", \"after_emb\"]] = df.apply(lambda row: make_emb(row, tokenizer), axis=1)\n",
            "<ipython-input-42-55bbb6f573b0>:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"text_pad\"] = df.apply(lambda row: [PADID] * (max_len - (len(row[\"before_emb\"]) + len(row[\"answer_emb\"]) + len(row[\"after_emb\"]))), axis=1)\n",
            "<ipython-input-42-55bbb6f573b0>:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"BIO_labels_text\"] = df.apply(create_BIO_labels_text, axis=1)\n",
            "<ipython-input-42-55bbb6f573b0>:27: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"question_emb\"] = df.apply(lambda row: tokenizer.encode_ids(row[\"question_text\"]), axis=1)\n",
            "<ipython-input-42-55bbb6f573b0>:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"question_pad\"] = df.apply(lambda row: [PADID] * (max_len_questions - len(row[\"question_emb\"])), axis=1)\n",
            "<ipython-input-42-55bbb6f573b0>:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"BIO_labels_question\"] = df.apply(lambda row: [0] * max_len_questions, axis=1)\n",
            "<ipython-input-42-55bbb6f573b0>:34: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"merged_emb\"] = df.apply(lambda row: row[\"question_emb\"] + row[\"question_pad\"] + row[\"before_emb\"] + row[\"answer_emb\"] + row[\"after_emb\"] + row[\"text_pad\"], axis=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         question_text  \\\n",
            "30   What is a way to increase your wound healing s...   \n",
            "47   Who founded the Burntisland Shipbuilding Company?   \n",
            "59       What is the surface area of the human cortex?   \n",
            "77   When did the case of R (Factortame Ltd) v Secr...   \n",
            "106                      When was Quezon City founded?   \n",
            "\n",
            "                                        document_title language  \\\n",
            "30                                       Wound healing  english   \n",
            "47                    Burntisland Shipbuilding Company  english   \n",
            "59                                     Cerebral cortex  english   \n",
            "77   R (Factortame Ltd) v Secretary of State for Tr...  english   \n",
            "106                                        Quezon City  english   \n",
            "\n",
            "                                           annotations  \\\n",
            "30   {'answer_start': [51], 'answer_text': ['cleani...   \n",
            "47   {'answer_start': [0], 'answer_text': ['Brother...   \n",
            "59   {'answer_start': [295], 'answer_text': ['2.3–2...   \n",
            "77   {'answer_start': [352], 'answer_text': ['Decem...   \n",
            "106    {'answer_start': [32], 'answer_text': ['1939']}   \n",
            "\n",
            "                                    document_plaintext  \\\n",
            "30   Wound care encourages and speeds wound healing...   \n",
            "47   Brothers Amos and Wilfrid Ayre founded Burntis...   \n",
            "59   For species of mammals, larger brains (in abso...   \n",
            "77   As from 31 March 1989, fishing vessel registra...   \n",
            "106  When Quezon City was created in 1939, the foll...   \n",
            "\n",
            "                                          document_url  \\\n",
            "30       https://en.wikipedia.org/wiki/Wound%20healing   \n",
            "47   https://en.wikipedia.org/wiki/Burntisland%20Sh...   \n",
            "59     https://en.wikipedia.org/wiki/Cerebral%20cortex   \n",
            "77   https://en.wikipedia.org/wiki/R%20%28Factortam...   \n",
            "106        https://en.wikipedia.org/wiki/Quezon%20City   \n",
            "\n",
            "                                                before  \\\n",
            "30   Wound care encourages and speeds wound healing...   \n",
            "47                                                       \n",
            "59   For species of mammals, larger brains (in abso...   \n",
            "77   As from 31 March 1989, fishing vessel registra...   \n",
            "106                   When Quezon City was created in    \n",
            "\n",
            "                                                answer  \\\n",
            "30   cleaning and protection from reinjury or infec...   \n",
            "47                      Brothers Amos and Wilfrid Ayre   \n",
            "59                                           2.3–2.8mm   \n",
            "77                                       December 1988   \n",
            "106                                               1939   \n",
            "\n",
            "                                                 after  \\\n",
            "30   . Depending on each patient's needs, it can ra...   \n",
            "47    founded Burntisland Shipbuilding Co. in 1918 ...   \n",
            "59   . There is an approximately logarithmic relati...   \n",
            "77                                                   .   \n",
            "106  , the following barrios or sitios: Balingasa, ...   \n",
            "\n",
            "                                            before_emb  \\\n",
            "30   [11633, 1237, 21280, 34, 11044, 11633, 14546, ...   \n",
            "47                                                  []   \n",
            "59   [72, 1878, 27, 11978, 24934, 2818, 1367, 555, ...   \n",
            "77   [79, 130, 39, 1080, 162, 6185, 7584, 8861, 664...   \n",
            "106              [391, 1675, 13628, 470, 73, 1648, 26]   \n",
            "\n",
            "                                            answer_emb  \\\n",
            "30   [16179, 34, 3938, 130, 4428, 24943, 588, 127, ...   \n",
            "47            [3746, 22064, 34, 2044, 17139, 6657, 12]   \n",
            "59                             [1672, 1873, 246, 6901]   \n",
            "77                                          [1254, 52]   \n",
            "106                                               [52]   \n",
            "\n",
            "                                             after_emb  \\\n",
            "30   [896, 5551, 71, 882, 7641, 24937, 24920, 5262,...   \n",
            "47   [2027, 16416, 20272, 17921, 381, 24935, 26, 52...   \n",
            "59   [896, 351, 80, 32, 3047, 23365, 92, 4917, 2658...   \n",
            "77                                               [896]   \n",
            "106  [1749, 7, 939, 735, 129, 113, 127, 1512, 2765,...   \n",
            "\n",
            "                                              text_pad  \\\n",
            "30   [24999, 24999, 24999, 24999, 24999, 24999, 249...   \n",
            "47   [24999, 24999, 24999, 24999, 24999, 24999, 249...   \n",
            "59   [24999, 24999, 24999, 24999, 24999, 24999, 249...   \n",
            "77   [24999, 24999, 24999, 24999, 24999, 24999, 249...   \n",
            "106  [24999, 24999, 24999, 24999, 24999, 24999, 249...   \n",
            "\n",
            "                                       BIO_labels_text  \\\n",
            "30   [0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 1, 1, ...   \n",
            "47   [2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
            "59   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
            "77   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
            "106  [0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, ...   \n",
            "\n",
            "                                          question_emb  \\\n",
            "30   [1294, 80, 4, 1104, 42, 3130, 3285, 11633, 145...   \n",
            "47     [305, 2027, 7, 16416, 20272, 17921, 901, 24967]   \n",
            "59   [1294, 80, 7, 3008, 755, 27, 7, 1549, 17884, 2...   \n",
            "77   [391, 994, 7, 1739, 27, 104, 64, 24928, 301, 1...   \n",
            "106           [391, 73, 1675, 13628, 470, 2027, 24967]   \n",
            "\n",
            "                                          question_pad  \\\n",
            "30   [24999, 24999, 24999, 24999, 24999, 24999, 249...   \n",
            "47   [24999, 24999, 24999, 24999, 24999, 24999, 249...   \n",
            "59   [24999, 24999, 24999, 24999, 24999, 24999, 249...   \n",
            "77   [24999, 24999, 24999, 24999, 24999, 24999, 249...   \n",
            "106  [24999, 24999, 24999, 24999, 24999, 24999, 249...   \n",
            "\n",
            "                                   BIO_labels_question  \n",
            "30   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
            "47   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
            "59   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
            "77   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
            "106  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-55bbb6f573b0>:35: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"BIO_labels\"] = df.apply(lambda row: row[\"BIO_labels_question\"] + row[\"BIO_labels_text\"], axis=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This will load the dataset and process it lazily in the __getitem__ function\n",
        "class ClassificationDatasetReader(Dataset):\n",
        "  def __init__(self, df):\n",
        "    self.df = df\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    row = self.df.values[idx]\n",
        "    # Calls the text_to_batch function\n",
        "    input_ids,seq_lens = row[0], len(row[0])\n",
        "    label = row[1]\n",
        "    return input_ids, seq_lens, label"
      ],
      "metadata": {
        "id": "RcYILXgMrH4x"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = ClassificationDatasetReader(english_train_merged)\n",
        "valid_dataset = ClassificationDatasetReader(english_val_merged)\n",
        "train_dataset.__getitem__(26)[1]"
      ],
      "metadata": {
        "id": "YlUEf-VDYT-n",
        "outputId": "3476826b-a18e-49d3-cd99-b472ac5db8a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3900"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_dataset = (english_train_merged[\"text\"], len(english_train_merged[\"text\"]), english_train_merged[\"answerable\"])\n",
        "#valid_dataset = (english_val_merged[\"text\"], len(english_val_merged[\"text\"]), english_val_merged[\"answerable\"])\n",
        "#train_dataset"
      ],
      "metadata": {
        "id": "zHhSBy5FYskb"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch_bilstm(input_data: Tuple) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "\n",
        "    input_ids = [i[0] for i in input_data]\n",
        "\n",
        "\n",
        "    seq_lens = [i[1] for i in input_data]\n",
        "    labels = [i[2] for i in input_data]\n",
        "\n",
        "    max_length = max([len(i) for i in input_ids])\n",
        "\n",
        "    input_ids = [(i + [0] * (max_length - len(i))) for i in input_ids]\n",
        "    labels = [(i + [0] * (max_length - len(i))) for i in labels] # 0 is the id of the O tag\n",
        "\n",
        "    assert (all(len(i) == max_length for i in input_ids))\n",
        "    assert (all(len(i) == max_length for i in labels))\n",
        "    return torch.tensor(input_ids), torch.tensor(seq_lens), torch.tensor(labels)"
      ],
      "metadata": {
        "id": "YZdJue4ocmKl"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch_bilstm, num_workers=n_workers)\n",
        "valid_dl = DataLoader(valid_dataset, batch_size=len(valid_dataset), collate_fn=collate_batch_bilstm, num_workers=n_workers)\n",
        "\n",
        "# Create the optimizer\n",
        "optimizer = Adam(model.parameters(), lr=lr)\n",
        "scheduler = CyclicLR(optimizer, base_lr=0., max_lr=lr, step_size_up=1, step_size_down=len(train_dl)*n_epochs, cycle_momentum=False)\n",
        "\n",
        "# Train\n",
        "losses, learning_rates = train(model, train_dl, valid_dl, optimizer, n_epochs, device, scheduler)\n",
        "model.load_state_dict(torch.load('best_model'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b390f7dc8ae843be9026d187f425c49d",
            "8e085ffb79b147b5a556114d74d8edc0",
            "6af80426e41c4bd595e4c4b10340586e",
            "a575d90a25b54cdbabb387a4552839e1",
            "72722895900442498a55a7682acb45cc",
            "968b4f788c864012b566a8d6a258e291",
            "7f4c3332b5774c578e54e8f4f2eb7592",
            "bdc69eaa6e884eb48444a6be1ddb031a",
            "f053e2f7d9624b9eb44cc7c554c46d00",
            "b457b227d7e8435980b1c301e5cbccca",
            "066bd0b8935543dc985cd5671eb8ac82"
          ]
        },
        "id": "jGum441qNys9",
        "outputId": "10cc10db-2460-4f6a-fc16-7e63f1038b29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/924 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b390f7dc8ae843be9026d187f425c49d"
            }
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "accelerator": "TPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b390f7dc8ae843be9026d187f425c49d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e085ffb79b147b5a556114d74d8edc0",
              "IPY_MODEL_6af80426e41c4bd595e4c4b10340586e",
              "IPY_MODEL_a575d90a25b54cdbabb387a4552839e1"
            ],
            "layout": "IPY_MODEL_72722895900442498a55a7682acb45cc"
          }
        },
        "8e085ffb79b147b5a556114d74d8edc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_968b4f788c864012b566a8d6a258e291",
            "placeholder": "​",
            "style": "IPY_MODEL_7f4c3332b5774c578e54e8f4f2eb7592",
            "value": "  0%"
          }
        },
        "6af80426e41c4bd595e4c4b10340586e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdc69eaa6e884eb48444a6be1ddb031a",
            "max": 924,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f053e2f7d9624b9eb44cc7c554c46d00",
            "value": 0
          }
        },
        "a575d90a25b54cdbabb387a4552839e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b457b227d7e8435980b1c301e5cbccca",
            "placeholder": "​",
            "style": "IPY_MODEL_066bd0b8935543dc985cd5671eb8ac82",
            "value": " 0/924 [00:00&lt;?, ?it/s]"
          }
        },
        "72722895900442498a55a7682acb45cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "968b4f788c864012b566a8d6a258e291": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f4c3332b5774c578e54e8f4f2eb7592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bdc69eaa6e884eb48444a6be1ddb031a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f053e2f7d9624b9eb44cc7c554c46d00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b457b227d7e8435980b1c301e5cbccca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "066bd0b8935543dc985cd5671eb8ac82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}