{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"a04b37c4d9f6435b890871efd07d9791":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bb8f9cd627bf45faba45064daf6d9fe7","IPY_MODEL_d7e92c863cea4d22b287f05dc736cc5f","IPY_MODEL_4ef154da01714dcb87896670bf4fafb5"],"layout":"IPY_MODEL_9ee12ca403c34496a7fcad535d4a6a55"}},"bb8f9cd627bf45faba45064daf6d9fe7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_71974ff1c179469aaf2eb1e9072d8d34","placeholder":"​","style":"IPY_MODEL_470f80a1f575411d84c05d19f0d1a930","value":"Downloading builder script: "}},"d7e92c863cea4d22b287f05dc736cc5f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6903c954a78740a8bf709a850f609919","max":2318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7c0e603c53344af3b0a30b5b327687b7","value":2318}},"4ef154da01714dcb87896670bf4fafb5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b681fb8f59984685bdf972dcbfcfb8d8","placeholder":"​","style":"IPY_MODEL_0ec945adbe27451bbb49fcc117e8f994","value":" 6.50k/? [00:00&lt;00:00, 186kB/s]"}},"9ee12ca403c34496a7fcad535d4a6a55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71974ff1c179469aaf2eb1e9072d8d34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"470f80a1f575411d84c05d19f0d1a930":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6903c954a78740a8bf709a850f609919":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c0e603c53344af3b0a30b5b327687b7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b681fb8f59984685bdf972dcbfcfb8d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ec945adbe27451bbb49fcc117e8f994":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95ee5c570c4c4ebd8bf0bdd793474ac6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0f3030315c83420d9f2169bed3b4d856","IPY_MODEL_d683e315b32442468a52c4acbaf74387","IPY_MODEL_5079479109284ca8a48a4a589a6a76fe"],"layout":"IPY_MODEL_c9c17e41ae3a40ecb13ca7693e0869c4"}},"0f3030315c83420d9f2169bed3b4d856":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc9084990e9d4b5c885c86157426dad9","placeholder":"​","style":"IPY_MODEL_12f58ce5b37c4c309e157af0ec2c02f3","value":"Downloading builder script: "}},"d683e315b32442468a52c4acbaf74387":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_88f6834e965b452fb9e47d8b2c80e0c7","max":1652,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3158617ca7764ab1aeb3f66db610b8c9","value":1652}},"5079479109284ca8a48a4a589a6a76fe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b79f1ee02b9145fe8b6a22263bd040db","placeholder":"​","style":"IPY_MODEL_059496274b834815b221845de52edf3d","value":" 4.21k/? [00:00&lt;00:00, 78.8kB/s]"}},"c9c17e41ae3a40ecb13ca7693e0869c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc9084990e9d4b5c885c86157426dad9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12f58ce5b37c4c309e157af0ec2c02f3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"88f6834e965b452fb9e47d8b2c80e0c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3158617ca7764ab1aeb3f66db610b8c9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b79f1ee02b9145fe8b6a22263bd040db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"059496274b834815b221845de52edf3d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets\n!pip install update transformers","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X72usktzzUIF","outputId":"48a0d415-7e07-48bd-adf5-d45450fbd534","execution":{"iopub.status.busy":"2023-10-27T11:12:20.091917Z","iopub.execute_input":"2023-10-27T11:12:20.092377Z","iopub.status.idle":"2023-10-27T11:12:44.615902Z","shell.execute_reply.started":"2023-10-27T11:12:20.092346Z","shell.execute_reply":"2023-10-27T11:12:44.614495Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.23.5)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.3.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.9.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nCollecting update\n  Downloading update-0.0.1-py2.py3-none-any.whl (2.9 kB)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.33.0)\nCollecting style==1.1.0 (from update)\n  Downloading style-1.1.0-py2.py3-none-any.whl (6.4 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\nInstalling collected packages: style, update\nSuccessfully installed style-1.1.0 update-0.0.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()","metadata":{"id":"n-hknPNiFPQ0","execution":{"iopub.status.busy":"2023-10-27T11:12:44.618005Z","iopub.execute_input":"2023-10-27T11:12:44.618346Z","iopub.status.idle":"2023-10-27T11:12:44.623109Z","shell.execute_reply.started":"2023-10-27T11:12:44.618311Z","shell.execute_reply":"2023-10-27T11:12:44.622257Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom collections import Counter\nimport torch\nimport datasets\ndatasets.logging.set_verbosity_error()\nfrom datasets import load_metric\n# from google.colab import drive\nfrom transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModelForSequenceClassification\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.metrics import f1_score\nimport pandas as pd\nimport random\n\nfrom sklearn.model_selection import train_test_split\nfrom transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\nfrom tqdm import tqdm\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom transformers import BertTokenizer, BertModel\n\n\n# # uncomment if CAN'T CONNECT TO GPU\n# import psutil\n# import platform","metadata":{"id":"erIIBBN-ebGV","execution":{"iopub.status.busy":"2023-10-27T11:12:44.624596Z","iopub.execute_input":"2023-10-27T11:12:44.624897Z","iopub.status.idle":"2023-10-27T11:12:44.638792Z","shell.execute_reply.started":"2023-10-27T11:12:44.624872Z","shell.execute_reply":"2023-10-27T11:12:44.637757Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# add-in as occasionally receive an error which requires this to be added\n# uncomment if the issue arises\n!pip install accelerate -U","metadata":{"id":"j1FeucwT_K-N","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b5e63226-7ca8-4bcd-c271-57de8c0aea52","execution":{"iopub.status.busy":"2023-10-27T11:12:44.641899Z","iopub.execute_input":"2023-10-27T11:12:44.642246Z","iopub.status.idle":"2023-10-27T11:12:56.732299Z","shell.execute_reply.started":"2023-10-27T11:12:44.642216Z","shell.execute_reply":"2023-10-27T11:12:56.731020Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.22.0)\nCollecting accelerate\n  Downloading accelerate-0.24.0-py3-none-any.whl (260 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.0/261.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.0.0)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.16.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2023.9.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.22.0\n    Uninstalling accelerate-0.22.0:\n      Successfully uninstalled accelerate-0.22.0\nSuccessfully installed accelerate-0.24.0\n","output_type":"stream"}]},{"cell_type":"code","source":"def enforce_reproducibility(seed=42):\n    # Sets seed manually for both CPU and CUDA\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    # For atomic operations there is currently\n    # no simple way to enforce determinism, as\n    # the order of parallel operations is not known.\n    # CUDNN\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    # System based\n    random.seed(seed)\n    np.random.seed(seed)\n\ndevice = torch.device(\"cpu\")\nif torch.cuda.is_available():\n  device = torch.device(\"cuda\")\n\nenforce_reproducibility()","metadata":{"id":"6T11MhtBdv1P","execution":{"iopub.status.busy":"2023-10-27T11:12:56.734077Z","iopub.execute_input":"2023-10-27T11:12:56.734520Z","iopub.status.idle":"2023-10-27T11:12:56.744068Z","shell.execute_reply.started":"2023-10-27T11:12:56.734479Z","shell.execute_reply":"2023-10-27T11:12:56.743312Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Preamble\nimport sys\n\nsys.path.append('..')","metadata":{"id":"AheXHlZxQ38o","execution":{"iopub.status.busy":"2023-10-27T11:12:56.745228Z","iopub.execute_input":"2023-10-27T11:12:56.745568Z","iopub.status.idle":"2023-10-27T11:12:56.753876Z","shell.execute_reply.started":"2023-10-27T11:12:56.745535Z","shell.execute_reply":"2023-10-27T11:12:56.753172Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{"id":"At8Cui50l5Q0"}},{"cell_type":"code","source":"from datasets import load_dataset\nimport pandas as pd\n\ndataset = load_dataset(\"copenlu/answerable_tydiqa\")\n\ntrain_set = dataset[\"train\"]\nvalidation_set = dataset[\"validation\"]\n\ndf_train = train_set.to_pandas()\ndf_val = validation_set.to_pandas()","metadata":{"id":"8Z5S6IwPQ38o","execution":{"iopub.status.busy":"2023-10-27T11:12:56.754817Z","iopub.execute_input":"2023-10-27T11:12:56.755389Z","iopub.status.idle":"2023-10-27T11:13:01.978491Z","shell.execute_reply.started":"2023-10-27T11:12:56.755364Z","shell.execute_reply":"2023-10-27T11:13:01.977690Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/2.47k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d07a99ccf6e43cdb7d2c2d597e0bb28"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset None/None (download: 75.43 MiB, generated: 131.78 MiB, post-processed: Unknown size, total: 207.21 MiB) to /root/.cache/huggingface/datasets/parquet/copenlu--nlp_course_tydiqa-42333912ea665dd0/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb2e1e0924fa436f8b025cbe8f440991"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/71.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"812dbc12d5504346b7e8ed3a1a6b08ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/7.49M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f6ac04d562542f0a75845a8f9fad740"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac839e1454704ed1af9807b1d8d5aa04"}},"metadata":{}},{"name":"stdout","text":"Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/copenlu--nlp_course_tydiqa-42333912ea665dd0/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff1aae51a1364c8c91617c26bbf91128"}},"metadata":{}}]},{"cell_type":"code","source":"# Get train and validation data for each language\ndf_train_bengali = df_train[df_train['language'] == 'bengali']\ndf_train_arabic = df_train[df_train['language'] == 'arabic']\ndf_train_indonesian = df_train[df_train['language'] == 'indonesian']\n\ndf_val_bengali = df_val[df_val['language'] == 'bengali']\ndf_val_arabic = df_val[df_val['language'] == 'arabic']\ndf_val_indonesian = df_val[df_val['language'] == 'indonesian']\n\n\n# For testing\ndf_val_english = df_val[df_val['language'] == 'english']\ndf_train_english = df_train[df_train['language'] == 'english']\n","metadata":{"id":"15Hvm5s-Q38p","execution":{"iopub.status.busy":"2023-10-27T11:13:01.979619Z","iopub.execute_input":"2023-10-27T11:13:01.979907Z","iopub.status.idle":"2023-10-27T11:13:02.078455Z","shell.execute_reply.started":"2023-10-27T11:13:01.979883Z","shell.execute_reply":"2023-10-27T11:13:02.077556Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Create a new dataframe with the combined documents and questions and add if they are answerable\ndf_train_bengali_merged = pd.DataFrame({\n    'text':df_train_bengali[\"document_plaintext\"],\n    'question': df_train_bengali[\"question_text\"],\n    'answerable':(df_train_bengali[\"annotations\"].apply(lambda x: 0 if x['answer_start'] == [-1] else 1))\n    })\ndf_train_arabic_merged = pd.DataFrame({\n    'text': df_train_arabic[\"document_plaintext\"],\n    'question': df_train_arabic[\"question_text\"],\n    'answerable': (df_train_arabic[\"annotations\"].apply(lambda x: 0 if x['answer_start'] == [-1] else 1))\n                                    })\ndf_train_indonesian_merged = pd.DataFrame({\n    'text':df_train_indonesian[\"document_plaintext\"],\n    'question': df_train_indonesian[\"question_text\"],\n    'answerable':(df_train_indonesian[\"annotations\"].apply(lambda x: 0 if x['answer_start'] == [-1] else 1))\n    })\ndf_train_english_merged = pd.DataFrame({\n    'text':df_train_english[\"document_plaintext\"],\n    'question': df_train_english[\"question_text\"],\n    'answerable':(df_train_english[\"annotations\"].apply(lambda x: 0 if x['answer_start'] == [-1] else 1))\n    })\n\n\n## Same for validation data\ndf_val_bengali_merged = pd.DataFrame({\n    'text':df_val_bengali[\"document_plaintext\"],\n    'question': df_val_bengali[\"question_text\"],\n    'answerable':(df_val_bengali[\"annotations\"].apply(lambda x: 0 if x['answer_start'] == [-1] else 1))\n    })\ndf_val_arabic_merged = pd.DataFrame({\n    'text': df_val_arabic[\"document_plaintext\"],\n    'question': df_val_arabic[\"question_text\"],\n    'answerable': (df_val_arabic[\"annotations\"].apply(lambda x: 0 if x['answer_start'] == [-1] else 1))\n                                    })\ndf_val_indonesian_merged = pd.DataFrame({\n    'text':df_val_indonesian[\"document_plaintext\"],\n    'question': df_val_indonesian[\"question_text\"],\n    'answerable':(df_val_indonesian[\"annotations\"].apply(lambda x: 0 if x['answer_start'] == [-1] else 1))\n    })\ndf_val_english_merged = pd.DataFrame({\n    'text':df_val_english[\"document_plaintext\"],\n    'question':  df_val_english[\"question_text\"],\n    'answerable':(df_val_english[\"annotations\"].apply(lambda x: 0 if x['answer_start'] == [-1] else 1))\n    })","metadata":{"id":"WyIm3zKzQ38p","execution":{"iopub.status.busy":"2023-10-27T11:13:02.079512Z","iopub.execute_input":"2023-10-27T11:13:02.079761Z","iopub.status.idle":"2023-10-27T11:13:02.349375Z","shell.execute_reply.started":"2023-10-27T11:13:02.079740Z","shell.execute_reply":"2023-10-27T11:13:02.348595Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Tokenization of text","metadata":{"id":"xcOyi2Oal-Em"}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n\ndef tokenize_text(df, max_length=128):\n    input_ids = []\n    attention_masks = []\n\n#     for row in df.iterrows():\n    encoded_text = tokenizer(\n        df[\"question\"].tolist(),\n        df[\"text\"].tolist(),\n        max_length=max_length,\n        padding=\"max_length\",\n        truncation='only_second',\n        return_attention_mask=True,\n        return_tensors=\"pt\"\n    )\n#         input_ids.append(encoded_text[\"input_ids\"])\n#         attention_masks.append(encoded_text[\"attention_mask\"])\n\n#     input_ids = torch.cat(input_ids, dim=0)\n#     attention_masks = torch.cat(attention_masks, dim=0)\n\n#     return input_ids, attention_masks\n    return encoded_text\n","metadata":{"id":"udS3DYSa06OW","execution":{"iopub.status.busy":"2023-10-27T11:13:02.352966Z","iopub.execute_input":"2023-10-27T11:13:02.353252Z","iopub.status.idle":"2023-10-27T11:13:03.597037Z","shell.execute_reply.started":"2023-10-27T11:13:02.353229Z","shell.execute_reply":"2023-10-27T11:13:03.596266Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2254b361fac84f5ea91a1da47fef6a64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21ce3fc073984b298ceb1f4d91e8a502"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2995cb257b9343bf8cd3035555cea312"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f32faddda3740caa981e83c3ed40ec3"}},"metadata":{}}]},{"cell_type":"markdown","source":"Defining model, training arguments and compute metrics","metadata":{"id":"bj13KazcmDNK"}},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)\nmodel.cuda()  # Use GPU for training\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UxJP_aEc2dPw","outputId":"53d564d9-52a1-452e-e5df-b445fc5839fb","execution":{"iopub.status.busy":"2023-10-27T11:13:03.598172Z","iopub.execute_input":"2023-10-27T11:13:03.598472Z","iopub.status.idle":"2023-10-27T11:13:08.425227Z","shell.execute_reply.started":"2023-10-27T11:13:03.598447Z","shell.execute_reply":"2023-10-27T11:13:08.424192Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a34c35735a164d85aaea1c1d0f491693"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"#define parameters for the model  - used for all models\ntraining_args = TrainingArguments(output_dir=\"my_trainer\",\n                                  evaluation_strategy=\"steps\",\n                                  num_train_epochs=3.0,\n                                  per_device_train_batch_size=16,\n                                  eval_steps=500\n                                  )","metadata":{"id":"pWD-6Sw1MZ4N","execution":{"iopub.status.busy":"2023-10-27T11:13:08.426291Z","iopub.execute_input":"2023-10-27T11:13:08.426562Z","iopub.status.idle":"2023-10-27T11:13:08.436976Z","shell.execute_reply.started":"2023-10-27T11:13:08.426539Z","shell.execute_reply":"2023-10-27T11:13:08.436053Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# define the compute_metrics function for the trainer\nmetric_f1 = load_metric('f1')\nmetric_ac = load_metric('accuracy')\n\ndef compute_metrics(eval_pred):\n    outputs, labels = eval_pred\n    predictions = np.argmax(outputs, axis=-1)\n    f1 = metric_f1.compute(predictions=predictions, references=labels)\n    ac = metric_ac.compute(predictions=predictions, references=labels)\n    return f1 | ac","metadata":{"id":"rvB-DPQ22w0o","outputId":"729a3adc-0f3f-4a04-b62f-9f42f16e4195","colab":{"base_uri":"https://localhost:8080/","height":136,"referenced_widgets":["a04b37c4d9f6435b890871efd07d9791","bb8f9cd627bf45faba45064daf6d9fe7","d7e92c863cea4d22b287f05dc736cc5f","4ef154da01714dcb87896670bf4fafb5","9ee12ca403c34496a7fcad535d4a6a55","71974ff1c179469aaf2eb1e9072d8d34","470f80a1f575411d84c05d19f0d1a930","6903c954a78740a8bf709a850f609919","7c0e603c53344af3b0a30b5b327687b7","b681fb8f59984685bdf972dcbfcfb8d8","0ec945adbe27451bbb49fcc117e8f994","95ee5c570c4c4ebd8bf0bdd793474ac6","0f3030315c83420d9f2169bed3b4d856","d683e315b32442468a52c4acbaf74387","5079479109284ca8a48a4a589a6a76fe","c9c17e41ae3a40ecb13ca7693e0869c4","bc9084990e9d4b5c885c86157426dad9","12f58ce5b37c4c309e157af0ec2c02f3","88f6834e965b452fb9e47d8b2c80e0c7","3158617ca7764ab1aeb3f66db610b8c9","b79f1ee02b9145fe8b6a22263bd040db","059496274b834815b221845de52edf3d"]},"execution":{"iopub.status.busy":"2023-10-27T11:13:08.438102Z","iopub.execute_input":"2023-10-27T11:13:08.438394Z","iopub.status.idle":"2023-10-27T11:13:09.610586Z","shell.execute_reply.started":"2023-10-27T11:13:08.438371Z","shell.execute_reply":"2023-10-27T11:13:09.609761Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.06k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dec9acfff74e40b9ae9d5652f3a817ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.41k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"586a378102e643f2b5dc292d5c9678e4"}},"metadata":{}}]},{"cell_type":"markdown","source":"### English version - delete? + delete trainer objects as i dont use them?","metadata":{"id":"DI0QTEWDmKH_"}},{"cell_type":"code","source":"# # In English - for testing\n\n# train_tokenized_text = tokenize_text(df_train_english_merged)\n# val_tokenized_text = tokenize_text(df_val_english_merged)\n\n\n# train_input_ids = torch.cat([train_tokenized_text[\"input_ids\"]], dim=0)\n# train_attention_masks = torch.cat([train_tokenized_text[\"attention_mask\"]], dim=0) \n# val_input_ids = torch.cat([val_tokenized_text[\"input_ids\"]], dim=0)\n# val_attention_masks = torch.cat([val_tokenized_text[\"attention_mask\"]], dim=0)\n\n# train_labels = torch.tensor(df_train_english_merged[\"answerable\"].tolist())\n# val_labels = torch.tensor(df_val_english_merged[\"answerable\"].tolist())","metadata":{"id":"AkG265e-k50P","execution":{"iopub.status.busy":"2023-10-27T11:13:09.611566Z","iopub.execute_input":"2023-10-27T11:13:09.611828Z","iopub.status.idle":"2023-10-27T11:13:09.616497Z","shell.execute_reply.started":"2023-10-27T11:13:09.611805Z","shell.execute_reply":"2023-10-27T11:13:09.615527Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# # In English - for testing\n\n# batch_size = 32\n\n# train_data = TensorDataset(train_input_ids.to('cuda'), train_attention_masks.to('cuda'), train_labels.to('cuda'))\n# train_sampler = RandomSampler(train_data)\n# train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n\n# val_data = TensorDataset(val_input_ids.to('cuda'), val_attention_masks.to('cuda'), val_labels.to('cuda'))\n# val_sampler = SequentialSampler(val_data)\n# val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n\n","metadata":{"id":"ucz_nOHB2Hpu","execution":{"iopub.status.busy":"2023-10-27T11:13:09.617664Z","iopub.execute_input":"2023-10-27T11:13:09.617942Z","iopub.status.idle":"2023-10-27T11:13:09.627891Z","shell.execute_reply.started":"2023-10-27T11:13:09.617918Z","shell.execute_reply":"2023-10-27T11:13:09.627174Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# # define the trainer object - for English test dataset\n# trainer_eng = Trainer(\n#     model=model,\n#     args=training_args,\n#     train_dataset=train_data,\n#     eval_dataset=val_data,\n#     compute_metrics=compute_metrics,\n#     tokenizer=tokenizer\n# )","metadata":{"id":"4iRSttSd7Sub","execution":{"iopub.status.busy":"2023-10-27T11:13:09.629097Z","iopub.execute_input":"2023-10-27T11:13:09.629397Z","iopub.status.idle":"2023-10-27T11:13:09.637391Z","shell.execute_reply.started":"2023-10-27T11:13:09.629374Z","shell.execute_reply":"2023-10-27T11:13:09.636571Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# # for English testing version\n# optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n# epochs = 4\n# total_steps = len(train_dataloader) * epochs\n# scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n","metadata":{"id":"PAourslR2gAy","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d08a6252-144e-4f98-c7ec-a37ca6ade452","execution":{"iopub.status.busy":"2023-10-27T11:13:09.638431Z","iopub.execute_input":"2023-10-27T11:13:09.638760Z","iopub.status.idle":"2023-10-27T11:13:09.650535Z","shell.execute_reply.started":"2023-10-27T11:13:09.638727Z","shell.execute_reply":"2023-10-27T11:13:09.649684Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# # English verson - for testing\n\n# # Training loop\n# for epoch in range(epochs):\n#     model.train()\n#     total_loss = 0  # Initialize the total loss for the epoch\n\n#     for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}\"):\n#         inputs = batch[:2]\n#         labels = batch[2]\n\n#         model.zero_grad()\n#         outputs = model(*inputs, labels=labels)\n#         loss = outputs.loss\n#         total_loss += loss.item()  # Accumulate the loss\n#         loss.backward()\n#         torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n#         optimizer.step()\n#         scheduler.step()\n\n#     average_loss = total_loss / len(train_dataloader)  # Compute the average loss for the epoch\n\n#     model.eval()\n#     predictions = []\n#     true_labels = []\n#     for batch in tqdm(val_dataloader, desc=f\"Evaluating Epoch {epoch + 1}\"):\n#         inputs = batch[:2]\n#         labels = batch[2]\n#         with torch.no_grad():\n#             outputs = model(*inputs)\n#         logits = outputs.logits\n#         predictions.extend(logits.argmax(dim=1).tolist())\n#         true_labels.extend(labels.tolist())\n\n#     accuracy = accuracy_score(true_labels, predictions)\n#     report = classification_report(true_labels, predictions, target_names=[\"Not Answerable\", \"Answerable\"])\n#     print(f\"Epoch {epoch + 1} - Accuracy: {accuracy:.4f} - Average Loss: {average_loss:.4f}\")\n#     print(report)\n\n","metadata":{"id":"-9Gmsd6uX5Be","execution":{"iopub.status.busy":"2023-10-27T11:13:09.651753Z","iopub.execute_input":"2023-10-27T11:13:09.652388Z","iopub.status.idle":"2023-10-27T11:13:09.661004Z","shell.execute_reply.started":"2023-10-27T11:13:09.652356Z","shell.execute_reply":"2023-10-27T11:13:09.660193Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"### Indonesian","metadata":{"id":"Af54UfImmcx8"}},{"cell_type":"code","source":"# For Indonesian\n\ntrain_tokenized_text_indonesian = tokenize_text(df_train_indonesian_merged)\nval_tokenized_text_indonesian = tokenize_text(df_val_indonesian_merged)\n\n\ntrain_input_ids_indonesian = torch.cat([train_tokenized_text_indonesian[\"input_ids\"]], dim=0)\ntrain_attention_masks_indonesian = torch.cat([train_tokenized_text_indonesian[\"attention_mask\"]], dim=0) \nval_input_ids_indonesian = torch.cat([val_tokenized_text_indonesian[\"input_ids\"]], dim=0)\nval_attention_masks_indonesian = torch.cat([val_tokenized_text_indonesian[\"attention_mask\"]], dim=0)\n\ntrain_labels_indonesian = torch.tensor(df_train_indonesian_merged[\"answerable\"].tolist())\nval_labels_indonesian = torch.tensor(df_val_indonesian_merged[\"answerable\"].tolist())\n\n\nbatch_size = 16\n\ntrain_data_indonesian = TensorDataset(train_input_ids_indonesian.to('cuda'), train_attention_masks_indonesian.to('cuda'), train_labels_indonesian.to('cuda'))\ntrain_sampler_indonesian = RandomSampler(train_data_indonesian)\ntrain_dataloader_indonesian = DataLoader(train_data_indonesian, sampler=train_sampler_indonesian, batch_size=batch_size)\n\nval_data_indonesian = TensorDataset(val_input_ids_indonesian.to('cuda'), val_attention_masks_indonesian.to('cuda'), val_labels_indonesian.to('cuda'))\nval_sampler_indonesian = SequentialSampler(val_data_indonesian)\nval_dataloader_indonesian = DataLoader(val_data_indonesian, sampler=val_sampler_indonesian, batch_size=batch_size)\n\n","metadata":{"id":"sEUUfCWN3p4j","execution":{"iopub.status.busy":"2023-10-27T11:13:09.662011Z","iopub.execute_input":"2023-10-27T11:13:09.662601Z","iopub.status.idle":"2023-10-27T11:13:13.589167Z","shell.execute_reply.started":"2023-10-27T11:13:09.662569Z","shell.execute_reply":"2023-10-27T11:13:13.588197Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# define the trainer object\ntrainer_indonesian = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data_indonesian,\n    eval_dataset=val_data_indonesian,\n    compute_metrics=compute_metrics,\n    tokenizer=tokenizer\n)","metadata":{"id":"b1p4wc2PJsId","execution":{"iopub.status.busy":"2023-10-27T11:13:13.590300Z","iopub.execute_input":"2023-10-27T11:13:13.590603Z","iopub.status.idle":"2023-10-27T11:13:13.622452Z","shell.execute_reply.started":"2023-10-27T11:13:13.590577Z","shell.execute_reply":"2023-10-27T11:13:13.621465Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\nepochs = 4\ntotal_steps = len(train_dataloader_indonesian) * epochs\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n","metadata":{"id":"bsKw_Dh6Js3U","execution":{"iopub.status.busy":"2023-10-27T11:13:13.623645Z","iopub.execute_input":"2023-10-27T11:13:13.623931Z","iopub.status.idle":"2023-10-27T11:13:13.687064Z","shell.execute_reply.started":"2023-10-27T11:13:13.623907Z","shell.execute_reply":"2023-10-27T11:13:13.686041Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"len(train_dataloader_indonesian)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T11:13:13.688417Z","iopub.execute_input":"2023-10-27T11:13:13.688715Z","iopub.status.idle":"2023-10-27T11:13:13.694905Z","shell.execute_reply.started":"2023-10-27T11:13:13.688691Z","shell.execute_reply":"2023-10-27T11:13:13.694013Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"713"},"metadata":{}}]},{"cell_type":"code","source":"model = model.to(\"cuda\")\n\n\n# Training loop\nfor epoch in range(epochs):\n    model.train()\n    total_loss = 0  # Initialize the total loss for the epoch\n\n    for batch in tqdm(train_dataloader_indonesian, desc=f\"Epoch {epoch + 1}\"):\n        inputs = batch[:2]\n        labels = batch[2]\n\n        model.zero_grad()\n        outputs = model(*inputs, labels=labels)\n        loss = outputs.loss\n        total_loss += loss.item()  # Accumulate the loss\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        scheduler.step()\n\n    average_loss = total_loss / len(train_dataloader_indonesian)  # Compute the average loss for the epoch\n\n    model.eval()\n    predictions = []\n    true_labels = []\n    for batch in tqdm(val_dataloader_indonesian, desc=f\"Evaluating Epoch {epoch + 1}\"):\n        inputs = batch[:2]\n        labels = batch[2]\n        with torch.no_grad():\n            outputs = model(*inputs)\n        logits = outputs.logits\n        predictions.extend(logits.argmax(dim=1).tolist())\n        true_labels.extend(labels.tolist())\n\n    accuracy = accuracy_score(true_labels, predictions)\n    report = classification_report(true_labels, predictions, target_names=[\"Not Answerable\", \"Answerable\"])\n    print(f\"Epoch {epoch + 1} - Accuracy: {accuracy:.4f} - Average Loss: {average_loss:.4f}\")\n    print(report)","metadata":{"id":"IpV_1rKN29Yr","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f2eb83ca-bfb7-4125-bee3-0b14c70dea73","execution":{"iopub.status.busy":"2023-10-27T11:13:13.696025Z","iopub.execute_input":"2023-10-27T11:13:13.696335Z","iopub.status.idle":"2023-10-27T11:23:11.792414Z","shell.execute_reply.started":"2023-10-27T11:13:13.696310Z","shell.execute_reply":"2023-10-27T11:23:11.791472Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"Epoch 1: 100%|██████████| 713/713 [02:26<00:00,  4.87it/s]\nEvaluating Epoch 1: 100%|██████████| 75/75 [00:04<00:00, 17.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 - Accuracy: 0.8724 - Average Loss: 0.4172\n                precision    recall  f1-score   support\n\nNot Answerable       0.87      0.88      0.87       594\n    Answerable       0.88      0.87      0.87       597\n\n      accuracy                           0.87      1191\n     macro avg       0.87      0.87      0.87      1191\n  weighted avg       0.87      0.87      0.87      1191\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 713/713 [02:24<00:00,  4.92it/s]\nEvaluating Epoch 2: 100%|██████████| 75/75 [00:04<00:00, 17.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 - Accuracy: 0.8774 - Average Loss: 0.2568\n                precision    recall  f1-score   support\n\nNot Answerable       0.93      0.82      0.87       594\n    Answerable       0.84      0.94      0.88       597\n\n      accuracy                           0.88      1191\n     macro avg       0.88      0.88      0.88      1191\n  weighted avg       0.88      0.88      0.88      1191\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 713/713 [02:24<00:00,  4.92it/s]\nEvaluating Epoch 3: 100%|██████████| 75/75 [00:04<00:00, 17.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 - Accuracy: 0.8774 - Average Loss: 0.1782\n                precision    recall  f1-score   support\n\nNot Answerable       0.91      0.84      0.87       594\n    Answerable       0.85      0.92      0.88       597\n\n      accuracy                           0.88      1191\n     macro avg       0.88      0.88      0.88      1191\n  weighted avg       0.88      0.88      0.88      1191\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 713/713 [02:24<00:00,  4.92it/s]\nEvaluating Epoch 4: 100%|██████████| 75/75 [00:04<00:00, 17.65it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 4 - Accuracy: 0.8841 - Average Loss: 0.1150\n                precision    recall  f1-score   support\n\nNot Answerable       0.90      0.86      0.88       594\n    Answerable       0.87      0.91      0.89       597\n\n      accuracy                           0.88      1191\n     macro avg       0.89      0.88      0.88      1191\n  weighted avg       0.89      0.88      0.88      1191\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save_pretrained(\"./indonesian_classification\")","metadata":{"execution":{"iopub.status.busy":"2023-10-27T11:23:11.793678Z","iopub.execute_input":"2023-10-27T11:23:11.793949Z","iopub.status.idle":"2023-10-27T11:23:13.537666Z","shell.execute_reply.started":"2023-10-27T11:23:11.793924Z","shell.execute_reply":"2023-10-27T11:23:13.536584Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'/kaggle/working/indonesian_classification/pytorch_model.bin')","metadata":{"execution":{"iopub.status.busy":"2023-10-27T11:23:13.538844Z","iopub.execute_input":"2023-10-27T11:23:13.539125Z","iopub.status.idle":"2023-10-27T11:23:13.544920Z","shell.execute_reply.started":"2023-10-27T11:23:13.539101Z","shell.execute_reply":"2023-10-27T11:23:13.544069Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/indonesian_classification/pytorch_model.bin","text/html":"<a href='/kaggle/working/indonesian_classification/pytorch_model.bin' target='_blank'>/kaggle/working/indonesian_classification/pytorch_model.bin</a><br>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Bengali","metadata":{"id":"HW8fQZD6mfjW"}},{"cell_type":"code","source":"# For Bengali\n\ntrain_tokenized_text_bengali = tokenize_text(df_train_bengali_merged)\nval_tokenized_text_bengali = tokenize_text(df_val_bengali_merged)\n\n\ntrain_input_ids_bengali = torch.cat([train_tokenized_text_bengali[\"input_ids\"]], dim=0)\ntrain_attention_masks_bengali = torch.cat([train_tokenized_text_bengali[\"attention_mask\"]], dim=0) \nval_input_ids_bengali = torch.cat([val_tokenized_text_bengali[\"input_ids\"]], dim=0)\nval_attention_masks_bengali = torch.cat([val_tokenized_text_bengali[\"attention_mask\"]], dim=0)\n\ntrain_labels_bengali = torch.tensor(df_train_bengali_merged[\"answerable\"].tolist())\nval_labels_bengali = torch.tensor(df_val_bengali_merged[\"answerable\"].tolist())\n\nbatch_size = 16\n\ntrain_data_bengali = TensorDataset(train_input_ids_bengali.to('cuda'), train_attention_masks_bengali.to('cuda'), train_labels_bengali.to('cuda'))\ntrain_sampler_bengali = RandomSampler(train_data_bengali)\ntrain_dataloader_bengali = DataLoader(train_data_bengali, sampler=train_sampler_bengali, batch_size=batch_size)\n\nval_data_bengali = TensorDataset(val_input_ids_bengali.to('cuda'), val_attention_masks_bengali.to('cuda'), val_labels_bengali.to('cuda'))\nval_sampler_bengali = SequentialSampler(val_data_bengali)\nval_dataloader_bengali = DataLoader(val_data_bengali, sampler=val_sampler_bengali, batch_size=batch_size)\n","metadata":{"id":"s2xosqFqlV1T","execution":{"iopub.status.busy":"2023-10-27T11:23:13.546051Z","iopub.execute_input":"2023-10-27T11:23:13.546407Z","iopub.status.idle":"2023-10-27T11:23:15.636590Z","shell.execute_reply.started":"2023-10-27T11:23:13.546376Z","shell.execute_reply":"2023-10-27T11:23:15.635629Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# define the trainer object\ntrainer_bengali = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data_bengali,\n    eval_dataset=val_data_bengali,\n    compute_metrics=compute_metrics,\n    tokenizer=tokenizer\n)","metadata":{"id":"9QazchflKT1r","execution":{"iopub.status.busy":"2023-10-27T11:23:15.637884Z","iopub.execute_input":"2023-10-27T11:23:15.638274Z","iopub.status.idle":"2023-10-27T11:23:15.650574Z","shell.execute_reply.started":"2023-10-27T11:23:15.638240Z","shell.execute_reply":"2023-10-27T11:23:15.649527Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\nepochs = 4\ntotal_steps = len(train_dataloader_bengali) * epochs\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LSvXOuJ9KT1y","outputId":"f0106f78-0e40-464f-e2f7-bd8f7931bf82","execution":{"iopub.status.busy":"2023-10-27T11:23:15.656088Z","iopub.execute_input":"2023-10-27T11:23:15.656451Z","iopub.status.idle":"2023-10-27T11:23:15.666203Z","shell.execute_reply.started":"2023-10-27T11:23:15.656427Z","shell.execute_reply":"2023-10-27T11:23:15.665304Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Initialize a list to store losses\ntrain_losses = []\n\n# Training loop\nfor epoch in range(epochs):\n    model.train()\n    total_loss = 0  # Initialize the total loss for the epoch\n\n    for batch in tqdm(train_dataloader_bengali, desc=f\"Epoch {epoch + 1}\"):\n        inputs = batch[:2]\n        labels = batch[2]\n\n        model.zero_grad()\n        outputs = model(*inputs, labels=labels)\n        loss = outputs.loss\n        total_loss += loss.item()  # Accumulate the loss\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        scheduler.step()\n\n    average_loss = total_loss / len(train_dataloader_bengali)  # Compute the average loss for the epoch\n\n    model.eval()\n    predictions = []\n    true_labels = []\n    for batch in tqdm(val_dataloader_bengali, desc=f\"Evaluating Epoch {epoch + 1}\"):\n        inputs = batch[:2]\n        labels = batch[2]\n        with torch.no_grad():\n            outputs = model(*inputs)\n        logits = outputs.logits\n        predictions.extend(logits.argmax(dim=1).tolist())\n        true_labels.extend(labels.tolist())\n\n    accuracy = accuracy_score(true_labels, predictions)\n    report = classification_report(true_labels, predictions, target_names=[\"Not Answerable\", \"Answerable\"])\n    print(f\"Epoch {epoch + 1} - Accuracy: {accuracy:.4f} - Average Loss: {average_loss:.4f}\")\n    print(report)\n","metadata":{"id":"6AGlWGEU4a_N","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8abca048-a7f4-49ba-ed0a-92a1ccc38ee6","execution":{"iopub.status.busy":"2023-10-27T11:23:15.667568Z","iopub.execute_input":"2023-10-27T11:23:15.667861Z","iopub.status.idle":"2023-10-27T11:27:21.966403Z","shell.execute_reply.started":"2023-10-27T11:23:15.667827Z","shell.execute_reply":"2023-10-27T11:27:21.965363Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"Epoch 1: 100%|██████████| 299/299 [01:00<00:00,  4.92it/s]\nEvaluating Epoch 1: 100%|██████████| 14/14 [00:00<00:00, 17.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 - Accuracy: 0.8527 - Average Loss: 0.4222\n                precision    recall  f1-score   support\n\nNot Answerable       0.91      0.79      0.84       112\n    Answerable       0.81      0.92      0.86       112\n\n      accuracy                           0.85       224\n     macro avg       0.86      0.85      0.85       224\n  weighted avg       0.86      0.85      0.85       224\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 299/299 [01:00<00:00,  4.92it/s]\nEvaluating Epoch 2: 100%|██████████| 14/14 [00:00<00:00, 17.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 - Accuracy: 0.8616 - Average Loss: 0.2874\n                precision    recall  f1-score   support\n\nNot Answerable       0.92      0.79      0.85       112\n    Answerable       0.82      0.93      0.87       112\n\n      accuracy                           0.86       224\n     macro avg       0.87      0.86      0.86       224\n  weighted avg       0.87      0.86      0.86       224\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 299/299 [01:00<00:00,  4.92it/s]\nEvaluating Epoch 3: 100%|██████████| 14/14 [00:00<00:00, 17.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 - Accuracy: 0.8482 - Average Loss: 0.1830\n                precision    recall  f1-score   support\n\nNot Answerable       0.88      0.81      0.84       112\n    Answerable       0.82      0.88      0.85       112\n\n      accuracy                           0.85       224\n     macro avg       0.85      0.85      0.85       224\n  weighted avg       0.85      0.85      0.85       224\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 299/299 [01:00<00:00,  4.92it/s]\nEvaluating Epoch 4: 100%|██████████| 14/14 [00:00<00:00, 17.52it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 4 - Accuracy: 0.8304 - Average Loss: 0.1191\n                precision    recall  f1-score   support\n\nNot Answerable       0.86      0.79      0.82       112\n    Answerable       0.80      0.88      0.84       112\n\n      accuracy                           0.83       224\n     macro avg       0.83      0.83      0.83       224\n  weighted avg       0.83      0.83      0.83       224\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save_pretrained(\"./bengali_classification\")","metadata":{"execution":{"iopub.status.busy":"2023-10-27T11:27:21.967630Z","iopub.execute_input":"2023-10-27T11:27:21.967901Z","iopub.status.idle":"2023-10-27T11:27:23.809507Z","shell.execute_reply.started":"2023-10-27T11:27:21.967878Z","shell.execute_reply":"2023-10-27T11:27:23.808385Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'/kaggle/working/bengali_classification/pytorch_model.bin')","metadata":{"execution":{"iopub.status.busy":"2023-10-27T11:27:23.810840Z","iopub.execute_input":"2023-10-27T11:27:23.811246Z","iopub.status.idle":"2023-10-27T11:27:23.819571Z","shell.execute_reply.started":"2023-10-27T11:27:23.811202Z","shell.execute_reply":"2023-10-27T11:27:23.818358Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/bengali_classification/pytorch_model.bin","text/html":"<a href='/kaggle/working/bengali_classification/pytorch_model.bin' target='_blank'>/kaggle/working/bengali_classification/pytorch_model.bin</a><br>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Arabic","metadata":{"id":"e3-A8ANrmjRp"}},{"cell_type":"code","source":"# For Arabic\n\ntrain_tokenized_text_arabic = tokenize_text(df_train_arabic_merged)\nval_tokenized_text_arabic = tokenize_text(df_val_arabic_merged)\n\n\ntrain_input_ids_arabic = torch.cat([train_tokenized_text_arabic[\"input_ids\"]], dim=0)\ntrain_attention_masks_arabic = torch.cat([train_tokenized_text_arabic[\"attention_mask\"]], dim=0) \nval_input_ids_arabic = torch.cat([val_tokenized_text_arabic[\"input_ids\"]], dim=0)\nval_attention_masks_arabic = torch.cat([val_tokenized_text_arabic[\"attention_mask\"]], dim=0)\n\ntrain_labels_arabic = torch.tensor(df_train_arabic_merged[\"answerable\"].tolist())\nval_labels_arabic = torch.tensor(df_val_arabic_merged[\"answerable\"].tolist())\n\nbatch_size = 16\n\ntrain_data_arabic = TensorDataset(train_input_ids_arabic.to('cuda'), train_attention_masks_arabic.to('cuda'), train_labels_arabic.to('cuda'))\ntrain_sampler_arabic = RandomSampler(train_data_arabic)\ntrain_dataloader_arabic = DataLoader(train_data_arabic, sampler=train_sampler_arabic, batch_size=batch_size)\n\nval_data_arabic = TensorDataset(val_input_ids_arabic.to('cuda'), val_attention_masks_arabic.to('cuda'), val_labels_arabic.to('cuda'))\nval_sampler_arabic = SequentialSampler(val_data_arabic)\nval_dataloader_arabic = DataLoader(val_data_arabic, sampler=val_sampler_arabic, batch_size=batch_size)\n","metadata":{"id":"Gv3c87WBsjMf","execution":{"iopub.status.busy":"2023-10-27T11:27:23.820761Z","iopub.execute_input":"2023-10-27T11:27:23.821024Z","iopub.status.idle":"2023-10-27T11:27:34.813694Z","shell.execute_reply.started":"2023-10-27T11:27:23.821001Z","shell.execute_reply":"2023-10-27T11:27:34.812837Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# define the trainer object\ntrainer_arabic = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data_arabic,\n    eval_dataset=val_data_arabic,\n    compute_metrics=compute_metrics,\n    tokenizer=tokenizer\n)","metadata":{"id":"PlNmmKEWKVND","execution":{"iopub.status.busy":"2023-10-27T11:27:34.814913Z","iopub.execute_input":"2023-10-27T11:27:34.815321Z","iopub.status.idle":"2023-10-27T11:27:34.827346Z","shell.execute_reply.started":"2023-10-27T11:27:34.815287Z","shell.execute_reply":"2023-10-27T11:27:34.826430Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\nepochs = 4\ntotal_steps = len(train_dataloader_arabic) * epochs\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n","metadata":{"id":"v5j5uQw9KVNO","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6e01f1a0-ec80-4240-976a-20fcf2f41576","execution":{"iopub.status.busy":"2023-10-27T11:27:34.828568Z","iopub.execute_input":"2023-10-27T11:27:34.828867Z","iopub.status.idle":"2023-10-27T11:27:34.839829Z","shell.execute_reply.started":"2023-10-27T11:27:34.828843Z","shell.execute_reply":"2023-10-27T11:27:34.838880Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"model = model.to(\"cuda\")\n\n# Training loop\nfor epoch in range(epochs):\n    model.train()\n    total_loss = 0  # Initialize the total loss for the epoch\n\n    for batch in tqdm(train_dataloader_arabic, desc=f\"Epoch {epoch + 1}\"):\n        inputs = batch[:2]\n        labels = batch[2]\n\n        model.zero_grad()\n        outputs = model(*inputs, labels=labels)\n        loss = outputs.loss\n        total_loss += loss.item()  # Accumulate the loss\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        scheduler.step()\n\n    average_loss = total_loss / len(train_dataloader_arabic)  # Compute the average loss for the epoch\n\n    model.eval()\n    predictions = []\n    true_labels = []\n    for batch in tqdm(val_dataloader_arabic, desc=f\"Evaluating Epoch {epoch + 1}\"):\n        inputs = batch[:2]\n        labels = batch[2]\n        with torch.no_grad():\n            outputs = model(*inputs)\n        logits = outputs.logits\n        predictions.extend(logits.argmax(dim=1).tolist())\n        true_labels.extend(labels.tolist())\n\n    accuracy = accuracy_score(true_labels, predictions)\n    report = classification_report(true_labels, predictions, target_names=[\"Not Answerable\", \"Answerable\"])\n    print(f\"Epoch {epoch + 1} - Accuracy: {accuracy:.4f} - Average Loss: {average_loss:.4f}\")\n    print(report)","metadata":{"id":"V1r0WonD4gNv","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d73e35e3-a97c-4978-df8c-0ecd6458b200","execution":{"iopub.status.busy":"2023-10-27T11:27:34.841225Z","iopub.execute_input":"2023-10-27T11:27:34.841465Z","iopub.status.idle":"2023-10-27T11:53:07.255028Z","shell.execute_reply.started":"2023-10-27T11:27:34.841444Z","shell.execute_reply":"2023-10-27T11:53:07.254057Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"Epoch 1: 100%|██████████| 1850/1850 [06:16<00:00,  4.91it/s]\nEvaluating Epoch 1: 100%|██████████| 119/119 [00:06<00:00, 17.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 - Accuracy: 0.9253 - Average Loss: 0.2556\n                precision    recall  f1-score   support\n\nNot Answerable       0.94      0.91      0.92       951\n    Answerable       0.92      0.94      0.93       951\n\n      accuracy                           0.93      1902\n     macro avg       0.93      0.93      0.93      1902\n  weighted avg       0.93      0.93      0.93      1902\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 1850/1850 [06:16<00:00,  4.91it/s]\nEvaluating Epoch 2: 100%|██████████| 119/119 [00:06<00:00, 17.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 - Accuracy: 0.9285 - Average Loss: 0.1847\n                precision    recall  f1-score   support\n\nNot Answerable       0.95      0.90      0.93       951\n    Answerable       0.91      0.96      0.93       951\n\n      accuracy                           0.93      1902\n     macro avg       0.93      0.93      0.93      1902\n  weighted avg       0.93      0.93      0.93      1902\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 1850/1850 [06:16<00:00,  4.92it/s]\nEvaluating Epoch 3: 100%|██████████| 119/119 [00:06<00:00, 17.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 - Accuracy: 0.9290 - Average Loss: 0.1230\n                precision    recall  f1-score   support\n\nNot Answerable       0.93      0.93      0.93       951\n    Answerable       0.93      0.93      0.93       951\n\n      accuracy                           0.93      1902\n     macro avg       0.93      0.93      0.93      1902\n  weighted avg       0.93      0.93      0.93      1902\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 1850/1850 [06:15<00:00,  4.92it/s]\nEvaluating Epoch 4: 100%|██████████| 119/119 [00:06<00:00, 17.64it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 4 - Accuracy: 0.9317 - Average Loss: 0.0764\n                precision    recall  f1-score   support\n\nNot Answerable       0.94      0.92      0.93       951\n    Answerable       0.92      0.95      0.93       951\n\n      accuracy                           0.93      1902\n     macro avg       0.93      0.93      0.93      1902\n  weighted avg       0.93      0.93      0.93      1902\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save_pretrained(\"./arabic_classification\")","metadata":{"execution":{"iopub.status.busy":"2023-10-27T11:53:07.256632Z","iopub.execute_input":"2023-10-27T11:53:07.257025Z","iopub.status.idle":"2023-10-27T11:53:08.392359Z","shell.execute_reply.started":"2023-10-27T11:53:07.256989Z","shell.execute_reply":"2023-10-27T11:53:08.391543Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'/kaggle/working/arabic_classification/pytorch_model.bin')","metadata":{"execution":{"iopub.status.busy":"2023-10-27T11:55:01.109741Z","iopub.execute_input":"2023-10-27T11:55:01.110621Z","iopub.status.idle":"2023-10-27T11:55:01.116484Z","shell.execute_reply.started":"2023-10-27T11:55:01.110585Z","shell.execute_reply":"2023-10-27T11:55:01.115617Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/arabic_classification/pytorch_model.bin","text/html":"<a href='/kaggle/working/arabic_classification/pytorch_model.bin' target='_blank'>/kaggle/working/arabic_classification/pytorch_model.bin</a><br>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Week 40 - visualisations for classifiction model\nSome examples with English first to establish which we want to use. Thinking the final one is the most appropriate.","metadata":{"id":"VA6IdkuUlv9i"}},{"cell_type":"code","source":"# attempt to use bertvis - move to end of the notebook if it works\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2, output_attentions=True)\nmodel.to(device)  # in this case to have on the device\n\n\n\n# for answerable question\nsentence_answerable = df_train_english_merged['text'][26]\n\n\ninputs_answerable = tokenizer.encode_plus(sentence_answerable, return_tensors='pt')\ninput_ids_answerable = inputs_answerable['input_ids']\ntoken_type_ids_answerable = inputs_answerable['token_type_ids']\n# Move inputs to the same device as the model\ninput_ids_answerable = input_ids_answerable.to(device)\ntoken_type_ids_answerable = token_type_ids_answerable.to(device)\n\n# Pass the inputs through the model, ensuring they are on the same device\nattention_answerable = model(input_ids_answerable, token_type_ids=token_type_ids_answerable)[-1]\n\n# sentence_a_start = token_type_ids[0].tolist().index(1)\ninput_id_list_answerable = input_ids_answerable[0].tolist() # Batch index 0\ntokens_answerable = tokenizer.convert_ids_to_tokens(input_id_list_answerable)\n\n# for not answerable question\nsentence_notanswerable = df_train_english_merged['text'][115992]\n\ninputs_notanswerable = tokenizer.encode_plus(sentence_notanswerable, return_tensors='pt')\ninput_ids_notanswerable = inputs_notanswerable['input_ids']\ntoken_type_ids_notanswerable = inputs_notanswerable['token_type_ids']\n# Move inputs to the same device as the model\ninput_ids_notanswerable = input_ids_notanswerable.to(device)\ntoken_type_ids_notanswerable = token_type_ids_notanswerable.to(device)\n\n# Pass the inputs through the model, ensuring they are on the same device\nattention_notanswerable = model(input_ids_notanswerable, token_type_ids=token_type_ids_notanswerable)[-1]\n\n# sentence_a_start = token_type_ids[0].tolist().index(1)\ninput_id_list_notanswerable = input_ids_notanswerable[0].tolist() # Batch index 0\ntokens_notanswerable = tokenizer.convert_ids_to_tokens(input_id_list_notanswerable)","metadata":{"id":"FK43ARtnPwMr","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6e7f5ca9-cefc-470e-e901-4de31c44ed57","execution":{"iopub.status.busy":"2023-10-27T09:45:53.086196Z","iopub.status.idle":"2023-10-27T09:45:53.086515Z","shell.execute_reply.started":"2023-10-27T09:45:53.086353Z","shell.execute_reply":"2023-10-27T09:45:53.086375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# answerable question\nhead_view(attention_answerable, tokens_answerable)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"6SOdkoj2Tvgo","outputId":"907e8209-3a65-4dc9-e10f-c16c8a624758","execution":{"iopub.status.busy":"2023-10-27T09:45:53.088523Z","iopub.status.idle":"2023-10-27T09:45:53.088885Z","shell.execute_reply.started":"2023-10-27T09:45:53.088721Z","shell.execute_reply":"2023-10-27T09:45:53.088738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# nonanswerable question\nhead_view(attention_notanswerable, tokens_notanswerable)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":838},"id":"WhTD2uLXdZgF","outputId":"0ed671f2-0879-4e8f-c0c6-9e213c3edbf5","execution":{"iopub.status.busy":"2023-10-27T09:45:53.089912Z","iopub.status.idle":"2023-10-27T09:45:53.090242Z","shell.execute_reply.started":"2023-10-27T09:45:53.090079Z","shell.execute_reply":"2023-10-27T09:45:53.090095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from bertviz.transformers_neuron_view import BertModel, BertTokenizer\nfrom bertviz.neuron_view import show\n\nmodel_type='bert'\nmodel_version = 'bert-base-multilingual-cased'\nmodel = BertModel.from_pretrained(model_version, output_attentions=True)\ntokenizer = BertTokenizer.from_pretrained(model_version)\nshow(model, model_type, tokenizer, sentence_answerable, layer=4, head=3)","metadata":{"id":"ACVHKXMNJsM5","outputId":"8010dd63-7c20-486d-d71a-0d13d5b9ba51","colab":{"base_uri":"https://localhost:8080/","height":1000},"execution":{"iopub.status.busy":"2023-10-27T09:45:53.092273Z","iopub.status.idle":"2023-10-27T09:45:53.092642Z","shell.execute_reply.started":"2023-10-27T09:45:53.092449Z","shell.execute_reply":"2023-10-27T09:45:53.092467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from bertviz.transformers_neuron_view import BertModel, BertTokenizer\nfrom bertviz.neuron_view import show\n\nmodel_type='bert'\nmodel_version = 'bert-base-multilingual-cased'\nmodel = BertModel.from_pretrained(model_version, output_attentions=True)\ntokenizer = BertTokenizer.from_pretrained(model_version)\nshow(model, model_type, tokenizer, sentence_notanswerable, layer=4, head=3)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"VSd1WIQpJ_et","outputId":"469b4a54-1f0b-4204-a668-513771f6efe2","execution":{"iopub.status.busy":"2023-10-27T09:45:53.094020Z","iopub.status.idle":"2023-10-27T09:45:53.094355Z","shell.execute_reply.started":"2023-10-27T09:45:53.094191Z","shell.execute_reply":"2023-10-27T09:45:53.094207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# possible alternate way of visualizing\n\n# Assuming you want to visualize attention for a specific instance (e.g., the first instance in the validation dataset)\ninstance_index = 0\n\n# Prepare input for the selected instance\ninputs = {\n    'input_ids': val_input_ids_arabic[instance_index].unsqueeze(0).to('cuda'),\n    'attention_mask': val_attention_masks_arabic[instance_index].unsqueeze(0).to('cuda')\n}\n\n# Pass the input through the model to get attentions\nwith torch.no_grad():\n    outputs = model(**inputs)\nattentions_arabic = outputs.attentions  # This will contain attention scores for different layers","metadata":{"id":"cLufZMzFmmEL","execution":{"iopub.status.busy":"2023-10-27T09:45:53.095579Z","iopub.status.idle":"2023-10-27T09:45:53.095909Z","shell.execute_reply.started":"2023-10-27T09:45:53.095747Z","shell.execute_reply":"2023-10-27T09:45:53.095762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n# Assuming you want to visualize attention for layer 3, head 0\nlayer_idx = 3\nhead_idx = 0\n\n# Get the attention scores for the selected layer and head\nattention_matrix = attentions_arabic[layer_idx][0][head_idx].cpu().numpy()\n\n# Create a heatmap\nplt.figure(figsize=(8, 8))\nsns.heatmap(attention_matrix, cmap='YlGnBu', xticklabels=False, yticklabels=False)\nplt.title(f'Attention Map for Layer {layer_idx}, Head {head_idx}')\nplt.show()\n","metadata":{"id":"b9NxRxN13TQx","execution":{"iopub.status.busy":"2023-10-27T09:45:53.097316Z","iopub.status.idle":"2023-10-27T09:45:53.097681Z","shell.execute_reply.started":"2023-10-27T09:45:53.097485Z","shell.execute_reply":"2023-10-27T09:45:53.097502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Week 41 - Zero-shot cross-lingual evaluation on classifier\n\nFirst, using Arabic as the training set and evaluating on Indonesian and Bengali.\n\nRan-out of GPUs on 4th epoch..","metadata":{"id":"wNtrmBdkmy4p"}},{"cell_type":"code","source":"arabic_model = AutoModelForSequenceClassification.from_pretrained(\"./arabic_classification\")\narabic_model.to('cuda')\n\narabic_model.eval()\npredictions_bengali = []\ntrue_labels_bengali = []\nfor batch in tqdm(val_dataloader_bengali, desc=f\"Evaluating\"):\n    inputs = batch[:2]\n    labels = batch[2]\n    with torch.no_grad():\n        outputs = arabic_model(*inputs)\n    logits = outputs.logits\n    predictions_bengali.extend(logits.argmax(dim=1).tolist())\n    true_labels_bengali.extend(labels.tolist())\n\naccuracy_bengali = accuracy_score(true_labels_bengali, predictions_bengali)\nreport_bengali = classification_report(true_labels_bengali, predictions_bengali, target_names=[\"Not Answerable\", \"Answerable\"], digits=5)\nprint(f\"Evaluating on Bengali: Accuracy: {accuracy_bengali:.4f} - Average Loss: {average_loss:.4f}\")\nprint(report_bengali)\n\narabic_model.eval()\npredictions_indonesian = []\ntrue_labels_indonesian = []\nfor batch in tqdm(val_dataloader_indonesian, desc=f\"Evaluating\"):\n    inputs = batch[:2]\n    labels = batch[2]\n    with torch.no_grad():\n        outputs = arabic_model(*inputs)\n    logits = outputs.logits\n    predictions_indonesian.extend(logits.argmax(dim=1).tolist())\n    true_labels_indonesian.extend(labels.tolist())\n\naccuracy_indonesian = accuracy_score(true_labels_indonesian, predictions_indonesian)\nreport_indonesian = classification_report(true_labels_indonesian, predictions_indonesian, target_names=[\"Not Answerable\", \"Answerable\"], digits=5)\nprint(f\"Evaluating on Indonesian: Accuracy: {accuracy_indonesian:.4f} - Average Loss: {average_loss:.4f}\")\nprint(report_indonesian)\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HvObkyMmoWMY","outputId":"c225b2f3-67ee-48f1-909e-5039b580f13f","execution":{"iopub.status.busy":"2023-10-27T12:49:29.789495Z","iopub.execute_input":"2023-10-27T12:49:29.789842Z","iopub.status.idle":"2023-10-27T12:49:36.995151Z","shell.execute_reply.started":"2023-10-27T12:49:29.789816Z","shell.execute_reply":"2023-10-27T12:49:36.994174Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stderr","text":"Evaluating: 100%|██████████| 14/14 [00:00<00:00, 17.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Evaluating on Bengali: Accuracy: 0.8571 - Average Loss: 0.0764\n                precision    recall  f1-score   support\n\nNot Answerable    0.88462   0.82143   0.85185       112\n    Answerable    0.83333   0.89286   0.86207       112\n\n      accuracy                        0.85714       224\n     macro avg    0.85897   0.85714   0.85696       224\n  weighted avg    0.85897   0.85714   0.85696       224\n\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 75/75 [00:04<00:00, 17.74it/s]","output_type":"stream"},{"name":"stdout","text":"Evaluating on Indonesian: Accuracy: 0.8841 - Average Loss: 0.0764\n                precision    recall  f1-score   support\n\nNot Answerable    0.90141   0.86195   0.88124       594\n    Answerable    0.86838   0.90620   0.88689       597\n\n      accuracy                        0.88413      1191\n     macro avg    0.88489   0.88408   0.88406      1191\n  weighted avg    0.88485   0.88413   0.88407      1191\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Using Bengali as the training language, and evaluating on Arabic and Indonesian.","metadata":{"id":"yzmklkkWyrgc"}},{"cell_type":"code","source":"bengali_model = AutoModelForSequenceClassification.from_pretrained(\"./bengali_classification\")\n\nbengali_model.to('cuda')\n\nbengali_model.eval()\npredictions_arabic = []\ntrue_labels_arabic = []\nfor batch in tqdm(val_dataloader_arabic, desc=f\"Evaluating\"):\n    inputs = batch[:2]\n    labels = batch[2]\n    with torch.no_grad():\n        outputs = bengali_model(*inputs)\n    logits = outputs.logits\n    predictions_arabic.extend(logits.argmax(dim=1).tolist())\n    true_labels_arabic.extend(labels.tolist())\n\naccuracy_arabic = accuracy_score(true_labels_arabic, predictions_arabic)\nreport_arabic = classification_report(true_labels_arabic, predictions_arabic, target_names=[\"Not Answerable\", \"Answerable\"], digits=5)\nprint(f\"Evaluating on Arabic: Accuracy: {accuracy_arabic:.4f} - Average Loss: {average_loss:.4f}\")\nprint(report_arabic)\n\nbengali_model.eval()\npredictions_indonesian = []\ntrue_labels_indonesian = []\nfor batch in tqdm(val_dataloader_indonesian, desc=f\"Evaluating\"):\n    inputs = batch[:2]\n    labels = batch[2]\n    with torch.no_grad():\n        outputs = bengali_model(*inputs)\n    logits = outputs.logits\n    predictions_indonesian.extend(logits.argmax(dim=1).tolist())\n    true_labels_indonesian.extend(labels.tolist())\n\naccuracy_indonesian = accuracy_score(true_labels_indonesian, predictions_indonesian)\nreport_indonesian = classification_report(true_labels_indonesian, predictions_indonesian, target_names=[\"Not Answerable\", \"Answerable\"], digits=5)\nprint(f\"Evaluating on Indonesian: Accuracy: {accuracy_indonesian:.4f} - Average Loss: {average_loss:.4f}\")\nprint(report_indonesian)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YHc-qZPuyqbf","outputId":"2db8ae44-b13a-42c5-9190-76d7296b5e94","execution":{"iopub.status.busy":"2023-10-27T12:50:38.860810Z","iopub.execute_input":"2023-10-27T12:50:38.861682Z","iopub.status.idle":"2023-10-27T12:50:52.057272Z","shell.execute_reply.started":"2023-10-27T12:50:38.861649Z","shell.execute_reply":"2023-10-27T12:50:52.056348Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stderr","text":"Evaluating: 100%|██████████| 119/119 [00:06<00:00, 17.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Evaluating on Arabic: Accuracy: 0.8943 - Average Loss: 0.0764\n                precision    recall  f1-score   support\n\nNot Answerable    0.91391   0.87066   0.89176       951\n    Answerable    0.87651   0.91798   0.89676       951\n\n      accuracy                        0.89432      1902\n     macro avg    0.89521   0.89432   0.89426      1902\n  weighted avg    0.89521   0.89432   0.89426      1902\n\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 75/75 [00:04<00:00, 17.72it/s]","output_type":"stream"},{"name":"stdout","text":"Evaluating on Indonesian: Accuracy: 0.8774 - Average Loss: 0.0764\n                precision    recall  f1-score   support\n\nNot Answerable    0.91026   0.83670   0.87193       594\n    Answerable    0.84961   0.91792   0.88245       597\n\n      accuracy                        0.87741      1191\n     macro avg    0.87993   0.87731   0.87719      1191\n  weighted avg    0.87986   0.87741   0.87720      1191\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Using Indonesian as training dataset and Bengali and Arabic for validation.","metadata":{"id":"tFJCGT1wzaiz"}},{"cell_type":"code","source":"indonesian_model = AutoModelForSequenceClassification.from_pretrained(\"./indonesian_classification\")\nindonesian_model.to('cuda')\n\nindonesian_model.eval()\npredictions_arabic = []\ntrue_labels_arabic = []\nfor batch in tqdm(val_dataloader_arabic, desc=f\"Evaluating\"):\n    inputs = batch[:2]\n    labels = batch[2]\n    with torch.no_grad():\n        outputs = indonesian_model(*inputs)\n    logits = outputs.logits\n    predictions_arabic.extend(logits.argmax(dim=1).tolist())\n    true_labels_arabic.extend(labels.tolist())\n\naccuracy_arabic = accuracy_score(true_labels_arabic, predictions_arabic)\nreport_arabic = classification_report(true_labels_arabic, predictions_arabic, target_names=[\"Not Answerable\", \"Answerable\"], digits=5)\nprint(f\"Evaluating on Arabic: Accuracy: {accuracy_arabic:.4f} - Average Loss: {average_loss:.4f}\")\nprint(report_arabic)\n\nindonesian_model.eval()\npredictions_bengali = []\ntrue_labels_bengali = []\nfor batch in tqdm(val_dataloader_bengali, desc=f\"Evaluating Epoch {epoch + 1}\"):\n    inputs = batch[:2]\n    labels = batch[2]\n    with torch.no_grad():\n        outputs = indonesian_model(*inputs)\n    logits = outputs.logits\n    predictions_bengali.extend(logits.argmax(dim=1).tolist())\n    true_labels_bengali.extend(labels.tolist())\n\naccuracy_bengali = accuracy_score(true_labels_bengali, predictions_bengali)\nreport_bengali = classification_report(true_labels_bengali, predictions_bengali, target_names=[\"Not Answerable\", \"Answerable\"], digits=5)\nprint(f\"Evaluating on Bengali: Accuracy: {accuracy_bengali:.4f} - Average Loss: {average_loss:.4f}\")\nprint(report_bengali)","metadata":{"id":"Ia3E5hZnzZHB","outputId":"dafa35dd-a6fa-4d7b-87bf-6475e7fdb2f4","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2023-10-27T12:51:08.729166Z","iopub.execute_input":"2023-10-27T12:51:08.730040Z","iopub.status.idle":"2023-10-27T12:51:18.470237Z","shell.execute_reply.started":"2023-10-27T12:51:08.730009Z","shell.execute_reply":"2023-10-27T12:51:18.469341Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stderr","text":"Evaluating: 100%|██████████| 119/119 [00:06<00:00, 17.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Evaluating on Arabic: Accuracy: 0.9175 - Average Loss: 0.0764\n                precision    recall  f1-score   support\n\nNot Answerable    0.92688   0.90641   0.91653       951\n    Answerable    0.90844   0.92850   0.91836       951\n\n      accuracy                        0.91746      1902\n     macro avg    0.91766   0.91746   0.91745      1902\n  weighted avg    0.91766   0.91746   0.91745      1902\n\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Epoch 4: 100%|██████████| 14/14 [00:00<00:00, 17.59it/s]","output_type":"stream"},{"name":"stdout","text":"Evaluating on Bengali: Accuracy: 0.8348 - Average Loss: 0.0764\n                precision    recall  f1-score   support\n\nNot Answerable    0.82051   0.85714   0.83843       112\n    Answerable    0.85047   0.81250   0.83105       112\n\n      accuracy                        0.83482       224\n     macro avg    0.83549   0.83482   0.83474       224\n  weighted avg    0.83549   0.83482   0.83474       224\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"arabic_model = AutoModelForSequenceClassification.from_pretrained(\"./arabic_classification\")\narabic_model.to('cuda')\n\narabic_model.eval()\npredictions_arabic = []\ntrue_labels_arabic = []\nfor batch in tqdm(val_dataloader_arabic, desc=f\"Evaluating\"):\n    inputs = batch[:2]\n    labels = batch[2]\n    with torch.no_grad():\n        outputs = arabic_model(*inputs)\n    logits = outputs.logits\n    predictions_arabic.extend(logits.argmax(dim=1).tolist())\n    true_labels_arabic.extend(labels.tolist())\n\naccuracy_arabic = accuracy_score(true_labels_arabic, predictions_arabic)\nreport_arabic = classification_report(true_labels_arabic, predictions_arabic, target_names=[\"Not Answerable\", \"Answerable\"], digits=5)\nprint(f\"Evaluating on Arabic: Accuracy: {accuracy_arabic:.4f} - Average Loss: {average_loss:.4f}\")\nprint(report_arabic)","metadata":{"id":"QBJ1_RifGj06","execution":{"iopub.status.busy":"2023-10-27T12:52:54.706949Z","iopub.execute_input":"2023-10-27T12:52:54.707741Z","iopub.status.idle":"2023-10-27T12:53:03.698876Z","shell.execute_reply.started":"2023-10-27T12:52:54.707705Z","shell.execute_reply":"2023-10-27T12:53:03.697974Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stderr","text":"Evaluating: 100%|██████████| 119/119 [00:06<00:00, 17.46it/s]","output_type":"stream"},{"name":"stdout","text":"Evaluating on Arabic: Accuracy: 0.9317 - Average Loss: 0.0764\n                precision    recall  f1-score   support\n\nNot Answerable    0.94378   0.91798   0.93070       951\n    Answerable    0.92016   0.94532   0.93257       951\n\n      accuracy                        0.93165      1902\n     macro avg    0.93197   0.93165   0.93164      1902\n  weighted avg    0.93197   0.93165   0.93164      1902\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"bengali_model = AutoModelForSequenceClassification.from_pretrained(\"./bengali_classification\")\nbengali_model.to('cuda')\n\nbengali_model.eval()\npredictions_bengali = []\ntrue_labels_bengali = []\nfor batch in tqdm(val_dataloader_bengali, desc=f\"Evaluating\"):\n    inputs = batch[:2]\n    labels = batch[2]\n    with torch.no_grad():\n        outputs = bengali_model(*inputs)\n    logits = outputs.logits\n    predictions_bengali.extend(logits.argmax(dim=1).tolist())\n    true_labels_bengali.extend(labels.tolist())\n\naccuracy_bengali = accuracy_score(true_labels_bengali, predictions_bengali)\nreport_bengali = classification_report(true_labels_bengali, predictions_bengali, target_names=[\"Not Answerable\", \"Answerable\"], digits=5)\nprint(f\"Evaluating on Bengali: Accuracy: {accuracy_bengali:.4f} - Average Loss: {average_loss:.4f}\")\nprint(report_bengali)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T12:55:31.204892Z","iopub.execute_input":"2023-10-27T12:55:31.205382Z","iopub.status.idle":"2023-10-27T12:55:34.238914Z","shell.execute_reply.started":"2023-10-27T12:55:31.205350Z","shell.execute_reply":"2023-10-27T12:55:34.237975Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stderr","text":"Evaluating: 100%|██████████| 14/14 [00:00<00:00, 17.09it/s]","output_type":"stream"},{"name":"stdout","text":"Evaluating on Bengali: Accuracy: 0.8304 - Average Loss: 0.0764\n                precision    recall  f1-score   support\n\nNot Answerable    0.86275   0.78571   0.82243       112\n    Answerable    0.80328   0.87500   0.83761       112\n\n      accuracy                        0.83036       224\n     macro avg    0.83301   0.83036   0.83002       224\n  weighted avg    0.83301   0.83036   0.83002       224\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"indonesian_model = AutoModelForSequenceClassification.from_pretrained(\"./indonesian_classification\")\nindonesian_model.to('cuda')\n\nindonesian_model.eval()\npredictions_indonesian = []\ntrue_labels_indonesian = []\nfor batch in tqdm(val_dataloader_indonesian, desc=f\"Evaluating\"):\n    inputs = batch[:2]\n    labels = batch[2]\n    with torch.no_grad():\n        outputs = indonesian_model(*inputs)\n    logits = outputs.logits\n    predictions_indonesian.extend(logits.argmax(dim=1).tolist())\n    true_labels_indonesian.extend(labels.tolist())\n\naccuracy_indonesian = accuracy_score(true_labels_indonesian, predictions_indonesian)\nreport_indonesian = classification_report(true_labels_indonesian, predictions_indonesian, target_names=[\"Not Answerable\", \"Answerable\"], digits=5)\nprint(f\"Evaluating on Indonesian: Accuracy: {accuracy_indonesian:.4f} - Average Loss: {average_loss:.4f}\")\nprint(report_indonesian)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T12:56:27.115130Z","iopub.execute_input":"2023-10-27T12:56:27.116004Z","iopub.status.idle":"2023-10-27T12:56:33.962050Z","shell.execute_reply.started":"2023-10-27T12:56:27.115972Z","shell.execute_reply":"2023-10-27T12:56:33.961183Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stderr","text":"Evaluating: 100%|██████████| 75/75 [00:04<00:00, 17.63it/s]","output_type":"stream"},{"name":"stdout","text":"Evaluating on Indonesian: Accuracy: 0.8841 - Average Loss: 0.0764\n                precision    recall  f1-score   support\n\nNot Answerable    0.90426   0.85859   0.88083       594\n    Answerable    0.86603   0.90955   0.88725       597\n\n      accuracy                        0.88413      1191\n     macro avg    0.88514   0.88407   0.88404      1191\n  weighted avg    0.88509   0.88413   0.88405      1191\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"0","metadata":{},"execution_count":null,"outputs":[]}]}