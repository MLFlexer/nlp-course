{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Week 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now move from binary classification to span-based QA, i.e., identifying the span in the document that answers the question, when it is answerable.\n",
    "Let k be the number of members in your group. Using the training data, implement k different sequence labellers for each of the three languages, which predict which tokens in a document are part of the answer to the correspond- ing question. Evaluate the sequence labellers on the respective validation sets, report and analyse the performance for each language and compare the scores across languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bpemb in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (0.3.4)\n",
      "Requirement already satisfied: sentencepiece in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from bpemb) (0.1.99)\n",
      "Requirement already satisfied: requests in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from bpemb) (2.29.0)\n",
      "Requirement already satisfied: numpy in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from bpemb) (1.24.3)\n",
      "Requirement already satisfied: gensim in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from bpemb) (4.3.1)\n",
      "Requirement already satisfied: tqdm in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from bpemb) (4.65.0)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from gensim->bpemb) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from gensim->bpemb) (6.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from requests->bpemb) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from requests->bpemb) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from requests->bpemb) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from requests->bpemb) (1.26.15)\n",
      "Requirement already satisfied: gensim in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (4.3.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from gensim) (6.3.0)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from gensim) (1.24.3)\n",
      "Collecting en-core-web-sm==3.6.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from en-core-web-sm==3.6.0) (3.6.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.24.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.8)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.10)\n",
      "Requirement already satisfied: jinja2 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.10)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.3.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.29.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.1)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.9)\n",
      "Requirement already satisfied: setuptools in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (66.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.8.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.10.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.11)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Requirement already satisfied: fasttext in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (0.9.2)\n",
      "Requirement already satisfied: pybind11>=2.2 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from fasttext) (2.11.1)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from fasttext) (66.0.0)\n",
      "Requirement already satisfied: numpy in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from fasttext) (1.24.3)\n",
      "Requirement already satisfied: datasets in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (2.12.0)\n",
      "Requirement already satisfied: aiohttp in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: multiprocess in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from datasets) (12.0.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from datasets) (0.17.2)\n",
      "Requirement already satisfied: xxhash in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: responses<0.19 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: pandas in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from datasets) (2.0.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from datasets) (2023.5.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: packaging in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from datasets) (2.29.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from aiohttp->datasets) (3.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.8.0)\n",
      "Requirement already satisfied: filelock in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: sklearn in /Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages (0.0.post5)\n"
     ]
    }
   ],
   "source": [
    "!pip install bpemb\n",
    "!pip install gensim\n",
    "!python -m spacy download en_core_web_sm\n",
    "!pip install fasttext\n",
    "!pip install datasets\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from math import log\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "import torch\n",
    "import random\n",
    "from math import log\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ExponentialLR, CyclicLR\n",
    "from typing import List, Tuple, AnyStr\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from datasets import load_dataset, load_metric\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch.nn.functional as F\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enforce_reproducibility(seed=42):\n",
    "    # Sets seed manually for both CPU and CUDA\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    # For atomic operations there is currently \n",
    "    # no simple way to enforce determinism, as\n",
    "    # the order of parallel operations is not known.\n",
    "    # CUDNN\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # System based\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "enforce_reproducibility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preamble \n",
    "import sys \n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/Users/emmastoklundlee/.cache/huggingface/datasets/copenlu___parquet/copenlu--nlp_course_tydiqa-cceecfb5416d988a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f0be4d12c744a3881426d428657c07f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116067\n",
      "13325\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>document_title</th>\n",
       "      <th>language</th>\n",
       "      <th>annotations</th>\n",
       "      <th>document_plaintext</th>\n",
       "      <th>document_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Milloin Charles Fort syntyi?</td>\n",
       "      <td>Charles Fort</td>\n",
       "      <td>finnish</td>\n",
       "      <td>{'answer_start': [18], 'answer_text': ['6. elo...</td>\n",
       "      <td>Charles Hoy Fort (6. elokuuta (joidenkin lähte...</td>\n",
       "      <td>https://fi.wikipedia.org/wiki/Charles%20Fort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“ダン” ダニエル・ジャドソン・キャラハンの出身はどこ</td>\n",
       "      <td>ダニエル・J・キャラハン</td>\n",
       "      <td>japanese</td>\n",
       "      <td>{'answer_start': [35], 'answer_text': ['カリフォルニ...</td>\n",
       "      <td>“ダン”こと、ダニエル・ジャドソン・キャラハンは1890年7月26日、カリフォルニア州サンフ...</td>\n",
       "      <td>https://ja.wikipedia.org/wiki/%E3%83%80%E3%83%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>వేప చెట్టు యొక్క శాస్త్రీయ నామం ఏమిటి?</td>\n",
       "      <td>వేప</td>\n",
       "      <td>telugu</td>\n",
       "      <td>{'answer_start': [12], 'answer_text': ['Azadir...</td>\n",
       "      <td>వేప (లాటిన్ Azadirachta indica, syn. Melia aza...</td>\n",
       "      <td>https://te.wikipedia.org/wiki/%E0%B0%B5%E0%B1%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>চেঙ্গিস খান কোন বংশের রাজা ছিলেন ?</td>\n",
       "      <td>চেঙ্গিজ খান</td>\n",
       "      <td>bengali</td>\n",
       "      <td>{'answer_start': [414], 'answer_text': ['বোরজি...</td>\n",
       "      <td>চেঙ্গিজ খান (মঙ্গোলীয়: Чингис Хаан  আ-ধ্ব-ব: ...</td>\n",
       "      <td>https://bn.wikipedia.org/wiki/%E0%A6%9A%E0%A7%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>రెయ్యలగడ్ద గ్రామ విస్తీర్ణత ఎంత?</td>\n",
       "      <td>రెయ్యలగడ్ద</td>\n",
       "      <td>telugu</td>\n",
       "      <td>{'answer_start': [259], 'answer_text': ['27 హె...</td>\n",
       "      <td>రెయ్యలగడ్ద, విశాఖపట్నం జిల్లా, గంగరాజు మాడుగుల...</td>\n",
       "      <td>https://te.wikipedia.org/wiki/%E0%B0%B0%E0%B1%...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            question_text document_title  language   \n",
       "0            Milloin Charles Fort syntyi?   Charles Fort   finnish  \\\n",
       "1             “ダン” ダニエル・ジャドソン・キャラハンの出身はどこ   ダニエル・J・キャラハン  japanese   \n",
       "2  వేప చెట్టు యొక్క శాస్త్రీయ నామం ఏమిటి?            వేప    telugu   \n",
       "3      চেঙ্গিস খান কোন বংশের রাজা ছিলেন ?    চেঙ্গিজ খান   bengali   \n",
       "4        రెయ్యలగడ్ద గ్రామ విస్తీర్ణత ఎంత?     రెయ్యలగడ్ద    telugu   \n",
       "\n",
       "                                         annotations   \n",
       "0  {'answer_start': [18], 'answer_text': ['6. elo...  \\\n",
       "1  {'answer_start': [35], 'answer_text': ['カリフォルニ...   \n",
       "2  {'answer_start': [12], 'answer_text': ['Azadir...   \n",
       "3  {'answer_start': [414], 'answer_text': ['বোরজি...   \n",
       "4  {'answer_start': [259], 'answer_text': ['27 హె...   \n",
       "\n",
       "                                  document_plaintext   \n",
       "0  Charles Hoy Fort (6. elokuuta (joidenkin lähte...  \\\n",
       "1  “ダン”こと、ダニエル・ジャドソン・キャラハンは1890年7月26日、カリフォルニア州サンフ...   \n",
       "2  వేప (లాటిన్ Azadirachta indica, syn. Melia aza...   \n",
       "3  চেঙ্গিজ খান (মঙ্গোলীয়: Чингис Хаан  আ-ধ্ব-ব: ...   \n",
       "4  రెయ్యలగడ్ద, విశాఖపట్నం జిల్లా, గంగరాజు మాడుగుల...   \n",
       "\n",
       "                                        document_url  \n",
       "0       https://fi.wikipedia.org/wiki/Charles%20Fort  \n",
       "1  https://ja.wikipedia.org/wiki/%E3%83%80%E3%83%...  \n",
       "2  https://te.wikipedia.org/wiki/%E0%B0%B5%E0%B1%...  \n",
       "3  https://bn.wikipedia.org/wiki/%E0%A6%9A%E0%A7%...  \n",
       "4  https://te.wikipedia.org/wiki/%E0%B0%B0%E0%B1%...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "dataset = load_dataset(\"copenlu/answerable_tydiqa\")\n",
    "\n",
    "train_set = dataset[\"train\"]\n",
    "validation_set = dataset[\"validation\"]\n",
    "\n",
    "df_train = train_set.to_pandas()\n",
    "df_val = validation_set.to_pandas()\n",
    "\n",
    "print(len(df_train))\n",
    "print(len(df_val))\n",
    "\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and validation data for each language\n",
    "df_train_bengali = df_train[df_train['language'] == 'bengali']\n",
    "df_train_arabic = df_train[df_train['language'] == 'arabic']\n",
    "df_train_indonesian = df_train[df_train['language'] == 'indonesian']\n",
    "\n",
    "df_val_bengali = df_val[df_val['language'] == 'bengali']\n",
    "df_val_arabic = df_val[df_val['language'] == 'arabic']\n",
    "df_val_indonesian = df_val[df_val['language'] == 'indonesian']\n",
    "\n",
    "\n",
    "# For testing\n",
    "df_val_english = df_val[df_val['language'] == 'english']\n",
    "df_train_english = df_train[df_train['language'] == 'english']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "mbert_tokeniser = AutoTokenizer.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "\n",
    "def tokenize(df, key, transformer_model):\n",
    "  df.loc[:, f'{key}_tokenized'] = [transformer_model.tokenize(row) for row in df[key]]\n",
    "\n",
    "\n",
    "def answer_text(df):\n",
    "    # create new column with 1 if answerable, 0 if not answerable\n",
    "    df['answerable'] = df['annotations'].apply(lambda x: 0 if x['answer_start'] == [-1] else 1)\n",
    "    # drop all rows with answerable = 0\n",
    "    # df = df[df['answerable'] == 1]\n",
    "    # return answer_text from annotations\n",
    "    df['answer_text'] = df['annotations'].apply(lambda x: x['answer_text'][0])\n",
    "    # create new column with answer_start converted to int\n",
    "    df['answer_start_int'] = df['annotations'].apply(lambda x: int(x['answer_start'][0]))\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Load spaCy model (you can choose a different model if needed)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "\n",
    "def label(df):\n",
    "    # Initialize labels with zeros for each document token for each document in the dataframe\n",
    "    df['labels'] = df['document_plaintext'].apply(lambda x: [0] * len(mbert_tokeniser.tokenize(x)))\n",
    "\n",
    "    # Tokenize the answer text\n",
    "    df['answer_text_tokenized'] = df['answer_text'].apply(mbert_tokeniser.tokenize)\n",
    "\n",
    "    # Tokenize and process the document plaintext\n",
    "    df['document_plaintext_tokenized'] = df['document_plaintext'].apply(mbert_tokeniser.tokenize)\n",
    "\n",
    "    # Find the starting index of answer_text in document_plaintext for each document\n",
    "    df['start_index'] = df.apply(lambda x: x['document_plaintext_tokenized'].index(x['answer_text_tokenized'][0]) if x['answer_text_tokenized'] and x['answer_text_tokenized'][0] in x['document_plaintext_tokenized'] else -1, axis=1)\n",
    "\n",
    "    # Mark the corresponding tokens in document_plaintext_tokenized with 1\n",
    "    df['labels'] = df.apply(lambda x: [1 if i >= x['start_index'] and i < x['start_index'] + len(x['answer_text_tokenized']) else 0 for i in range(len(x['document_plaintext_tokenized']))], axis=1)\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/2628830032.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answerable'] = df['annotations'].apply(lambda x: 0 if x['answer_start'] == [-1] else 1)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/2628830032.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answer_text'] = df['annotations'].apply(lambda x: x['answer_text'][0])\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/2628830032.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answer_start_int'] = df['annotations'].apply(lambda x: int(x['answer_start'][0]))\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['labels'] = df['document_plaintext'].apply(lambda x: [0] * len(mbert_tokeniser.tokenize(x)))\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answer_text_tokenized'] = df['answer_text'].apply(mbert_tokeniser.tokenize)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['document_plaintext_tokenized'] = df['document_plaintext'].apply(mbert_tokeniser.tokenize)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['start_index'] = df.apply(lambda x: x['document_plaintext_tokenized'].index(x['answer_text_tokenized'][0]) if x['answer_text_tokenized'] and x['answer_text_tokenized'][0] in x['document_plaintext_tokenized'] else -1, axis=1)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['labels'] = df.apply(lambda x: [1 if i >= x['start_index'] and i < x['start_index'] + len(x['answer_text_tokenized']) else 0 for i in range(len(x['document_plaintext_tokenized']))], axis=1)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/2628830032.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answerable'] = df['annotations'].apply(lambda x: 0 if x['answer_start'] == [-1] else 1)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/2628830032.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answer_text'] = df['annotations'].apply(lambda x: x['answer_text'][0])\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/2628830032.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answer_start_int'] = df['annotations'].apply(lambda x: int(x['answer_start'][0]))\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['labels'] = df['document_plaintext'].apply(lambda x: [0] * len(mbert_tokeniser.tokenize(x)))\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answer_text_tokenized'] = df['answer_text'].apply(mbert_tokeniser.tokenize)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['document_plaintext_tokenized'] = df['document_plaintext'].apply(mbert_tokeniser.tokenize)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['start_index'] = df.apply(lambda x: x['document_plaintext_tokenized'].index(x['answer_text_tokenized'][0]) if x['answer_text_tokenized'] and x['answer_text_tokenized'][0] in x['document_plaintext_tokenized'] else -1, axis=1)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['labels'] = df.apply(lambda x: [1 if i >= x['start_index'] and i < x['start_index'] + len(x['answer_text_tokenized']) else 0 for i in range(len(x['document_plaintext_tokenized']))], axis=1)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/2628830032.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answerable'] = df['annotations'].apply(lambda x: 0 if x['answer_start'] == [-1] else 1)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/2628830032.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answer_text'] = df['annotations'].apply(lambda x: x['answer_text'][0])\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/2628830032.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answer_start_int'] = df['annotations'].apply(lambda x: int(x['answer_start'][0]))\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['labels'] = df['document_plaintext'].apply(lambda x: [0] * len(mbert_tokeniser.tokenize(x)))\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answer_text_tokenized'] = df['answer_text'].apply(mbert_tokeniser.tokenize)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['document_plaintext_tokenized'] = df['document_plaintext'].apply(mbert_tokeniser.tokenize)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['start_index'] = df.apply(lambda x: x['document_plaintext_tokenized'].index(x['answer_text_tokenized'][0]) if x['answer_text_tokenized'] and x['answer_text_tokenized'][0] in x['document_plaintext_tokenized'] else -1, axis=1)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['labels'] = df.apply(lambda x: [1 if i >= x['start_index'] and i < x['start_index'] + len(x['answer_text_tokenized']) else 0 for i in range(len(x['document_plaintext_tokenized']))], axis=1)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/2628830032.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answerable'] = df['annotations'].apply(lambda x: 0 if x['answer_start'] == [-1] else 1)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/2628830032.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answer_text'] = df['annotations'].apply(lambda x: x['answer_text'][0])\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/2628830032.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answer_start_int'] = df['annotations'].apply(lambda x: int(x['answer_start'][0]))\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['labels'] = df['document_plaintext'].apply(lambda x: [0] * len(mbert_tokeniser.tokenize(x)))\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answer_text_tokenized'] = df['answer_text'].apply(mbert_tokeniser.tokenize)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['document_plaintext_tokenized'] = df['document_plaintext'].apply(mbert_tokeniser.tokenize)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['start_index'] = df.apply(lambda x: x['document_plaintext_tokenized'].index(x['answer_text_tokenized'][0]) if x['answer_text_tokenized'] and x['answer_text_tokenized'][0] in x['document_plaintext_tokenized'] else -1, axis=1)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['labels'] = df.apply(lambda x: [1 if i >= x['start_index'] and i < x['start_index'] + len(x['answer_text_tokenized']) else 0 for i in range(len(x['document_plaintext_tokenized']))], axis=1)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/2628830032.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answerable'] = df['annotations'].apply(lambda x: 0 if x['answer_start'] == [-1] else 1)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/2628830032.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answer_text'] = df['annotations'].apply(lambda x: x['answer_text'][0])\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/2628830032.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answer_start_int'] = df['annotations'].apply(lambda x: int(x['answer_start'][0]))\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['labels'] = df['document_plaintext'].apply(lambda x: [0] * len(mbert_tokeniser.tokenize(x)))\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answer_text_tokenized'] = df['answer_text'].apply(mbert_tokeniser.tokenize)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['document_plaintext_tokenized'] = df['document_plaintext'].apply(mbert_tokeniser.tokenize)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['start_index'] = df.apply(lambda x: x['document_plaintext_tokenized'].index(x['answer_text_tokenized'][0]) if x['answer_text_tokenized'] and x['answer_text_tokenized'][0] in x['document_plaintext_tokenized'] else -1, axis=1)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['labels'] = df.apply(lambda x: [1 if i >= x['start_index'] and i < x['start_index'] + len(x['answer_text_tokenized']) else 0 for i in range(len(x['document_plaintext_tokenized']))], axis=1)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/2628830032.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answerable'] = df['annotations'].apply(lambda x: 0 if x['answer_start'] == [-1] else 1)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/2628830032.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answer_text'] = df['annotations'].apply(lambda x: x['answer_text'][0])\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/2628830032.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answer_start_int'] = df['annotations'].apply(lambda x: int(x['answer_start'][0]))\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['labels'] = df['document_plaintext'].apply(lambda x: [0] * len(mbert_tokeniser.tokenize(x)))\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answer_text_tokenized'] = df['answer_text'].apply(mbert_tokeniser.tokenize)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['document_plaintext_tokenized'] = df['document_plaintext'].apply(mbert_tokeniser.tokenize)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['start_index'] = df.apply(lambda x: x['document_plaintext_tokenized'].index(x['answer_text_tokenized'][0]) if x['answer_text_tokenized'] and x['answer_text_tokenized'][0] in x['document_plaintext_tokenized'] else -1, axis=1)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['labels'] = df.apply(lambda x: [1 if i >= x['start_index'] and i < x['start_index'] + len(x['answer_text_tokenized']) else 0 for i in range(len(x['document_plaintext_tokenized']))], axis=1)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/2628830032.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answerable'] = df['annotations'].apply(lambda x: 0 if x['answer_start'] == [-1] else 1)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/2628830032.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answer_text'] = df['annotations'].apply(lambda x: x['answer_text'][0])\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/2628830032.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answer_start_int'] = df['annotations'].apply(lambda x: int(x['answer_start'][0]))\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['labels'] = df['document_plaintext'].apply(lambda x: [0] * len(mbert_tokeniser.tokenize(x)))\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answer_text_tokenized'] = df['answer_text'].apply(mbert_tokeniser.tokenize)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['document_plaintext_tokenized'] = df['document_plaintext'].apply(mbert_tokeniser.tokenize)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['start_index'] = df.apply(lambda x: x['document_plaintext_tokenized'].index(x['answer_text_tokenized'][0]) if x['answer_text_tokenized'] and x['answer_text_tokenized'][0] in x['document_plaintext_tokenized'] else -1, axis=1)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['labels'] = df.apply(lambda x: [1 if i >= x['start_index'] and i < x['start_index'] + len(x['answer_text_tokenized']) else 0 for i in range(len(x['document_plaintext_tokenized']))], axis=1)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/2628830032.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answerable'] = df['annotations'].apply(lambda x: 0 if x['answer_start'] == [-1] else 1)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/2628830032.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answer_text'] = df['annotations'].apply(lambda x: x['answer_text'][0])\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/2628830032.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answer_start_int'] = df['annotations'].apply(lambda x: int(x['answer_start'][0]))\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['labels'] = df['document_plaintext'].apply(lambda x: [0] * len(mbert_tokeniser.tokenize(x)))\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answer_text_tokenized'] = df['answer_text'].apply(mbert_tokeniser.tokenize)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['document_plaintext_tokenized'] = df['document_plaintext'].apply(mbert_tokeniser.tokenize)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['start_index'] = df.apply(lambda x: x['document_plaintext_tokenized'].index(x['answer_text_tokenized'][0]) if x['answer_text_tokenized'] and x['answer_text_tokenized'][0] in x['document_plaintext_tokenized'] else -1, axis=1)\n",
      "/var/folders/3m/k0nn68mj0ylfjxzs4mcl9_f00000gn/T/ipykernel_37397/404054192.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['labels'] = df.apply(lambda x: [1 if i >= x['start_index'] and i < x['start_index'] + len(x['answer_text_tokenized']) else 0 for i in range(len(x['document_plaintext_tokenized']))], axis=1)\n"
     ]
    }
   ],
   "source": [
    "df_train_english = label(answer_text(df_train_english))\n",
    "df_val_english = label(answer_text(df_val_english))\n",
    "df_train_bengali = label(answer_text(df_train_bengali))\n",
    "df_val_bengali = label(answer_text(df_val_bengali))\n",
    "df_train_arabic = label(answer_text(df_train_arabic))\n",
    "df_val_arabic = label(answer_text(df_val_arabic))\n",
    "df_train_indonesian = label(answer_text(df_train_indonesian))\n",
    "df_val_indonesian = label(answer_text(df_val_indonesian))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answerable\n",
      "1    3696\n",
      "0    3693\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# count values in answerable column\n",
    "print(df_train_english['answerable'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'مسألة وجود العثمانيين المسلمين في أوروبا وطردهم منها واستعادة القسطنطينية من العثمانيين بعد سقوطها في 1453 وتهديد مصالح الدول الأوروبية في هذه المنطقة'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_arabic['answer_text'][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25001, 100)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from bpemb import BPEmb\n",
    "\n",
    "# Load English model with 25k word-pieces\n",
    "bpemb_id = BPEmb(lang='eng', dim=100, vs=25000)\n",
    "\n",
    "# Assuming bpemb_id is your pre-trained word embeddings (e.g., fastText, Word2Vec, or GloVe)\n",
    "\n",
    "# Extract the embeddings\n",
    "pretrained_embeddings = bpemb_id.emb.vectors\n",
    "\n",
    "# Define the [PAD] token embedding as all zeros\n",
    "pad_embedding = np.zeros(shape=(1, 100))\n",
    "\n",
    "# Concatenate the embeddings with the [PAD] token\n",
    "pretrained_embeddings_with_pad = np.concatenate([pretrained_embeddings, pad_embedding], axis=0)\n",
    "\n",
    "# Extract the vocab and add an extra [PAD] token\n",
    "vocabulary = bpemb_id.emb.index_to_key + ['[PAD]']\n",
    "\n",
    "# Create a dictionary from the embeddings\n",
    "embedding_dict = {token: embedding for token, embedding in zip(vocabulary, pretrained_embeddings_with_pad)}\n",
    "\n",
    "# Ensure that the shape of pretrained_embeddings_with_pad is correct\n",
    "print(pretrained_embeddings_with_pad.shape)\n",
    "\n",
    "\n",
    "# Define a function to tokenize and embed text\n",
    "def embed_text(df, embedding_dict):\n",
    "    tokenized_text_list = []\n",
    "\n",
    "    for document_text in df['document_plaintext_tokenized']:\n",
    "        # Tokenize the document text\n",
    "        tokens = [token for token in document_text]\n",
    "\n",
    "        # Map tokens to embeddings using the dictionary\n",
    "        token_embeddings = [embedding_dict.get(token, embedding_dict['[PAD]']) for token in tokens]\n",
    "\n",
    "        # Append the token embeddings to the list\n",
    "        tokenized_text_list.extend(token_embeddings)\n",
    "\n",
    "    # Return the sequence embeddings as a NumPy array\n",
    "    sequence_embedding = np.array(tokenized_text_list)\n",
    "    return sequence_embedding\n",
    "\n",
    "# Usage:\n",
    "sequence_embedding = embed_text(df_train_english, embedding_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 100)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_embed_train_english = embed_text(df_train_english, embedding_dict)\n",
    "seq_embed_val_englihs = embed_text(df_val_english, embedding_dict)\n",
    "seq_embed_train_bengali = embed_text(df_train_bengali, embedding_dict)\n",
    "seq_embed_val_bengali = embed_text(df_val_bengali, embedding_dict)\n",
    "seq_embed_train_arabic = embed_text(df_train_arabic, embedding_dict)\n",
    "seq_embed_val_arabic = embed_text(df_val_arabic, embedding_dict)\n",
    "seq_embed_train_indonesian = embed_text(df_train_indonesian, embedding_dict)\n",
    "seq_embed_val_indonesian = embed_text(df_val_indonesian, embedding_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(983911, 100)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_embed_train_english.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindex dataframe\n",
    "df_train_english = df_train_english.reset_index(drop=True)\n",
    "df_val_english = df_val_english.reset_index(drop=True)\n",
    "df_train_bengali = df_train_bengali.reset_index(drop=True)\n",
    "df_val_bengali = df_val_bengali.reset_index(drop=True)\n",
    "df_train_arabic = df_train_arabic.reset_index(drop=True)\n",
    "df_val_arabic = df_val_arabic.reset_index(drop=True)\n",
    "df_train_indonesian = df_train_indonesian.reset_index(drop=True)\n",
    "df_val_indonesian = df_val_indonesian.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create one long list of the lists in df_train_english['labels']\n",
    "\n",
    "def get_labels(df):\n",
    "    labels = []\n",
    "    for i in range(len(df)):\n",
    "        labels.extend(df['labels'][i])\n",
    "    return np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_train_labels = get_labels(df_train_english)\n",
    "english_val_labels = get_labels(df_val_english)\n",
    "bengali_train_labels = get_labels(df_train_bengali)\n",
    "bengali_val_labels = get_labels(df_val_bengali)\n",
    "arabic_train_labels = get_labels(df_train_arabic)\n",
    "arabic_val_labels = get_labels(df_val_arabic)\n",
    "indonesian_train_labels = get_labels(df_train_indonesian)\n",
    "indonesian_val_labels = get_labels(df_val_indonesian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>document_title</th>\n",
       "      <th>language</th>\n",
       "      <th>annotations</th>\n",
       "      <th>document_plaintext</th>\n",
       "      <th>document_url</th>\n",
       "      <th>answerable</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>answer_start_int</th>\n",
       "      <th>labels</th>\n",
       "      <th>answer_text_tokenized</th>\n",
       "      <th>document_plaintext_tokenized</th>\n",
       "      <th>start_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When was quantum field theory developed?</td>\n",
       "      <td>Quantum field theory</td>\n",
       "      <td>english</td>\n",
       "      <td>{'answer_start': [159], 'answer_text': ['1920s']}</td>\n",
       "      <td>Quantum field theory naturally began with the ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Quantum%20field%...</td>\n",
       "      <td>1</td>\n",
       "      <td>1920s</td>\n",
       "      <td>159</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1920s]</td>\n",
       "      <td>[quantum, field, theory, naturally, began, wit...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who was the first Nobel prize winner for Liter...</td>\n",
       "      <td>List of Nobel laureates in Literature</td>\n",
       "      <td>english</td>\n",
       "      <td>{'answer_start': [610], 'answer_text': ['Sully...</td>\n",
       "      <td>The Nobel Prize in Literature (Swedish: Nobelp...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/List%20of%20Nobe...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sully Prudhomme</td>\n",
       "      <td>610</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[sull, ##y, pr, ##ud, ##hom, ##me]</td>\n",
       "      <td>[the, nobel, prize, in, literature, (, swedish...</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When is the dialectical method used?</td>\n",
       "      <td>Dialectic</td>\n",
       "      <td>english</td>\n",
       "      <td>{'answer_start': [129], 'answer_text': ['disco...</td>\n",
       "      <td>Dialectic or dialectics (Greek: διαλεκτική, di...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Dialectic</td>\n",
       "      <td>1</td>\n",
       "      <td>discourse between two or more people holding d...</td>\n",
       "      <td>129</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[discourse, between, two, or, more, people, ho...</td>\n",
       "      <td>[dialect, ##ic, or, dialect, ##ics, (, greek, ...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who invented Hangul?</td>\n",
       "      <td>Origin of Hangul</td>\n",
       "      <td>english</td>\n",
       "      <td>{'answer_start': [88], 'answer_text': ['Sejong...</td>\n",
       "      <td>Hangul was personally created and promulgated ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Origin%20of%20Ha...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sejong the Great</td>\n",
       "      <td>88</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[se, ##jong, the, great]</td>\n",
       "      <td>[hangul, was, personally, created, and, promu,...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What do Grasshoppers eat?</td>\n",
       "      <td>Grasshopper</td>\n",
       "      <td>english</td>\n",
       "      <td>{'answer_start': [0], 'answer_text': ['Grassho...</td>\n",
       "      <td>Grasshoppers are plant-eaters, with a few spec...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Grasshopper</td>\n",
       "      <td>1</td>\n",
       "      <td>Grasshoppers are plant-eaters, with a few spec...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[grasshoppers, are, plant, -, eat, ##ers, ,, w...</td>\n",
       "      <td>[grasshoppers, are, plant, -, eat, ##ers, ,, w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7384</th>\n",
       "      <td>What was Neil Brooks' fastest recorded time?</td>\n",
       "      <td>Swimming at the 1980 Summer Olympics – Men's 4...</td>\n",
       "      <td>english</td>\n",
       "      <td>{'answer_start': [-1], 'answer_text': ['']}</td>\n",
       "      <td>The medley relay was scheduled in the Olympisk...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Swimming%20at%20...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[the, medley, relay, was, scheduled, in, the, ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7385</th>\n",
       "      <td>Who are the three most important eastern philo...</td>\n",
       "      <td>Eastern philosophy</td>\n",
       "      <td>english</td>\n",
       "      <td>{'answer_start': [-1], 'answer_text': ['']}</td>\n",
       "      <td>Sāmkhya is a dualist philosophical tradition b...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Eastern%20philos...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[sam, ##kh, ##ya, is, a, dual, ##ist, philosop...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7386</th>\n",
       "      <td>Who was costume designer for the first Star Wa...</td>\n",
       "      <td>John Mollo</td>\n",
       "      <td>english</td>\n",
       "      <td>{'answer_start': [-1], 'answer_text': ['']}</td>\n",
       "      <td>Mollo was surprised by the success of Star War...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/John%20Mollo</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[moll, ##o, was, surprise, ##d, by, the, succe...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7387</th>\n",
       "      <td>Who developed the first thermonuclear weapon?</td>\n",
       "      <td>History of nuclear weapons</td>\n",
       "      <td>english</td>\n",
       "      <td>{'answer_start': [-1], 'answer_text': ['']}</td>\n",
       "      <td>In the end, President Truman made the final de...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/History%20of%20n...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[in, the, end, ,, president, truman, made, the...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7388</th>\n",
       "      <td>What is the population of Mahwah, NJ?</td>\n",
       "      <td>Mahwah, New Jersey</td>\n",
       "      <td>english</td>\n",
       "      <td>{'answer_start': [-1], 'answer_text': ['']}</td>\n",
       "      <td>The previous mayor, Bill Laforet faced a recal...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Mahwah%2C%20New%...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[the, previous, mayor, ,, bill, la, ##for, ##e...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7389 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          question_text   \n",
       "0              When was quantum field theory developed?  \\\n",
       "1     Who was the first Nobel prize winner for Liter...   \n",
       "2                  When is the dialectical method used?   \n",
       "3                                  Who invented Hangul?   \n",
       "4                             What do Grasshoppers eat?   \n",
       "...                                                 ...   \n",
       "7384       What was Neil Brooks' fastest recorded time?   \n",
       "7385  Who are the three most important eastern philo...   \n",
       "7386  Who was costume designer for the first Star Wa...   \n",
       "7387      Who developed the first thermonuclear weapon?   \n",
       "7388              What is the population of Mahwah, NJ?   \n",
       "\n",
       "                                         document_title language   \n",
       "0                                  Quantum field theory  english  \\\n",
       "1                 List of Nobel laureates in Literature  english   \n",
       "2                                             Dialectic  english   \n",
       "3                                      Origin of Hangul  english   \n",
       "4                                           Grasshopper  english   \n",
       "...                                                 ...      ...   \n",
       "7384  Swimming at the 1980 Summer Olympics – Men's 4...  english   \n",
       "7385                                 Eastern philosophy  english   \n",
       "7386                                         John Mollo  english   \n",
       "7387                         History of nuclear weapons  english   \n",
       "7388                                 Mahwah, New Jersey  english   \n",
       "\n",
       "                                            annotations   \n",
       "0     {'answer_start': [159], 'answer_text': ['1920s']}  \\\n",
       "1     {'answer_start': [610], 'answer_text': ['Sully...   \n",
       "2     {'answer_start': [129], 'answer_text': ['disco...   \n",
       "3     {'answer_start': [88], 'answer_text': ['Sejong...   \n",
       "4     {'answer_start': [0], 'answer_text': ['Grassho...   \n",
       "...                                                 ...   \n",
       "7384        {'answer_start': [-1], 'answer_text': ['']}   \n",
       "7385        {'answer_start': [-1], 'answer_text': ['']}   \n",
       "7386        {'answer_start': [-1], 'answer_text': ['']}   \n",
       "7387        {'answer_start': [-1], 'answer_text': ['']}   \n",
       "7388        {'answer_start': [-1], 'answer_text': ['']}   \n",
       "\n",
       "                                     document_plaintext   \n",
       "0     Quantum field theory naturally began with the ...  \\\n",
       "1     The Nobel Prize in Literature (Swedish: Nobelp...   \n",
       "2     Dialectic or dialectics (Greek: διαλεκτική, di...   \n",
       "3     Hangul was personally created and promulgated ...   \n",
       "4     Grasshoppers are plant-eaters, with a few spec...   \n",
       "...                                                 ...   \n",
       "7384  The medley relay was scheduled in the Olympisk...   \n",
       "7385  Sāmkhya is a dualist philosophical tradition b...   \n",
       "7386  Mollo was surprised by the success of Star War...   \n",
       "7387  In the end, President Truman made the final de...   \n",
       "7388  The previous mayor, Bill Laforet faced a recal...   \n",
       "\n",
       "                                           document_url  answerable   \n",
       "0     https://en.wikipedia.org/wiki/Quantum%20field%...           1  \\\n",
       "1     https://en.wikipedia.org/wiki/List%20of%20Nobe...           1   \n",
       "2               https://en.wikipedia.org/wiki/Dialectic           1   \n",
       "3     https://en.wikipedia.org/wiki/Origin%20of%20Ha...           1   \n",
       "4             https://en.wikipedia.org/wiki/Grasshopper           1   \n",
       "...                                                 ...         ...   \n",
       "7384  https://en.wikipedia.org/wiki/Swimming%20at%20...           0   \n",
       "7385  https://en.wikipedia.org/wiki/Eastern%20philos...           0   \n",
       "7386         https://en.wikipedia.org/wiki/John%20Mollo           0   \n",
       "7387  https://en.wikipedia.org/wiki/History%20of%20n...           0   \n",
       "7388  https://en.wikipedia.org/wiki/Mahwah%2C%20New%...           0   \n",
       "\n",
       "                                            answer_text  answer_start_int   \n",
       "0                                                 1920s               159  \\\n",
       "1                                       Sully Prudhomme               610   \n",
       "2     discourse between two or more people holding d...               129   \n",
       "3                                      Sejong the Great                88   \n",
       "4     Grasshoppers are plant-eaters, with a few spec...                 0   \n",
       "...                                                 ...               ...   \n",
       "7384                                                                   -1   \n",
       "7385                                                                   -1   \n",
       "7386                                                                   -1   \n",
       "7387                                                                   -1   \n",
       "7388                                                                   -1   \n",
       "\n",
       "                                                 labels   \n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \\\n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "...                                                 ...   \n",
       "7384  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "7385  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "7386  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "7387  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "7388  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                  answer_text_tokenized   \n",
       "0                                               [1920s]  \\\n",
       "1                    [sull, ##y, pr, ##ud, ##hom, ##me]   \n",
       "2     [discourse, between, two, or, more, people, ho...   \n",
       "3                              [se, ##jong, the, great]   \n",
       "4     [grasshoppers, are, plant, -, eat, ##ers, ,, w...   \n",
       "...                                                 ...   \n",
       "7384                                                 []   \n",
       "7385                                                 []   \n",
       "7386                                                 []   \n",
       "7387                                                 []   \n",
       "7388                                                 []   \n",
       "\n",
       "                           document_plaintext_tokenized  start_index  \n",
       "0     [quantum, field, theory, naturally, began, wit...           31  \n",
       "1     [the, nobel, prize, in, literature, (, swedish...          120  \n",
       "2     [dialect, ##ic, or, dialect, ##ics, (, greek, ...           33  \n",
       "3     [hangul, was, personally, created, and, promu,...           18  \n",
       "4     [grasshoppers, are, plant, -, eat, ##ers, ,, w...            0  \n",
       "...                                                 ...          ...  \n",
       "7384  [the, medley, relay, was, scheduled, in, the, ...           -1  \n",
       "7385  [sam, ##kh, ##ya, is, a, dual, ##ist, philosop...           -1  \n",
       "7386  [moll, ##o, was, surprise, ##d, by, the, succe...           -1  \n",
       "7387  [in, the, end, ,, president, truman, made, the...           -1  \n",
       "7388  [the, previous, mayor, ,, bill, la, ##for, ##e...           -1  \n",
       "\n",
       "[7389 rows x 13 columns]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ENGLISH - Logistic Regression\n",
      "Accuracy: 0.974860459262988\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emmastoklundlee/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# define parameters\n",
    "\n",
    "model_english = LogisticRegression()\n",
    "model_english.fit(seq_embed_train_english, english_train_labels)\n",
    "\n",
    "# English\n",
    "y_pred_english = model_english.predict(seq_embed_val_englihs)\n",
    "print()\n",
    "print(\"ENGLISH - Logistic Regression\")\n",
    "print(\"Accuracy:\", accuracy_score(english_val_labels, y_pred_english))\n",
    "print(\"Precision:\", precision_score(english_val_labels, y_pred_english))\n",
    "print(\"Recall:\", recall_score(english_val_labels, y_pred_english))\n",
    "print(\"F1:\", f1_score(english_val_labels, y_pred_english))\n",
    "\n",
    "# model_bengali = LogisticRegression()\n",
    "# model_bengali.fit(seq_embed_train_bengali, bengali_train_labels)\n",
    "\n",
    "# # Bengali\n",
    "# y_pred_bengali = model_bengali.predict(seq_embed_val_bengali)\n",
    "# print()\n",
    "# print(\"BENGALI - Logistic Regression\")\n",
    "# print(\"Accuracy:\", accuracy_score(bengali_val_labels, y_pred_bengali))\n",
    "# print(\"Precision:\", precision_score(bengali_val_labels, y_pred_bengali))\n",
    "# print(\"Recall:\", recall_score(bengali_val_labels, y_pred_bengali))\n",
    "# print(\"F1:\", f1_score(bengali_val_labels, y_pred_bengali))\n",
    "\n",
    "# model_arabic = LogisticRegression()\n",
    "# model_arabic.fit(seq_embed_train_arabic, arabic_train_labels)\n",
    "\n",
    "# # Arabic\n",
    "# y_pred_arabic = model_arabic.predict(seq_embed_val_arabic)\n",
    "# print()\n",
    "# print(\"ARABIC - Logistic Regression\")\n",
    "# print(\"Accuracy:\", accuracy_score(arabic_val_labels, y_pred_arabic))\n",
    "# print(\"Precision:\", precision_score(arabic_val_labels, y_pred_arabic))\n",
    "# print(\"Recall:\", recall_score(arabic_val_labels, y_pred_arabic))\n",
    "# print(\"F1:\", f1_score(arabic_val_labels, y_pred_arabic))\n",
    "\n",
    "# model_indonesian = LogisticRegression()\n",
    "# model_indonesian.fit(seq_embed_train_indonesian, indonesian_train_labels)\n",
    "\n",
    "# # Indonesian\n",
    "# y_pred_indonesian = model_indonesian.predict(seq_embed_val_indonesian)\n",
    "# print()\n",
    "# print(\"INDONESIAN - Logistic Regression\")\n",
    "# print(\"Accuracy:\", accuracy_score(indonesian_val_labels, y_pred_indonesian))\n",
    "# print(\"Precision:\", precision_score(indonesian_val_labels, y_pred_indonesian))\n",
    "# print(\"Recall:\", recall_score(indonesian_val_labels, y_pred_indonesian))\n",
    "# print(\"F1:\", f1_score(indonesian_val_labels, y_pred_indonesian))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[303], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m model_english \u001b[39m=\u001b[39m RandomForestClassifier()\n\u001b[1;32m     10\u001b[0m \u001b[39m# Fit the model to the data\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m model_english\u001b[39m.\u001b[39;49mfit(seq_embed_train_english, english_train_labels)\n\u001b[1;32m     12\u001b[0m \u001b[39m# model_indonesian.fit(seq_embed_train_indonesian, indonesian_train_labels)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m# model_bengali.fit(seq_embed_train_bengali, bengali_train_labels)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# model_arabic.fit(seq_embed_train_arabic, arabic_train_labels)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m \n\u001b[1;32m     46\u001b[0m \u001b[39m# English\u001b[39;00m\n\u001b[1;32m     47\u001b[0m y_pred_english \u001b[39m=\u001b[39m model_english\u001b[39m.\u001b[39mpredict(seq_embed_val_englihs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    462\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    463\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    464\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    465\u001b[0m ]\n\u001b[1;32m    467\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 473\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    474\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    475\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    476\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    477\u001b[0m )(\n\u001b[1;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    479\u001b[0m         t,\n\u001b[1;32m    480\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[1;32m    481\u001b[0m         X,\n\u001b[1;32m    482\u001b[0m         y,\n\u001b[1;32m    483\u001b[0m         sample_weight,\n\u001b[1;32m    484\u001b[0m         i,\n\u001b[1;32m    485\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    486\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    487\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    488\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[1;32m    489\u001b[0m     )\n\u001b[1;32m    490\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[1;32m    491\u001b[0m )\n\u001b[1;32m    493\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    182\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[0;32m--> 184\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages/sklearn/tree/_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    860\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \n\u001b[1;32m    862\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    890\u001b[0m         X,\n\u001b[1;32m    891\u001b[0m         y,\n\u001b[1;32m    892\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    893\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gensim_update/lib/python3.9/site-packages/sklearn/tree/_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    370\u001b[0m         splitter,\n\u001b[1;32m    371\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    377\u001b[0m     )\n\u001b[0;32m--> 379\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[1;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a random forest classifier\n",
    "# model_indonesian = RandomForestClassifier()\n",
    "# model_bengali = RandomForestClassifier()\n",
    "# model_arabic = RandomForestClassifier()\n",
    "model_english = RandomForestClassifier()\n",
    "\n",
    "# Fit the model to the data\n",
    "model_english.fit(seq_embed_train_english, english_train_labels)\n",
    "# model_indonesian.fit(seq_embed_train_indonesian, indonesian_train_labels)\n",
    "# model_bengali.fit(seq_embed_train_bengali, bengali_train_labels)\n",
    "# model_arabic.fit(seq_embed_train_arabic, arabic_train_labels)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "# # Indonesian\n",
    "# y_pred_indonesian = model_indonesian.predict(seq_embed_val_indonesian)\n",
    "# print()\n",
    "# print(\"INDONESIAN - Random Forest\")\n",
    "# print(\"Accuracy:\", accuracy_score(indonesian_val_labels, y_pred_indonesian))\n",
    "# print(\"Precision:\", precision_score(indonesian_val_labels, y_pred_indonesian))\n",
    "# print(\"Recall:\", recall_score(indonesian_val_labels, y_pred_indonesian))\n",
    "# print(\"F1:\", f1_score(indonesian_val_labels, y_pred_indonesian))\n",
    "\n",
    "# # Bengali\n",
    "# y_pred_bengali = model_bengali.predict(seq_embed_val_bengali)\n",
    "# print()\n",
    "# print(\"BENGALI - Random Forest\")\n",
    "# print(\"Accuracy:\", accuracy_score(bengali_val_labels, y_pred_bengali))\n",
    "# print(\"Precision:\", precision_score(bengali_val_labels, y_pred_bengali))\n",
    "# print(\"Recall:\", recall_score(bengali_val_labels, y_pred_bengali))\n",
    "# print(\"F1:\", f1_score(bengali_val_labels, y_pred_bengali))\n",
    "\n",
    "\n",
    "# # Arabic\n",
    "# y_pred_arabic = model_arabic.predict(seq_embed_val_arabic)\n",
    "# print()\n",
    "# print(\"ARABIC - Random Forest\")\n",
    "# print(\"Accuracy:\", accuracy_score(arabic_val_labels, y_pred_arabic))\n",
    "# print(\"Precision:\", precision_score(arabic_val_labels, y_pred_arabic))\n",
    "# print(\"Recall:\", recall_score(arabic_val_labels, y_pred_arabic))\n",
    "# print(\"F1:\", f1_score(arabic_val_labels, y_pred_arabic))\n",
    "\n",
    "# English\n",
    "y_pred_english = model_english.predict(seq_embed_val_englihs)\n",
    "print()\n",
    "print(\"ENGLISH - Random Forest\")\n",
    "print(\"Accuracy:\", accuracy_score(english_val_labels, y_pred_english))\n",
    "print(\"Precision:\", precision_score(english_val_labels, y_pred_english))\n",
    "print(\"Recall:\", recall_score(english_val_labels, y_pred_english))\n",
    "print(\"F1:\", f1_score(english_val_labels, y_pred_english))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install transformers\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "# Create a tqdm progress bar to track the processing\n",
    "with tqdm(total=len(ner_results)) as pbar:\n",
    "    for result in ner_results:\n",
    "        # Process each NER result here if needed\n",
    "        print(result)\n",
    "        # Update the progress bar\n",
    "        pbar.update(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version using the larger model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-large-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-large-NER\")\n",
    "\n",
    "nlp_large = pipeline(\"ner\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column in df applying nlp to document_plaintext_tokenized\n",
    "def ner(df):\n",
    "    df['ner'] = df['document_plaintext'].apply(lambda x: nlp(x))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column in df applying nlp to document_plaintext_tokenized\n",
    "def ner_large(df):\n",
    "    df['ner_large'] = df['document_plaintext'].apply(lambda x: nlp_large(x))\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
