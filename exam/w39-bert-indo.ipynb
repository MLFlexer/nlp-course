{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/MLFlexer/nlp-course/blob/malthe/assignments/w4_bert_indo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ZTpCe2R1L_yd"},"source":["# BERT sequence labeling: Indonesian\n","This notebook is made with modified code from lab 6: https://github.com/coastalcph/nlp-course/blob/44633220993b07e10f81de4edaf007868b46392d/labs/notebooks_2023/lab_6.ipynb"]},{"cell_type":"code","execution_count":55,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-10-27T07:46:04.057728Z","iopub.status.busy":"2023-10-27T07:46:04.056809Z","iopub.status.idle":"2023-10-27T07:46:39.266059Z","shell.execute_reply":"2023-10-27T07:46:39.264901Z","shell.execute_reply.started":"2023-10-27T07:46:04.057691Z"},"id":"2mAF--cPLf5y","outputId":"e7836240-0678-45c4-da92-a2e03df66b9e","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","Requirement already satisfied: update in /opt/conda/lib/python3.10/site-packages (0.0.1)\n","Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.33.0)\n","Requirement already satisfied: style==1.1.0 in /opt/conda/lib/python3.10/site-packages (from update) (1.1.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.3)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.9.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.6.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\n","Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.2)\n","Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.3.0)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.9.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.16.4)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\n","Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.12.2)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.6.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","Requirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.1)\n","Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.23.5)\n","Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.7)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.0.2)\n","Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.3.0)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.15)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.9.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.16.4)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\n","Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\n","Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.6.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.0.9)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.1.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"]}],"source":["!pip install update transformers\n","!pip install datasets\n","!pip install evaluate"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2023-10-27T07:46:39.269666Z","iopub.status.busy":"2023-10-27T07:46:39.268676Z","iopub.status.idle":"2023-10-27T07:46:39.277046Z","shell.execute_reply":"2023-10-27T07:46:39.276078Z","shell.execute_reply.started":"2023-10-27T07:46:39.269620Z"},"id":"c4d_FN4UqwhT","trusted":true},"outputs":[],"source":["from datasets import load_dataset\n","from datasets import load_metric\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer\n","from transformers import AutoModelForQuestionAnswering\n","from transformers import AutoConfig\n","from functools import partial\n","import torch\n","import random\n","import numpy as np\n","from tqdm import tqdm\n","from transformers import AdamW\n","from transformers import get_linear_schedule_with_warmup\n","from torch.optim.lr_scheduler import LambdaLR\n","from torch import nn\n","from collections import defaultdict, OrderedDict\n","# MODEL_NAME = 'xlm-roberta-base'\n","MODEL_NAME = 'bert-base-multilingual-uncased'\n","NUM_SUBSAMPLES = 11394\n","#bengali: 4779\n","#Arabic: 29598\n","#Indonesian: 11394\n","LANGUAGE = \"indonesian\" # \"bengali\" \"arabic\""]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2023-10-27T07:46:39.278575Z","iopub.status.busy":"2023-10-27T07:46:39.278310Z","iopub.status.idle":"2023-10-27T07:46:39.293240Z","shell.execute_reply":"2023-10-27T07:46:39.292434Z","shell.execute_reply.started":"2023-10-27T07:46:39.278552Z"},"id":"kC8A3_ytq43o","trusted":true},"outputs":[],"source":["def enforce_reproducibility(seed=42):\n","    # Sets seed manually for both CPU and CUDA\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    # For atomic operations there is currently\n","    # no simple way to enforce determinism, as\n","    # the order of parallel operations is not known.\n","    # CUDNN\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    # System based\n","    random.seed(seed)\n","    np.random.seed(seed)\n","\n","device = torch.device(\"cpu\")\n","if torch.cuda.is_available():\n","  device = torch.device(\"cuda\")\n","\n","enforce_reproducibility()"]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2023-10-27T07:46:39.295590Z","iopub.status.busy":"2023-10-27T07:46:39.295288Z","iopub.status.idle":"2023-10-27T07:46:40.017486Z","shell.execute_reply":"2023-10-27T07:46:40.016585Z","shell.execute_reply.started":"2023-10-27T07:46:39.295547Z"},"id":"XB3XXwrpLZLp","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"63546f27277e4ab9b17bf731ae71ad93","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from datasets import load_dataset\n","\n","dataset = load_dataset(\"copenlu/answerable_tydiqa\")\n","\n","filtered_dataset = dataset.filter(lambda entry: entry[\"language\"] in [LANGUAGE])\n","\n","train_set = filtered_dataset[\"train\"]\n","validation_set = filtered_dataset[\"validation\"]"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ee9oqmJSRwWT"},"source":[]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2023-10-27T07:46:40.019144Z","iopub.status.busy":"2023-10-27T07:46:40.018793Z","iopub.status.idle":"2023-10-27T07:46:40.385343Z","shell.execute_reply":"2023-10-27T07:46:40.384516Z","shell.execute_reply.started":"2023-10-27T07:46:40.019108Z"},"id":"Q2Hu9T0qh0IL","trusted":true},"outputs":[],"source":["from datasets import Dataset, DatasetDict\n","train_set_df = train_set.to_pandas()\n","train_set_df['id'] = range(len(train_set_df))\n","validation_set_df = validation_set.to_pandas()\n","validation_set_df['id'] = range(len(validation_set_df))\n","\n","train_set = Dataset.from_pandas(train_set_df)\n","validation_set = Dataset.from_pandas(validation_set_df)"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-10-27T07:39:16.461502Z","iopub.status.busy":"2023-10-27T07:39:16.461208Z","iopub.status.idle":"2023-10-27T07:39:16.469048Z","shell.execute_reply":"2023-10-27T07:39:16.468072Z","shell.execute_reply.started":"2023-10-27T07:39:16.461477Z"},"id":"zeTDJL35LvwO","outputId":"749262f2-79dc-4f22-a274-5334794b9898","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1191\n"]},{"data":{"text/plain":["{'question_text': 'Kapan PBB mulai terbentuk ?',\n"," 'document_title': 'Perserikatan Bangsa-Bangsa',\n"," 'language': 'indonesian',\n"," 'annotations': {'answer_start': [360], 'answer_text': ['24 Oktober 1945']},\n"," 'document_plaintext': 'Sebagai tindak lanjut Atlantic Charter tersebut, pada tanggal 25 April 1945, Konferensi PBB tentang Organisasi Internasional diadakan di San Francisco, dengan dihadiri oleh 50 pemerintah negara, dan sejumlah organisasi non-pemerintah yang terlibat dalam penyusunan Piagam Perserikatan Bangsa-Bangsa (Declaration of the United Nations). PBB resmi dibentuk pada 24 Oktober 1945 atas ratifikasi Piagam oleh lima anggota tetap Dewan Keamanan -Perancis, Republik Tiongkok, Uni Soviet, Inggris dan Amerika Serikat- dan mayoritas dari 46 negara anggota lainnya.',\n"," 'document_url': 'https://id.wikipedia.org/wiki/Perserikatan%20Bangsa-Bangsa',\n"," 'id': 2}"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["print(len(validation_set))\n","train_set[2]"]},{"cell_type":"code","execution_count":60,"metadata":{"execution":{"iopub.execute_input":"2023-10-27T07:46:40.386715Z","iopub.status.busy":"2023-10-27T07:46:40.386430Z","iopub.status.idle":"2023-10-27T07:46:40.643149Z","shell.execute_reply":"2023-10-27T07:46:40.642347Z","shell.execute_reply.started":"2023-10-27T07:46:40.386691Z"},"id":"PXY8QobAruAB","trusted":true},"outputs":[],"source":["tk = AutoTokenizer.from_pretrained(MODEL_NAME)"]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2023-10-27T07:46:40.644901Z","iopub.status.busy":"2023-10-27T07:46:40.644541Z","iopub.status.idle":"2023-10-27T07:46:40.659693Z","shell.execute_reply":"2023-10-27T07:46:40.658708Z","shell.execute_reply.started":"2023-10-27T07:46:40.644865Z"},"id":"lO4rSfT3saW4","trusted":true},"outputs":[],"source":["def get_train_features(tk, samples):\n","  '''\n","  Tokenizes all of the text in the given samples, splittling inputs that are too long for our model\n","  across multiple features. Finds the token offsets of the answers, which serve as the labels for\n","  our inputs.\n","  '''\n","  batch = tk.batch_encode_plus(\n","        [[q,c] for q,c in zip(samples['question_text'], samples['document_plaintext'])],\n","        padding='max_length',\n","        truncation='only_second',\n","        stride=128,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True\n","    )\n","\n","  # Get a list which maps the input features index to their original index in the\n","  # samples list (for split inputs). E.g. if our batch size is 4 and the second sample\n","  # is split into 3 inputs because it is very large, sample_mapping would look like\n","  # [0, 1, 1, 1, 2, 3]\n","  sample_mapping = batch.pop('overflow_to_sample_mapping')\n","  # Get all of the character offsets for each token\n","  offset_mapping = batch.pop('offset_mapping')\n","\n","  # Store the start and end tokens\n","  batch['start_tokens'] = []\n","  batch['end_tokens'] = []\n","\n","  # Iterate through all of the offsets\n","  for i, offsets in enumerate(offset_mapping):\n","    # Get the right sample by mapping it to its original index\n","    sample_idx = sample_mapping[i]\n","    # Get the sequence IDs to know where context starts so we can ignore question tokens\n","    sequence_ids = batch.sequence_ids(i)\n","\n","    # Get the start and end character positions of the answer\n","    ans = samples['annotations'][sample_idx]\n","    start_char = ans['answer_start'][0]\n","    end_char = start_char + len(ans['answer_text'][0])\n","    # while end_char > 0 and (end_char >= len(samples['context'][sample_idx]) or samples['context'][sample_idx][end_char] == ' '):\n","    #   end_char -= 1\n","\n","    # Start from the first token in the context, which can be found by going to the\n","    # first token where sequence_ids is 1\n","    start_token = 0\n","    while sequence_ids[start_token] != 1:\n","      start_token += 1\n","\n","    end_token = len(offsets) - 1\n","    while sequence_ids[end_token] != 1:\n","      end_token -= 1\n","\n","    # By default set it to the CLS token if the answer isn't in this input\n","    if start_char < offsets[start_token][0] or end_char > offsets[end_token][1]:\n","      start_token = 0\n","      end_token = 0\n","    # Otherwise find the correct token indices\n","    else:\n","      # Advance the start token index until we have passed the start character index\n","      while start_token < len(offsets) and offsets[start_token][0] <= start_char:\n","        start_token += 1\n","      start_token -= 1\n","\n","      # Decrease the end token index until we have passed the end character index\n","      while end_token >= 0 and offsets[end_token][1] >= end_char:\n","        end_token -= 1\n","      end_token += 1\n","\n","    batch['start_tokens'].append(start_token)\n","    batch['end_tokens'].append(end_token)\n","\n","  #batch['start_tokens'] = np.array(batch['start_tokens'])\n","  #batch['end_tokens'] = np.array(batch['end_tokens'])\n","\n","  return batch\n","\n","def collate_fn(inputs):\n","  '''\n","  Defines how to combine different samples in a batch\n","  '''\n","  input_ids = torch.tensor([i['input_ids'] for i in inputs])\n","  attention_mask = torch.tensor([i['attention_mask'] for i in inputs])\n","  start_tokens = torch.tensor([i['start_tokens'] for i in inputs])\n","  end_tokens = torch.tensor([i['end_tokens'] for i in inputs])\n","\n","  # Truncate to max length\n","  max_len = max(attention_mask.sum(-1))\n","  input_ids = input_ids[:,:max_len]\n","  attention_mask = attention_mask[:,:max_len]\n","\n","  return {'input_ids': input_ids, 'attention_mask': attention_mask, 'start_tokens': start_tokens, 'end_tokens': end_tokens}"]},{"cell_type":"code","execution_count":62,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["26d4aa7cf7284d44beccaffc11cb051c","67897069762c40658ced65a742355869","13ecca4ce65b48fb9288073930d0fd45","2fc457ef6897481482750337181d8a98","82553d004cad48e69feefaace5bd5944","1a994b43feab49b29bef35159151c868","ff3a59810f56463ea86f075032454ce8","8d9b7c9dad2542d1be687f4bb4143ad6","f070dd90187d40b182bb7d3260acbe78","498e82b151cc40848c8ae1f528bdb4db","82c025e832744f87acfb987639e0e875"]},"execution":{"iopub.execute_input":"2023-10-27T07:46:40.661125Z","iopub.status.busy":"2023-10-27T07:46:40.660850Z","iopub.status.idle":"2023-10-27T07:46:49.131989Z","shell.execute_reply":"2023-10-27T07:46:49.131107Z","shell.execute_reply.started":"2023-10-27T07:46:40.661101Z"},"id":"8dBau9r7seZU","outputId":"45994b4f-0a79-4395-f152-1c2e29f7f137","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"be3840a9c4904041b2a384cc9e3361d2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/12 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenized_dataset = train_set.map(partial(get_train_features, tk), batched=True, remove_columns=train_set.column_names)"]},{"cell_type":"code","execution_count":63,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-10-27T07:46:49.133534Z","iopub.status.busy":"2023-10-27T07:46:49.133193Z","iopub.status.idle":"2023-10-27T07:46:49.139400Z","shell.execute_reply":"2023-10-27T07:46:49.138601Z","shell.execute_reply.started":"2023-10-27T07:46:49.133504Z"},"id":"w66oxEb9tBdt","outputId":"5d3d90cb-52aa-4fb2-a540-fddb56a24110","trusted":true},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_tokens', 'end_tokens'],\n","    num_rows: 11594\n","})"]},"execution_count":63,"metadata":{},"output_type":"execute_result"}],"source":["tokenized_dataset"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2023-10-27T07:39:52.900409Z","iopub.status.busy":"2023-10-27T07:39:52.900067Z","iopub.status.idle":"2023-10-27T07:39:52.964438Z","shell.execute_reply":"2023-10-27T07:39:52.963700Z","shell.execute_reply.started":"2023-10-27T07:39:52.900384Z"},"id":"ExRWEMevtE8z","trusted":true},"outputs":[],"source":["samples = random.sample(list(range(len(tokenized_dataset))), NUM_SUBSAMPLES)\n","tokenized_dataset = tokenized_dataset.select(samples)\n","train_dl = DataLoader(tokenized_dataset, collate_fn=collate_fn, shuffle=True, batch_size=4)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-10-26T15:10:26.478420Z","iopub.status.busy":"2023-10-26T15:10:26.478144Z","iopub.status.idle":"2023-10-26T15:10:26.482428Z","shell.execute_reply":"2023-10-26T15:10:26.481530Z","shell.execute_reply.started":"2023-10-26T15:10:26.478398Z"},"id":"Fuszid5REYXG","trusted":true},"outputs":[],"source":["import gc"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-10-26T15:10:26.484035Z","iopub.status.busy":"2023-10-26T15:10:26.483769Z","iopub.status.idle":"2023-10-26T15:10:26.494291Z","shell.execute_reply":"2023-10-26T15:10:26.493583Z","shell.execute_reply.started":"2023-10-26T15:10:26.484013Z"},"id":"L1t6iqEbtc9D","trusted":true},"outputs":[],"source":["def train(\n","    model: nn.Module,\n","    train_dl: DataLoader,\n","    optimizer: torch.optim.Optimizer,\n","    schedule: LambdaLR,\n","    n_epochs: int,\n","    device: torch.device\n","):\n","  \"\"\"\n","  The main training loop which will optimize a given model on a given dataset\n","  :param model: The model being optimized\n","  :param train_dl: The training dataset\n","  :param optimizer: The optimizer used to update the model parameters\n","  :param n_epochs: Number of epochs to train for\n","  :param device: The device to train on\n","  \"\"\"\n","\n","  # Keep track of the loss and best accuracy\n","  losses = []\n","  best_acc = 0.0\n","  pcounter = 0\n","\n","  # Iterate through epochs\n","  for ep in range(n_epochs):\n","\n","    loss_epoch = []\n","\n","    #Iterate through each batch in the dataloader\n","    for batch in tqdm(train_dl):\n","      # VERY IMPORTANT: Make sure the model is in training mode, which turns on\n","      # things like dropout and layer normalization\n","      model.train()\n","\n","      # VERY IMPORTANT: zero out all of the gradients on each iteration -- PyTorch\n","      # keeps track of these dynamically in its computation graph so you need to explicitly\n","      # zero them out\n","      optimizer.zero_grad()\n","\n","      # Place each tensor on the GPU\n","      batch = {b: batch[b].to(device) for b in batch}\n","\n","      # Pass the inputs through the model, get the current loss and logits\n","      outputs = model(\n","          input_ids=batch['input_ids'],\n","          attention_mask=batch['attention_mask'],\n","          start_positions=batch['start_tokens'],\n","          end_positions=batch['end_tokens']\n","      )\n","      loss = outputs['loss']\n","      losses.append(loss.item())\n","      loss_epoch.append(loss.item())\n","\n","      # Calculate all of the gradients and weight updates for the model\n","      loss.backward()\n","\n","      # Optional: clip gradients\n","      #torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","      # Finally, update the weights of the model and advance the LR schedule\n","      optimizer.step()\n","      scheduler.step()\n","      gc.collect()\n","  return losses"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-10-26T15:10:26.495502Z","iopub.status.busy":"2023-10-26T15:10:26.495261Z","iopub.status.idle":"2023-10-26T15:10:35.795425Z","shell.execute_reply":"2023-10-26T15:10:35.794356Z","shell.execute_reply.started":"2023-10-26T15:10:26.495481Z"},"id":"a9oBUnR-tezT","outputId":"568b0c18-e623-4221-9e29-715ae02969e4","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c84034f62c064e4aa41876ca2c8f30fb","version_major":2,"version_minor":0},"text/plain":["Downloading model.safetensors:   0%|          | 0.00/672M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = AutoModelForQuestionAnswering.from_pretrained(MODEL_NAME).to(device)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-10-26T15:10:35.797610Z","iopub.status.busy":"2023-10-26T15:10:35.796847Z","iopub.status.idle":"2023-10-26T15:10:35.811840Z","shell.execute_reply":"2023-10-26T15:10:35.810905Z","shell.execute_reply.started":"2023-10-26T15:10:35.797559Z"},"id":"JkQShWSQth50","outputId":"bdb49912-8bbe-405d-92f3-465174210281","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["# Create the optimizer\n","lr=2e-5\n","n_epochs = 5\n","weight_decay = 0.01\n","warmup_steps = 200\n","\n","no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","      'weight_decay': weight_decay},\n","    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","]\n","# optimizer = Adam(optimizer_grouped_parameters, lr=1e-3)\n","# scheduler = None\n","optimizer = AdamW(optimizer_grouped_parameters, lr=lr)\n","scheduler = get_linear_schedule_with_warmup(\n","    optimizer,\n","    warmup_steps,\n","    n_epochs * len(train_dl)\n",")"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-10-26T15:10:35.813454Z","iopub.status.busy":"2023-10-26T15:10:35.813126Z","iopub.status.idle":"2023-10-26T16:36:11.360318Z","shell.execute_reply":"2023-10-26T16:36:11.359418Z","shell.execute_reply.started":"2023-10-26T15:10:35.813422Z"},"id":"aP17eWFRtk2x","outputId":"329b2b05-2196-4bf7-8e55-923799635af8","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 2849/2849 [17:04<00:00,  2.78it/s]\n","100%|██████████| 2849/2849 [17:04<00:00,  2.78it/s]\n","100%|██████████| 2849/2849 [17:11<00:00,  2.76it/s]\n","100%|██████████| 2849/2849 [17:03<00:00,  2.78it/s]\n","100%|██████████| 2849/2849 [17:11<00:00,  2.76it/s]\n"]}],"source":["losses = train(\n","    model,\n","    train_dl,\n","    optimizer,\n","    scheduler,\n","    n_epochs,\n","    device\n",")"]},{"cell_type":"code","execution_count":65,"metadata":{"execution":{"iopub.execute_input":"2023-10-27T07:46:51.208566Z","iopub.status.busy":"2023-10-27T07:46:51.208257Z","iopub.status.idle":"2023-10-27T07:46:51.218260Z","shell.execute_reply":"2023-10-27T07:46:51.217350Z","shell.execute_reply.started":"2023-10-27T07:46:51.208539Z"},"id":"Dz4_lMebtpbX","trusted":true},"outputs":[],"source":["def get_validation_features(tk, samples):\n","  # First, tokenize the text. We get the offsets and return overflowing sequences in\n","  # order to break up long sequences into multiple inputs. The offsets will help us\n","  # determine the original answer text\n","  batch = tk.batch_encode_plus(\n","        [[q,c] for q,c in zip(samples['question_text'], samples['document_plaintext'])],\n","        padding='max_length',\n","        truncation='only_second',\n","        stride=128,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True\n","    )\n","\n","  # We'll store the ID of the samples to calculate squad score\n","  batch['example_id'] = []\n","  # The overflow sample map tells us which input each sample corresponds to\n","  sample_map = batch.pop('overflow_to_sample_mapping')\n","\n","  for i in range(len(batch['input_ids'])):\n","    # The sample index tells us which of the values in \"samples\" these features belong to\n","    sample_idx = sample_map[i]\n","    sequence_ids = batch.sequence_ids(i)\n","\n","    # Add the ID to map these features back to the correct sample\n","    batch['example_id'].append(samples['id'][sample_idx])\n","\n","    #Set offsets for non-context words to be None for ease of processing\n","    batch['offset_mapping'][i] = [o if sequence_ids[k] == 1 else None for k,o in enumerate(batch['offset_mapping'][i])]\n","\n","  return batch\n","\n","def val_collate_fn(inputs):\n","  input_ids = torch.tensor([i['input_ids'] for i in inputs])\n","  attention_mask = torch.tensor([i['attention_mask'] for i in inputs])\n","\n","  # Truncate to max length\n","  max_len = max(attention_mask.sum(-1))\n","  input_ids = input_ids[:,:max_len]\n","  attention_mask = attention_mask[:,:max_len]\n","\n","  return {'input_ids': input_ids, 'attention_mask': attention_mask}"]},{"cell_type":"code","execution_count":66,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["ff373df92b834036ad963a91955bbd1b","955f869efde2433188550c262be29fa6","217e97a5a69c41f8be85c6123affeb03","ed08cd57502444c9abb8d49259d2f18b","8d10165cde2942d1ba9a2c512d1aad14","7b824e331c524d8a89d0b8ac67bc78fa","95a3a1b8b32843f19ab7ad0b6b62b683","10448e87ef3d4dde898f230ff819a659","8787200ae0ab42d2a280649406dccd3d","b0d1a10c9c944dbd8c0d7866efd1c588","cc7b263869274af79be78e140481a476"]},"execution":{"iopub.execute_input":"2023-10-27T07:46:52.170784Z","iopub.status.busy":"2023-10-27T07:46:52.169824Z","iopub.status.idle":"2023-10-27T07:47:02.110582Z","shell.execute_reply":"2023-10-27T07:47:02.109718Z","shell.execute_reply.started":"2023-10-27T07:46:52.170735Z"},"id":"1ywVmDAstrPx","outputId":"7cb292fc-7fef-4f4e-fc58-b5831af0add8","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4c8e4429c73c4e6d900f221b5221cb3a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["validation_dataset = validation_set.map(partial(get_validation_features, tk), batched=True, remove_columns=validation_set.column_names)"]},{"cell_type":"code","execution_count":67,"metadata":{"execution":{"iopub.execute_input":"2023-10-27T07:47:02.112594Z","iopub.status.busy":"2023-10-27T07:47:02.112282Z","iopub.status.idle":"2023-10-27T07:47:02.130004Z","shell.execute_reply":"2023-10-27T07:47:02.129122Z","shell.execute_reply.started":"2023-10-27T07:47:02.112568Z"},"id":"MnBTW-pVuC6w","trusted":true},"outputs":[],"source":["def predict(model: nn.Module, valid_dl: DataLoader):\n","  \"\"\"\n","  Evaluates the model on the given dataset\n","  :param model: The model under evaluation\n","  :param valid_dl: A `DataLoader` reading validation data\n","  :return: The accuracy of the model on the dataset\n","  \"\"\"\n","  # VERY IMPORTANT: Put your model in \"eval\" mode -- this disables things like\n","  # layer normalization and dropout\n","  model.eval()\n","  start_logits_all = []\n","  end_logits_all = []\n","\n","  # ALSO IMPORTANT: Don't accumulate gradients during this process\n","  with torch.no_grad():\n","    for batch in tqdm(valid_dl, desc='Evaluation'):\n","      batch = {b: batch[b].to(device) for b in batch}\n","\n","      # Pass the inputs through the model, get the current loss and logits\n","      outputs = model(\n","          input_ids=batch['input_ids'],\n","          attention_mask=batch['attention_mask']\n","      )\n","      # Store the \"start\" class logits and \"end\" class logits for every token in the input\n","      start_logits_all.extend(list(outputs['start_logits'].detach().cpu().numpy()))\n","      end_logits_all.extend(list(outputs['end_logits'].detach().cpu().numpy()))\n","\n","\n","    return start_logits_all,end_logits_all\n","\n","def post_process_predictions(examples, dataset, logits, tokenizer, num_possible_answers = 20, max_answer_length = 30):\n","  all_start_logits, all_end_logits = logits\n","  # Build a map from example to its corresponding features. This will allow us to index from\n","  # sample ID to all of the features for that sample (in case they were split up due to long input)\n","  example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n","  features_per_example = defaultdict(list)\n","  for i, feature in enumerate(dataset):\n","      features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n","\n","  # Create somewhere to store our predictions\n","  predictions = OrderedDict()\n","\n","  # Iterate through each sample in the dataset\n","  for j, sample in enumerate(tqdm(examples)):\n","\n","    # Get the feature indices (all of the features split across the batch)\n","    feature_indices = features_per_example[j]\n","    # Get the original context which predumably has the answer text\n","    context = sample['document_plaintext']\n","\n","    preds = []\n","\n","    min_score_threshold = None\n","\n","    # Iterate through all of the features\n","    for ft_idx in feature_indices:\n","\n","      # Get the start and end answer logits for this input\n","      start_logits = all_start_logits[ft_idx]\n","      end_logits = all_end_logits[ft_idx]\n","\n","      # Get the offsets to map token indices to character indices\n","      offset_mapping = dataset[ft_idx]['offset_mapping']\n","\n","\n","      # Update minimum null prediction.\n","      cls_index = dataset[ft_idx][\"input_ids\"].index(tokenizer.cls_token_id)\n","      feature_min_score_threshold = start_logits[cls_index] + end_logits[cls_index]\n","      if min_score_threshold is None or min_score_threshold < feature_min_score_threshold:\n","          min_score_threshold = feature_min_score_threshold\n","\n","      # Sort the logits and take the top N\n","      start_indices = np.argsort(start_logits)[::-1][:num_possible_answers]\n","      end_indices = np.argsort(end_logits)[::-1][:num_possible_answers]\n","\n","      # Iterate through start and end indices\n","      for start_index in start_indices:\n","        for end_index in end_indices:\n","\n","          # Ignore this combination if either the indices are not in the context\n","          if start_index >= len(offset_mapping) or end_index >= len(offset_mapping) or offset_mapping[start_index] is None or offset_mapping[end_index] is None:\n","            continue\n","\n","          # Also ignore if the start index is greater than the end index of the number of tokens\n","          # is greater than some specified threshold\n","          if start_index > end_index or end_index - start_index + 1 > max_answer_length:\n","            continue\n","          try:\n","              ans_text = context[offset_mapping[start_index][0]:offset_mapping[end_index][1]]\n","              preds.append({\n","                  'score': start_logits[start_index] + end_logits[end_index],\n","                  'text': ans_text\n","              })\n","          except Exception as e:\n","              continue\n","\n","    if len(preds) > 0:\n","      # Sort by score to get the top answer\n","      best_answer = sorted(preds, key=lambda x: x['score'], reverse=True)[0]\n","    else:\n","      best_answer = {'score': 0.0, 'text': \"\"}\n","\n","    # if the best answer is below the threshold for lowest score, give it the empty string\n","\n","    answer = best_answer[\"text\"] if best_answer[\"score\"] > min_score_threshold else \"\"\n","    predictions[sample['id']] = answer\n","  return predictions"]},{"cell_type":"code","execution_count":68,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-10-27T07:47:02.131485Z","iopub.status.busy":"2023-10-27T07:47:02.131216Z","iopub.status.idle":"2023-10-27T07:47:20.696023Z","shell.execute_reply":"2023-10-27T07:47:20.695089Z","shell.execute_reply.started":"2023-10-27T07:47:02.131461Z"},"id":"48-vkpvnuJ1q","outputId":"9aab5790-7fb2-45da-d612-e7d06ebb893d","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Evaluation: 100%|██████████| 38/38 [00:18<00:00,  2.05it/s]\n"]}],"source":["val_dl = DataLoader(validation_dataset, collate_fn=val_collate_fn, batch_size=32)\n","logits = predict(model, val_dl)"]},{"cell_type":"code","execution_count":69,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-10-27T07:47:20.698745Z","iopub.status.busy":"2023-10-27T07:47:20.698455Z","iopub.status.idle":"2023-10-27T07:47:20.706113Z","shell.execute_reply":"2023-10-27T07:47:20.704967Z","shell.execute_reply.started":"2023-10-27T07:47:20.698719Z"},"id":"GnDrQ9zB1vt_","outputId":"b425f343-75a7-467c-87ee-014bb1f851ac","trusted":true},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'example_id'],\n","    num_rows: 1210\n","})"]},"execution_count":69,"metadata":{},"output_type":"execute_result"}],"source":["validation_dataset"]},{"cell_type":"code","execution_count":70,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-10-27T07:47:20.707532Z","iopub.status.busy":"2023-10-27T07:47:20.707253Z","iopub.status.idle":"2023-10-27T07:47:29.759434Z","shell.execute_reply":"2023-10-27T07:47:29.758657Z","shell.execute_reply.started":"2023-10-27T07:47:20.707501Z"},"id":"lTy-WKaxuLKN","outputId":"aab51fb7-4a11-4796-c82b-391245d928a9","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1191/1191 [00:06<00:00, 192.24it/s]\n"]}],"source":["predictions = post_process_predictions(validation_set, validation_dataset, logits, tk)\n","formatted_predictions = [{'id': k, 'prediction_text': v} for k,v in predictions.items()]\n","gold = [{'id': example['id'], 'answers': example['annotations'][\"answer_text\"][0]} for example in validation_set]"]},{"cell_type":"code","execution_count":71,"metadata":{"execution":{"iopub.execute_input":"2023-10-27T07:47:29.761062Z","iopub.status.busy":"2023-10-27T07:47:29.760711Z","iopub.status.idle":"2023-10-27T07:47:29.778617Z","shell.execute_reply":"2023-10-27T07:47:29.777754Z","shell.execute_reply.started":"2023-10-27T07:47:29.761029Z"},"id":"ko5CJBuYygA-","trusted":true},"outputs":[],"source":["\"\"\" **MODIFIED code from lab 6** Official evaluation script for v1.1 of the SQuAD dataset. \"\"\"\n","from __future__ import print_function\n","from collections import Counter\n","import string\n","import re\n","import argparse\n","import json\n","import sys\n","\n","\n","def normalize_answer(s):\n","    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n","    def remove_articles(text):\n","        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n","\n","    def white_space_fix(text):\n","        return ' '.join(text.split())\n","\n","    def remove_punc(text):\n","        exclude = set(string.punctuation)\n","        return ''.join(ch for ch in text if ch not in exclude)\n","\n","    def lower(text):\n","        return text.lower()\n","\n","    return white_space_fix(remove_articles(remove_punc(lower(s))))\n","\n","\n","def f1_score(prediction, ground_truth):\n","    prediction_tokens = normalize_answer(prediction).split()\n","    ground_truth_tokens = normalize_answer(ground_truth).split()\n","    if len(prediction_tokens) == 0 and len(ground_truth_tokens) == 0:\n","      return 1\n","    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n","    num_same = sum(common.values())\n","    if num_same == 0:\n","        return 0\n","    precision = 1.0 * num_same / len(prediction_tokens)\n","    recall = 1.0 * num_same / len(ground_truth_tokens)\n","    f1 = (2 * precision * recall) / (precision + recall)\n","    return f1\n","\n","\n","def exact_match_score(prediction, ground_truth):\n","    return (normalize_answer(prediction) == normalize_answer(ground_truth))\n","\n","\n","def metric_max_over_ground_truths(metric_fn, prediction, ground_truths):\n","    scores_for_ground_truths = []\n","    for ground_truth in ground_truths:\n","        score = metric_fn(prediction, ground_truth)\n","        scores_for_ground_truths.append(score)\n","    return max(scores_for_ground_truths)\n","\n","\n","def evaluate_squad(dataset, predictions):\n","    f1 = exact_match = total = 0\n","    for article in dataset:\n","        for paragraph in article['paragraphs']:\n","            for qa in paragraph['qas']:\n","                total += 1\n","                if qa['id'] not in predictions:\n","                    message = 'Unanswered question ' + qa['id'] + \\\n","                              ' will receive score 0.'\n","                    print(message, file=sys.stderr)\n","                    continue\n","                ground_truths = list(map(lambda x: x['text'], qa['answers']))\n","                prediction = predictions[qa['id']]\n","                exact_match += metric_max_over_ground_truths(\n","                    exact_match_score, prediction, ground_truths)\n","                f1 += metric_max_over_ground_truths(\n","                    f1_score, prediction, ground_truths)\n","\n","    exact_match = 100.0 * exact_match / total\n","    f1 = 100.0 * f1 / total\n","\n","    return {'exact_match': exact_match, 'f1': f1}\n","\n","def compute_squad(predictions, references):\n","  pred_dict = {prediction[\"id\"]: prediction[\"prediction_text\"] for prediction in predictions}\n","  dataset = [\n","      {\n","          \"paragraphs\": [\n","              {\n","                  \"qas\": [\n","                      {\n","                          \"answers\": [{\"text\": ref[\"answers\"]} ],\n","                          \"id\": ref[\"id\"],\n","                      }\n","                      for ref in references\n","                  ]\n","              }\n","          ]\n","      }\n","  ]\n","  score = evaluate_squad(dataset=dataset, predictions=pred_dict)\n","  return score"]},{"cell_type":"code","execution_count":72,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-10-27T07:47:29.780310Z","iopub.status.busy":"2023-10-27T07:47:29.779988Z","iopub.status.idle":"2023-10-27T07:47:29.848666Z","shell.execute_reply":"2023-10-27T07:47:29.847829Z","shell.execute_reply.started":"2023-10-27T07:47:29.780279Z"},"id":"h99TMCPDuj6Q","outputId":"8fdbf5f0-0e7d-4360-84d5-9e4bf86de8ba","trusted":true},"outputs":[{"data":{"text/plain":["{'exact_match': 75.56675062972292, 'f1': 80.50033006143278}"]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["compute_squad(references=gold, predictions=formatted_predictions)"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-10-26T16:42:25.569434Z","iopub.status.busy":"2023-10-26T16:42:25.568617Z","iopub.status.idle":"2023-10-26T16:42:26.639825Z","shell.execute_reply":"2023-10-26T16:42:26.639009Z","shell.execute_reply.started":"2023-10-26T16:42:25.569390Z"},"trusted":true},"outputs":[],"source":["model.save_pretrained(\"./indonesian_model\")"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2023-10-27T07:46:49.141860Z","iopub.status.busy":"2023-10-27T07:46:49.141561Z","iopub.status.idle":"2023-10-27T07:46:51.206494Z","shell.execute_reply":"2023-10-27T07:46:51.205591Z","shell.execute_reply.started":"2023-10-27T07:46:49.141835Z"},"trusted":true},"outputs":[],"source":["model = AutoModelForQuestionAnswering.from_pretrained(\"./indonesian_model\").to(device)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyORsGOJW2Z5ZFtw56gBQm56","gpuType":"T4","include_colab_link":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"widgets":{"application/vnd.jupyter.widget-state+json":{"10448e87ef3d4dde898f230ff819a659":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13ecca4ce65b48fb9288073930d0fd45":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d9b7c9dad2542d1be687f4bb4143ad6","max":11394,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f070dd90187d40b182bb7d3260acbe78","value":11394}},"1a994b43feab49b29bef35159151c868":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"217e97a5a69c41f8be85c6123affeb03":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_10448e87ef3d4dde898f230ff819a659","max":1191,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8787200ae0ab42d2a280649406dccd3d","value":1191}},"26d4aa7cf7284d44beccaffc11cb051c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_67897069762c40658ced65a742355869","IPY_MODEL_13ecca4ce65b48fb9288073930d0fd45","IPY_MODEL_2fc457ef6897481482750337181d8a98"],"layout":"IPY_MODEL_82553d004cad48e69feefaace5bd5944"}},"2fc457ef6897481482750337181d8a98":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_498e82b151cc40848c8ae1f528bdb4db","placeholder":"​","style":"IPY_MODEL_82c025e832744f87acfb987639e0e875","value":" 11394/11394 [00:18&lt;00:00, 742.98 examples/s]"}},"498e82b151cc40848c8ae1f528bdb4db":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67897069762c40658ced65a742355869":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a994b43feab49b29bef35159151c868","placeholder":"​","style":"IPY_MODEL_ff3a59810f56463ea86f075032454ce8","value":"Map: 100%"}},"7b824e331c524d8a89d0b8ac67bc78fa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82553d004cad48e69feefaace5bd5944":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82c025e832744f87acfb987639e0e875":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8787200ae0ab42d2a280649406dccd3d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8d10165cde2942d1ba9a2c512d1aad14":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d9b7c9dad2542d1be687f4bb4143ad6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"955f869efde2433188550c262be29fa6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b824e331c524d8a89d0b8ac67bc78fa","placeholder":"​","style":"IPY_MODEL_95a3a1b8b32843f19ab7ad0b6b62b683","value":"Map: 100%"}},"95a3a1b8b32843f19ab7ad0b6b62b683":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b0d1a10c9c944dbd8c0d7866efd1c588":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc7b263869274af79be78e140481a476":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed08cd57502444c9abb8d49259d2f18b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0d1a10c9c944dbd8c0d7866efd1c588","placeholder":"​","style":"IPY_MODEL_cc7b263869274af79be78e140481a476","value":" 1191/1191 [00:01&lt;00:00, 1147.95 examples/s]"}},"f070dd90187d40b182bb7d3260acbe78":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ff373df92b834036ad963a91955bbd1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_955f869efde2433188550c262be29fa6","IPY_MODEL_217e97a5a69c41f8be85c6123affeb03","IPY_MODEL_ed08cd57502444c9abb8d49259d2f18b"],"layout":"IPY_MODEL_8d10165cde2942d1ba9a2c512d1aad14"}},"ff3a59810f56463ea86f075032454ce8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":4}
