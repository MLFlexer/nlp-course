{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Zero shot sequence labeling\n","This notebook is made with the notion that we already have a pre-trained model.\n","\n","This notebook is made with modified code from lab 6: https://github.com/coastalcph/nlp-course/blob/44633220993b07e10f81de4edaf007868b46392d/labs/notebooks_2023/lab_6.ipynb"]},{"cell_type":"code","execution_count":36,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-10-29T12:25:20.630065Z","iopub.status.busy":"2023-10-29T12:25:20.629263Z","iopub.status.idle":"2023-10-29T12:25:55.292772Z","shell.execute_reply":"2023-10-29T12:25:55.291532Z","shell.execute_reply.started":"2023-10-29T12:25:20.630031Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","Requirement already satisfied: update in /opt/conda/lib/python3.10/site-packages (0.0.1)\n","Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.33.0)\n","Requirement already satisfied: style==1.1.0 in /opt/conda/lib/python3.10/site-packages (from update) (1.1.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.3)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.9.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.6.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\n","Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.2)\n","Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.3.0)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.9.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.16.4)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\n","Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.12.2)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.6.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","Requirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.1)\n","Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.23.5)\n","Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.7)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.0.2)\n","Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.3.0)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.15)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.9.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.16.4)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\n","Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\n","Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.6.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.0.9)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.1.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"]}],"source":["!pip install update transformers\n","!pip install datasets\n","!pip install evaluate"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2023-10-29T12:25:55.297169Z","iopub.status.busy":"2023-10-29T12:25:55.296371Z","iopub.status.idle":"2023-10-29T12:25:55.304224Z","shell.execute_reply":"2023-10-29T12:25:55.303299Z","shell.execute_reply.started":"2023-10-29T12:25:55.297138Z"},"trusted":true},"outputs":[],"source":["from datasets import load_dataset\n","from datasets import load_metric\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer\n","from transformers import AutoModelForQuestionAnswering\n","from transformers import AutoConfig\n","from functools import partial\n","import torch\n","import random\n","import numpy as np\n","from tqdm import tqdm\n","from transformers import AdamW\n","from transformers import get_linear_schedule_with_warmup\n","from torch.optim.lr_scheduler import LambdaLR\n","from torch import nn\n","from collections import defaultdict, OrderedDict\n","# MODEL_NAME = 'xlm-roberta-base'\n","MODEL_NAME = 'bert-base-multilingual-uncased'\n","# NUM_SUBSAMPLES = 11394\n","#bengali: 4779\n","#Arabic: 29598\n","#Indonesian: 11394\n","LANGUAGE = \"indonesian\" # \"bengali\" \"arabic\""]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2023-10-29T12:25:55.305837Z","iopub.status.busy":"2023-10-29T12:25:55.305509Z","iopub.status.idle":"2023-10-29T12:25:55.322660Z","shell.execute_reply":"2023-10-29T12:25:55.321869Z","shell.execute_reply.started":"2023-10-29T12:25:55.305806Z"},"trusted":true},"outputs":[],"source":["def enforce_reproducibility(seed=42):\n","    # Sets seed manually for both CPU and CUDA\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    # For atomic operations there is currently\n","    # no simple way to enforce determinism, as\n","    # the order of parallel operations is not known.\n","    # CUDNN\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    # System based\n","    random.seed(seed)\n","    np.random.seed(seed)\n","\n","device = torch.device(\"cpu\")\n","if torch.cuda.is_available():\n","  device = torch.device(\"cuda\")\n","\n","enforce_reproducibility()"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2023-10-29T12:25:55.323835Z","iopub.status.busy":"2023-10-29T12:25:55.323599Z","iopub.status.idle":"2023-10-29T12:25:56.519059Z","shell.execute_reply":"2023-10-29T12:25:56.518272Z","shell.execute_reply.started":"2023-10-29T12:25:55.323814Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cf2f058e1c334396a0d176487118ae3e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from datasets import load_dataset\n","from datasets import Dataset, DatasetDict\n","\n","dataset = load_dataset(\"copenlu/answerable_tydiqa\")\n","\n","filtered_dataset = dataset.filter(lambda entry: entry[\"language\"] in [LANGUAGE])\n","\n","train_set = filtered_dataset[\"train\"]\n","validation_set = filtered_dataset[\"validation\"]\n","\n","train_set_df = train_set.to_pandas()\n","train_set_df['id'] = range(len(train_set_df))\n","validation_set_df = validation_set.to_pandas()\n","validation_set_df['id'] = range(len(validation_set_df))\n","\n","train_set = Dataset.from_pandas(train_set_df)\n","validation_set = Dataset.from_pandas(validation_set_df)"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2023-10-29T12:25:56.521717Z","iopub.status.busy":"2023-10-29T12:25:56.521437Z","iopub.status.idle":"2023-10-29T12:25:56.731473Z","shell.execute_reply":"2023-10-29T12:25:56.730658Z","shell.execute_reply.started":"2023-10-29T12:25:56.521692Z"},"trusted":true},"outputs":[],"source":["tk = AutoTokenizer.from_pretrained(MODEL_NAME)"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2023-10-29T12:25:56.732860Z","iopub.status.busy":"2023-10-29T12:25:56.732571Z","iopub.status.idle":"2023-10-29T12:25:58.596887Z","shell.execute_reply":"2023-10-29T12:25:58.596054Z","shell.execute_reply.started":"2023-10-29T12:25:56.732836Z"},"trusted":true},"outputs":[],"source":["model = AutoModelForQuestionAnswering.from_pretrained(\"/kaggle/input/arabic-model\").to(device)"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2023-10-29T12:25:58.598335Z","iopub.status.busy":"2023-10-29T12:25:58.598053Z","iopub.status.idle":"2023-10-29T12:25:58.608075Z","shell.execute_reply":"2023-10-29T12:25:58.607132Z","shell.execute_reply.started":"2023-10-29T12:25:58.598310Z"},"trusted":true},"outputs":[],"source":["def get_validation_features(tk, samples):\n","  # First, tokenize the text. We get the offsets and return overflowing sequences in\n","  # order to break up long sequences into multiple inputs. The offsets will help us\n","  # determine the original answer text\n","  batch = tk.batch_encode_plus(\n","        [[q,c] for q,c in zip(samples['question_text'], samples['document_plaintext'])],\n","        padding='max_length',\n","        truncation='only_second',\n","        stride=128,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True\n","    )\n","\n","  # We'll store the ID of the samples to calculate squad score\n","  batch['example_id'] = []\n","  # The overflow sample map tells us which input each sample corresponds to\n","  sample_map = batch.pop('overflow_to_sample_mapping')\n","\n","  for i in range(len(batch['input_ids'])):\n","    # The sample index tells us which of the values in \"samples\" these features belong to\n","    sample_idx = sample_map[i]\n","    sequence_ids = batch.sequence_ids(i)\n","\n","    # Add the ID to map these features back to the correct sample\n","    batch['example_id'].append(samples['id'][sample_idx])\n","\n","    #Set offsets for non-context words to be None for ease of processing\n","    batch['offset_mapping'][i] = [o if sequence_ids[k] == 1 else None for k,o in enumerate(batch['offset_mapping'][i])]\n","\n","  return batch\n","\n","def val_collate_fn(inputs):\n","  input_ids = torch.tensor([i['input_ids'] for i in inputs])\n","  attention_mask = torch.tensor([i['attention_mask'] for i in inputs])\n","\n","  # Truncate to max length\n","  max_len = max(attention_mask.sum(-1))\n","  input_ids = input_ids[:,:max_len]\n","  attention_mask = attention_mask[:,:max_len]\n","\n","  return {'input_ids': input_ids, 'attention_mask': attention_mask}"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2023-10-29T12:25:58.609733Z","iopub.status.busy":"2023-10-29T12:25:58.609211Z","iopub.status.idle":"2023-10-29T12:26:08.560294Z","shell.execute_reply":"2023-10-29T12:26:08.559273Z","shell.execute_reply.started":"2023-10-29T12:25:58.609700Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"70d17900918c4ebfb0d63bdf00360bf5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["validation_dataset = validation_set.map(partial(get_validation_features, tk), batched=True, remove_columns=validation_set.column_names)"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2023-10-29T12:26:08.561894Z","iopub.status.busy":"2023-10-29T12:26:08.561578Z","iopub.status.idle":"2023-10-29T12:26:08.579627Z","shell.execute_reply":"2023-10-29T12:26:08.578648Z","shell.execute_reply.started":"2023-10-29T12:26:08.561869Z"},"trusted":true},"outputs":[],"source":["def predict(model: nn.Module, valid_dl: DataLoader):\n","  \"\"\"\n","  Evaluates the model on the given dataset\n","  :param model: The model under evaluation\n","  :param valid_dl: A `DataLoader` reading validation data\n","  :return: The accuracy of the model on the dataset\n","  \"\"\"\n","  # VERY IMPORTANT: Put your model in \"eval\" mode -- this disables things like\n","  # layer normalization and dropout\n","  model.eval()\n","  start_logits_all = []\n","  end_logits_all = []\n","\n","  # ALSO IMPORTANT: Don't accumulate gradients during this process\n","  with torch.no_grad():\n","    for batch in tqdm(valid_dl, desc='Evaluation'):\n","      batch = {b: batch[b].to(device) for b in batch}\n","\n","      # Pass the inputs through the model, get the current loss and logits\n","      outputs = model(\n","          input_ids=batch['input_ids'],\n","          attention_mask=batch['attention_mask']\n","      )\n","      # Store the \"start\" class logits and \"end\" class logits for every token in the input\n","      start_logits_all.extend(list(outputs['start_logits'].detach().cpu().numpy()))\n","      end_logits_all.extend(list(outputs['end_logits'].detach().cpu().numpy()))\n","\n","\n","    return start_logits_all,end_logits_all\n","\n","def post_process_predictions(examples, dataset, logits, tokenizer, num_possible_answers = 20, max_answer_length = 30):\n","  all_start_logits, all_end_logits = logits\n","  # Build a map from example to its corresponding features. This will allow us to index from\n","  # sample ID to all of the features for that sample (in case they were split up due to long input)\n","  example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n","  features_per_example = defaultdict(list)\n","  for i, feature in enumerate(dataset):\n","      features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n","\n","  # Create somewhere to store our predictions\n","  predictions = OrderedDict()\n","\n","  # Iterate through each sample in the dataset\n","  for j, sample in enumerate(tqdm(examples)):\n","\n","    # Get the feature indices (all of the features split across the batch)\n","    feature_indices = features_per_example[j]\n","    # Get the original context which predumably has the answer text\n","    context = sample['document_plaintext']\n","\n","    preds = []\n","\n","    min_score_threshold = None\n","\n","    # Iterate through all of the features\n","    for ft_idx in feature_indices:\n","\n","      # Get the start and end answer logits for this input\n","      start_logits = all_start_logits[ft_idx]\n","      end_logits = all_end_logits[ft_idx]\n","\n","      # Get the offsets to map token indices to character indices\n","      offset_mapping = dataset[ft_idx]['offset_mapping']\n","\n","\n","      # Update minimum null prediction.\n","      cls_index = dataset[ft_idx][\"input_ids\"].index(tokenizer.cls_token_id)\n","      feature_min_score_threshold = start_logits[cls_index] + end_logits[cls_index]\n","      if min_score_threshold is None or min_score_threshold < feature_min_score_threshold:\n","          min_score_threshold = feature_min_score_threshold\n","\n","      # Sort the logits and take the top N\n","      start_indices = np.argsort(start_logits)[::-1][:num_possible_answers]\n","      end_indices = np.argsort(end_logits)[::-1][:num_possible_answers]\n","\n","      # Iterate through start and end indices\n","      for start_index in start_indices:\n","        for end_index in end_indices:\n","\n","          # Ignore this combination if either the indices are not in the context\n","          if start_index >= len(offset_mapping) or end_index >= len(offset_mapping) or offset_mapping[start_index] is None or offset_mapping[end_index] is None:\n","            continue\n","\n","          # Also ignore if the start index is greater than the end index of the number of tokens\n","          # is greater than some specified threshold\n","          if start_index > end_index or end_index - start_index + 1 > max_answer_length:\n","            continue\n","          try:\n","              ans_text = context[offset_mapping[start_index][0]:offset_mapping[end_index][1]]\n","              preds.append({\n","                  'score': start_logits[start_index] + end_logits[end_index],\n","                  'text': ans_text\n","              })\n","          except Exception as e:\n","              continue\n","\n","    if len(preds) > 0:\n","      # Sort by score to get the top answer\n","      best_answer = sorted(preds, key=lambda x: x['score'], reverse=True)[0]\n","    else:\n","      best_answer = {'score': 0.0, 'text': \"\"}\n","\n","    # if the best answer is below the threshold for lowest score, give it the empty string\n","\n","    answer = best_answer[\"text\"] if best_answer[\"score\"] > min_score_threshold else \"\"\n","    predictions[sample['id']] = answer\n","  return predictions"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2023-10-29T12:26:08.581503Z","iopub.status.busy":"2023-10-29T12:26:08.581066Z","iopub.status.idle":"2023-10-29T12:26:27.043222Z","shell.execute_reply":"2023-10-29T12:26:27.042370Z","shell.execute_reply.started":"2023-10-29T12:26:08.581472Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Evaluation: 100%|██████████| 38/38 [00:18<00:00,  2.06it/s]\n"]}],"source":["val_dl = DataLoader(validation_dataset, collate_fn=val_collate_fn, batch_size=32)\n","logits = predict(model, val_dl)"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2023-10-29T12:26:27.044703Z","iopub.status.busy":"2023-10-29T12:26:27.044431Z","iopub.status.idle":"2023-10-29T12:26:27.051381Z","shell.execute_reply":"2023-10-29T12:26:27.050404Z","shell.execute_reply.started":"2023-10-29T12:26:27.044680Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'example_id'],\n","    num_rows: 1210\n","})"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["validation_dataset"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2023-10-29T12:26:27.052802Z","iopub.status.busy":"2023-10-29T12:26:27.052516Z","iopub.status.idle":"2023-10-29T12:26:36.143264Z","shell.execute_reply":"2023-10-29T12:26:36.142462Z","shell.execute_reply.started":"2023-10-29T12:26:27.052770Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1191/1191 [00:06<00:00, 188.80it/s]\n"]}],"source":["predictions = post_process_predictions(validation_set, validation_dataset, logits, tk)\n","formatted_predictions = [{'id': k, 'prediction_text': v} for k,v in predictions.items()]\n","gold = [{'id': example['id'], 'answers': example['annotations'][\"answer_text\"][0]} for example in validation_set]"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2023-10-29T12:26:36.145172Z","iopub.status.busy":"2023-10-29T12:26:36.144820Z","iopub.status.idle":"2023-10-29T12:26:36.162597Z","shell.execute_reply":"2023-10-29T12:26:36.161703Z","shell.execute_reply.started":"2023-10-29T12:26:36.145140Z"},"trusted":true},"outputs":[],"source":["\"\"\" **MODIFIED code from lab 6** Official evaluation script for v1.1 of the SQuAD dataset. \"\"\"\n","from __future__ import print_function\n","from collections import Counter\n","import string\n","import re\n","import argparse\n","import json\n","import sys\n","\n","\n","def normalize_answer(s):\n","    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n","    def remove_articles(text):\n","        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n","\n","    def white_space_fix(text):\n","        return ' '.join(text.split())\n","\n","    def remove_punc(text):\n","        exclude = set(string.punctuation)\n","        return ''.join(ch for ch in text if ch not in exclude)\n","\n","    def lower(text):\n","        return text.lower()\n","\n","    return white_space_fix(remove_articles(remove_punc(lower(s))))\n","\n","\n","def f1_score(prediction, ground_truth):\n","    prediction_tokens = normalize_answer(prediction).split()\n","    ground_truth_tokens = normalize_answer(ground_truth).split()\n","    if len(prediction_tokens) == 0 and len(ground_truth_tokens) == 0:\n","      return 1\n","    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n","    num_same = sum(common.values())\n","    if num_same == 0:\n","        return 0\n","    precision = 1.0 * num_same / len(prediction_tokens)\n","    recall = 1.0 * num_same / len(ground_truth_tokens)\n","    f1 = (2 * precision * recall) / (precision + recall)\n","    return f1\n","\n","\n","def exact_match_score(prediction, ground_truth):\n","    return (normalize_answer(prediction) == normalize_answer(ground_truth))\n","\n","\n","def metric_max_over_ground_truths(metric_fn, prediction, ground_truths):\n","    scores_for_ground_truths = []\n","    for ground_truth in ground_truths:\n","        score = metric_fn(prediction, ground_truth)\n","        scores_for_ground_truths.append(score)\n","    return max(scores_for_ground_truths)\n","\n","\n","def evaluate_squad(dataset, predictions):\n","    f1 = exact_match = total = 0\n","    for article in dataset:\n","        for paragraph in article['paragraphs']:\n","            for qa in paragraph['qas']:\n","                total += 1\n","                if qa['id'] not in predictions:\n","                    message = 'Unanswered question ' + qa['id'] + \\\n","                              ' will receive score 0.'\n","                    print(message, file=sys.stderr)\n","                    continue\n","                ground_truths = list(map(lambda x: x['text'], qa['answers']))\n","                prediction = predictions[qa['id']]\n","                exact_match += metric_max_over_ground_truths(\n","                    exact_match_score, prediction, ground_truths)\n","                f1 += metric_max_over_ground_truths(\n","                    f1_score, prediction, ground_truths)\n","\n","    exact_match = 100.0 * exact_match / total\n","    f1 = 100.0 * f1 / total\n","\n","    return {'exact_match': exact_match, 'f1': f1}\n","\n","def compute_squad(predictions, references):\n","  pred_dict = {prediction[\"id\"]: prediction[\"prediction_text\"] for prediction in predictions}\n","  dataset = [\n","      {\n","          \"paragraphs\": [\n","              {\n","                  \"qas\": [\n","                      {\n","                          \"answers\": [{\"text\": ref[\"answers\"]} ],\n","                          \"id\": ref[\"id\"],\n","                      }\n","                      for ref in references\n","                  ]\n","              }\n","          ]\n","      }\n","  ]\n","  score = evaluate_squad(dataset=dataset, predictions=pred_dict)\n","  return score"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2023-10-29T12:26:36.166625Z","iopub.status.busy":"2023-10-29T12:26:36.166368Z","iopub.status.idle":"2023-10-29T12:26:36.232619Z","shell.execute_reply":"2023-10-29T12:26:36.231781Z","shell.execute_reply.started":"2023-10-29T12:26:36.166602Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'exact_match': 62.04869857262804, 'f1': 69.10885954901626}"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["compute_squad(references=gold, predictions=formatted_predictions)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## All in one function:"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2023-10-29T12:26:36.235597Z","iopub.status.busy":"2023-10-29T12:26:36.234885Z","iopub.status.idle":"2023-10-29T12:26:36.244020Z","shell.execute_reply":"2023-10-29T12:26:36.243029Z","shell.execute_reply.started":"2023-10-29T12:26:36.235566Z"},"trusted":true},"outputs":[],"source":["def zero_shot_eval(model_path, language):\n","    filtered_dataset = dataset.filter(lambda entry: entry[\"language\"] in [language])\n","\n","    train_set = filtered_dataset[\"train\"]\n","    validation_set = filtered_dataset[\"validation\"]\n","\n","    train_set_df = train_set.to_pandas()\n","    train_set_df['id'] = range(len(train_set_df))\n","    validation_set_df = validation_set.to_pandas()\n","    validation_set_df['id'] = range(len(validation_set_df))\n","\n","    train_set = Dataset.from_pandas(train_set_df)\n","    validation_set = Dataset.from_pandas(validation_set_df)\n","    \n","    model = AutoModelForQuestionAnswering.from_pretrained(model_path).to(device)\n","    \n","    validation_dataset = validation_set.map(partial(get_validation_features, tk), batched=True, remove_columns=validation_set.column_names)\n","    \n","    val_dl = DataLoader(validation_dataset, collate_fn=val_collate_fn, batch_size=32)\n","    logits = predict(model, val_dl)\n","    \n","    predictions = post_process_predictions(validation_set, validation_dataset, logits, tk)\n","    formatted_predictions = [{'id': k, 'prediction_text': v} for k,v in predictions.items()]\n","    gold = [{'id': example['id'], 'answers': example['annotations'][\"answer_text\"][0]} for example in validation_set]\n","    \n","    return compute_squad(references=gold, predictions=formatted_predictions)\n","    "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Bengali model"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2023-10-29T12:26:36.245358Z","iopub.status.busy":"2023-10-29T12:26:36.245055Z","iopub.status.idle":"2023-10-29T12:27:15.615363Z","shell.execute_reply":"2023-10-29T12:27:15.614493Z","shell.execute_reply.started":"2023-10-29T12:26:36.245332Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0a63b3a7ee9f444ca898dc0ab1481b58","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Evaluation: 100%|██████████| 38/38 [00:18<00:00,  2.05it/s]\n","100%|██████████| 1191/1191 [00:06<00:00, 192.74it/s]\n"]},{"data":{"text/plain":["{'exact_match': 57.59865659109992, 'f1': 60.15850996218458}"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["bengali_indonesian_zero_shot = zero_shot_eval(\"/kaggle/input/bengali-bert-2\", \"indonesian\")\n","bengali_indonesian_zero_shot"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2023-10-29T12:27:15.616674Z","iopub.status.busy":"2023-10-29T12:27:15.616409Z","iopub.status.idle":"2023-10-29T12:27:26.854839Z","shell.execute_reply":"2023-10-29T12:27:26.853711Z","shell.execute_reply.started":"2023-10-29T12:27:15.616651Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"61f8b43f523e4ed58eb81bfc9cb97d2a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Evaluation: 100%|██████████| 8/8 [00:05<00:00,  1.59it/s]\n","100%|██████████| 224/224 [00:01<00:00, 169.05it/s]\n"]},{"data":{"text/plain":["{'exact_match': 65.17857142857143, 'f1': 71.27000231910947}"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["bengali_arabic_zero_shot = zero_shot_eval(\"/kaggle/input/bengali-bert-2\", \"arabic\")\n","bengali_arabic_zero_shot"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2023-10-29T12:27:26.856615Z","iopub.status.busy":"2023-10-29T12:27:26.856283Z","iopub.status.idle":"2023-10-29T12:28:39.589508Z","shell.execute_reply":"2023-10-29T12:28:39.588610Z","shell.execute_reply.started":"2023-10-29T12:27:26.856589Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ff087d4288244b99ba1d5628898b997e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Evaluation: 100%|██████████| 62/62 [00:36<00:00,  1.68it/s]\n","100%|██████████| 1902/1902 [00:11<00:00, 172.68it/s]\n"]},{"data":{"text/plain":["{'exact_match': 56.098843322818084, 'f1': 58.272597262247125}"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["bengali_bengali_zero_shot = zero_shot_eval(\"/kaggle/input/bengali-bert-2\", \"bengali\")\n","bengali_bengali_zero_shot"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Indonesian model"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2023-10-29T12:28:39.591134Z","iopub.status.busy":"2023-10-29T12:28:39.590833Z","iopub.status.idle":"2023-10-29T12:28:50.792670Z","shell.execute_reply":"2023-10-29T12:28:50.791708Z","shell.execute_reply.started":"2023-10-29T12:28:39.591102Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bfc6a90ae8744983a7b2b01d52c5586b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Evaluation: 100%|██████████| 8/8 [00:04<00:00,  1.67it/s]\n","100%|██████████| 224/224 [00:01<00:00, 167.95it/s]\n"]},{"data":{"text/plain":["{'exact_match': 56.25, 'f1': 61.72435203685203}"]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["indonesian_arabic_zeo_shot = zero_shot_eval(\"/kaggle/input/indonesian-bert-3\", \"arabic\")\n","indonesian_arabic_zeo_shot"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2023-10-29T12:28:50.794042Z","iopub.status.busy":"2023-10-29T12:28:50.793786Z","iopub.status.idle":"2023-10-29T12:29:30.442628Z","shell.execute_reply":"2023-10-29T12:29:30.441719Z","shell.execute_reply.started":"2023-10-29T12:28:50.794021Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ccafde236e1945f8b11ebd5aa0a481cd","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Evaluation: 100%|██████████| 38/38 [00:18<00:00,  2.04it/s]\n","100%|██████████| 1191/1191 [00:06<00:00, 190.93it/s]\n"]},{"data":{"text/plain":["{'exact_match': 75.56675062972292, 'f1': 80.50033006143278}"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["indonesian_bengali_zeo_shot = zero_shot_eval(\"/kaggle/input/indonesian-bert-3\", \"bengali\")\n","indonesian_bengali_zeo_shot"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2023-10-29T12:29:30.444083Z","iopub.status.busy":"2023-10-29T12:29:30.443798Z","iopub.status.idle":"2023-10-29T12:30:43.446646Z","shell.execute_reply":"2023-10-29T12:30:43.445790Z","shell.execute_reply.started":"2023-10-29T12:29:30.444058Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e1fd2b66d5d7407d9cac28495751737f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Evaluation: 100%|██████████| 62/62 [00:36<00:00,  1.68it/s]\n","100%|██████████| 1902/1902 [00:11<00:00, 171.46it/s]\n"]},{"data":{"text/plain":["{'exact_match': 66.19348054679286, 'f1': 73.36365789378847}"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["indonesian_indonesian_zeo_shot = zero_shot_eval(\"/kaggle/input/indonesian-bert-3\", \"indonesian\")\n","indonesian_indonesian_zeo_shot"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Arabic model"]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2023-10-29T12:30:43.448516Z","iopub.status.busy":"2023-10-29T12:30:43.448128Z","iopub.status.idle":"2023-10-29T12:31:23.150515Z","shell.execute_reply":"2023-10-29T12:31:23.149560Z","shell.execute_reply.started":"2023-10-29T12:30:43.448482Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f4110bbf455448178baf87ee2fc4de1d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Evaluation: 100%|██████████| 38/38 [00:18<00:00,  2.07it/s]\n","100%|██████████| 1191/1191 [00:06<00:00, 190.53it/s]\n"]},{"data":{"text/plain":["{'exact_match': 62.04869857262804, 'f1': 69.10885954901626}"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["arabic_ben_zero_shot = zero_shot_eval(\"/kaggle/input/arabic-bert-2\", \"bengali\")\n","arabic_ben_zero_shot"]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2023-10-29T12:31:23.151916Z","iopub.status.busy":"2023-10-29T12:31:23.151653Z","iopub.status.idle":"2023-10-29T12:31:34.419980Z","shell.execute_reply":"2023-10-29T12:31:34.419060Z","shell.execute_reply.started":"2023-10-29T12:31:23.151894Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5c8c2601a56141a387c61cf46918b785","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Evaluation: 100%|██████████| 8/8 [00:04<00:00,  1.66it/s]\n","100%|██████████| 224/224 [00:01<00:00, 168.41it/s]\n"]},{"data":{"text/plain":["{'exact_match': 51.339285714285715, 'f1': 54.21977328227329}"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["arabic_indo_zero_shot = zero_shot_eval(\"/kaggle/input/arabic-bert-2\", \"indonesian\")\n","arabic_indo_zero_shot"]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2023-10-29T12:31:34.421789Z","iopub.status.busy":"2023-10-29T12:31:34.421417Z","iopub.status.idle":"2023-10-29T12:32:14.154214Z","shell.execute_reply":"2023-10-29T12:32:14.153273Z","shell.execute_reply.started":"2023-10-29T12:31:34.421755Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8a1d5067d6cf435188cf3c48e3c23d09","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Evaluation: 100%|██████████| 38/38 [00:18<00:00,  2.03it/s]\n","100%|██████████| 1191/1191 [00:06<00:00, 188.80it/s]\n"]},{"data":{"text/plain":["{'exact_match': 62.04869857262804, 'f1': 69.10885954901626}"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["arabic_arabic_zero_shot = zero_shot_eval(\"/kaggle/input/arabic-bert-2\", \"arabic\")\n","arabic_arabic_zero_shot"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
