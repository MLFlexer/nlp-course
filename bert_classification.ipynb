{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPuVO9O7/C3fVX6a2zRI7dO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3d310bb765214c37a2dae93a34281672": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_01ac0a5bda474bffb7923a4b56851c1c",
              "IPY_MODEL_9371bb918c7a4c76bf79793d8310a5eb",
              "IPY_MODEL_9beb1ca53b4c46eea7a7371da21a4333"
            ],
            "layout": "IPY_MODEL_cce2c3e42e2042d28be4d32dfa11cfe8"
          }
        },
        "01ac0a5bda474bffb7923a4b56851c1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d14078eeea3a4803b7d374a027858748",
            "placeholder": "​",
            "style": "IPY_MODEL_22324476ef2147658a865f05cab3b10e",
            "value": "Downloading builder script: "
          }
        },
        "9371bb918c7a4c76bf79793d8310a5eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_223b58e0bbd44aad9ce21c333a80c7c0",
            "max": 2318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b735dc9007a46a980c3b58b3c9cc2b2",
            "value": 2318
          }
        },
        "9beb1ca53b4c46eea7a7371da21a4333": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba9b465ccd054485934e9333841e6a30",
            "placeholder": "​",
            "style": "IPY_MODEL_1733b484527b47e7807c2d364175d31a",
            "value": " 6.50k/? [00:00&lt;00:00, 116kB/s]"
          }
        },
        "cce2c3e42e2042d28be4d32dfa11cfe8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d14078eeea3a4803b7d374a027858748": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22324476ef2147658a865f05cab3b10e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "223b58e0bbd44aad9ce21c333a80c7c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b735dc9007a46a980c3b58b3c9cc2b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba9b465ccd054485934e9333841e6a30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1733b484527b47e7807c2d364175d31a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb0d68f2989c45379de87b4f20c681f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5859d5d8e89e4b0487b3a4c045702fb5",
              "IPY_MODEL_91bb36d87c1e4dbf8bb5293a0af4fd4a",
              "IPY_MODEL_e629d1c60f324defb72073acc30c9daf"
            ],
            "layout": "IPY_MODEL_1bb9395ce92045998f72276742e32a50"
          }
        },
        "5859d5d8e89e4b0487b3a4c045702fb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfb920ed18544b73a5228cf3637ec439",
            "placeholder": "​",
            "style": "IPY_MODEL_b7021a3ce51a430ca34171b0fb7c21d1",
            "value": "Downloading builder script: "
          }
        },
        "91bb36d87c1e4dbf8bb5293a0af4fd4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa320d71e2a443fc9fa7a17e3764a94e",
            "max": 1652,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7dd0c488cf7c4b12a269cde8cb9896bd",
            "value": 1652
          }
        },
        "e629d1c60f324defb72073acc30c9daf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8d71b08aa2441cbbce65b62138325fd",
            "placeholder": "​",
            "style": "IPY_MODEL_6b896addf7154292bc73a992bff5545f",
            "value": " 4.21k/? [00:00&lt;00:00, 124kB/s]"
          }
        },
        "1bb9395ce92045998f72276742e32a50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfb920ed18544b73a5228cf3637ec439": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7021a3ce51a430ca34171b0fb7c21d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa320d71e2a443fc9fa7a17e3764a94e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dd0c488cf7c4b12a269cde8cb9896bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8d71b08aa2441cbbce65b62138325fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b896addf7154292bc73a992bff5545f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MLFlexer/nlp-course/blob/Emma/bert_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X72usktzzUIF",
        "outputId": "d25e44d9-0e10-4b0e-d5b8-5783a68b7607"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bpemb in /usr/local/lib/python3.10/dist-packages (0.3.4)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from bpemb) (4.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bpemb) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bpemb) (2.31.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from bpemb) (0.1.99)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from bpemb) (4.66.1)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim->bpemb) (1.11.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->bpemb) (6.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb) (2023.7.22)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.17.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.34.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "2023-10-21 13:54:03.677187: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-21 13:54:04.708384: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-10-21 13:54:06.082558: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-21 13:54:06.083050: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-21 13:54:06.083233: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "Collecting en-core-web-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!pip install bpemb\n",
        "!pip install gensim\n",
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add-in as occasionally receive an error which requires this to be added\n",
        "# uncomment if the issue arises\n",
        "!pip install transformer[torch]"
      ],
      "metadata": {
        "id": "j1FeucwT_K-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b1f4a4d-283c-4cd4-f87b-a246c036fec2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement transformer[torch] (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for transformer[torch]\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import torch\n",
        "import datasets\n",
        "datasets.logging.set_verbosity_error()\n",
        "from datasets import load_metric\n",
        "from google.colab import drive\n",
        "from transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModelForSequenceClassification\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import f1_score\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# # uncomment if CAN'T CONNECT TO GPU (it happens...)\n",
        "# import psutil\n",
        "# import platform"
      ],
      "metadata": {
        "id": "erIIBBN-ebGV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to save output of models so they can be reloaded\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "output_dir = '/content/drive/My Drive/Colab Notebooks/NLP/'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OD-nst6u-7jc",
        "outputId": "3b121730-3390-459b-e192-667c4531564d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU housekeeping code: you do not need to modify anything, simply\n",
        "# read through it to understand what is going on, and run as is\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# a helper function to format byte counts into KB, MB and so on\n",
        "def bytes_format(b):\n",
        "    if b < 1000:\n",
        "              return f'{b} B'\n",
        "    elif b < 1000000:\n",
        "        return f'{round(float(b/1000),2)} KB'\n",
        "    elif b < 1000000000:\n",
        "        return f'{round(float(b/1000000),2)} MB'\n",
        "    else:\n",
        "        return f'{round(float(b/1000000000),2)} GB'\n",
        "\n",
        "# a helper function to check the amount of available memory\n",
        "def memory_report():\n",
        "  if device!='cpu':\n",
        "    print(f\"GPU available: {torch.cuda.get_device_name()}\")\n",
        "    #print(torch.cuda.memory_summary())\n",
        "    total = torch.cuda.get_device_properties(0).total_memory\n",
        "    reserved = torch.cuda.memory_reserved(0)\n",
        "    allocated = torch.cuda.memory_allocated(0)\n",
        "  #  free = reserved-allocated  # free inside memory_reserved\n",
        "    print(f\"Total cuda memory: {bytes_format(total)}, reserved: {bytes_format(reserved)}, allocated: {bytes_format(allocated)}\")\n",
        "  else:\n",
        "    # Print total memory available on CPU\n",
        "    print(f'Device is CPU {platform.processor()}. GPU is not available rn')\n",
        "    total_memory = psutil.virtual_memory().total\n",
        "    print(f\"Total CPU memory: {bytes_format(total_memory)}\")\n",
        "\n",
        "memory_report()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6T11MhtBdv1P",
        "outputId": "fa6b67d4-8273-4666-81ea-315c6c46a4aa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available: Tesla T4\n",
            "Total cuda memory: 15.84 GB, reserved: 0 B, allocated: 0 B\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AheXHlZxQ38o"
      },
      "outputs": [],
      "source": [
        "# Preamble\n",
        "import sys\n",
        "\n",
        "sys.path.append('..')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "8Z5S6IwPQ38o",
        "outputId": "769acf66-3837-4d97-da52-3d34260ae718"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116067\n",
            "13325\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            question_text document_title  language  \\\n",
              "0            Milloin Charles Fort syntyi?   Charles Fort   finnish   \n",
              "1             “ダン” ダニエル・ジャドソン・キャラハンの出身はどこ   ダニエル・J・キャラハン  japanese   \n",
              "2  వేప చెట్టు యొక్క శాస్త్రీయ నామం ఏమిటి?            వేప    telugu   \n",
              "3      চেঙ্গিস খান কোন বংশের রাজা ছিলেন ?    চেঙ্গিজ খান   bengali   \n",
              "4        రెయ్యలగడ్ద గ్రామ విస్తీర్ణత ఎంత?     రెయ్యలగడ్ద    telugu   \n",
              "\n",
              "                                         annotations  \\\n",
              "0  {'answer_start': [18], 'answer_text': ['6. elo...   \n",
              "1  {'answer_start': [35], 'answer_text': ['カリフォルニ...   \n",
              "2  {'answer_start': [12], 'answer_text': ['Azadir...   \n",
              "3  {'answer_start': [414], 'answer_text': ['বোরজি...   \n",
              "4  {'answer_start': [259], 'answer_text': ['27 హె...   \n",
              "\n",
              "                                  document_plaintext  \\\n",
              "0  Charles Hoy Fort (6. elokuuta (joidenkin lähte...   \n",
              "1  “ダン”こと、ダニエル・ジャドソン・キャラハンは1890年7月26日、カリフォルニア州サンフ...   \n",
              "2  వేప (లాటిన్ Azadirachta indica, syn. Melia aza...   \n",
              "3  চেঙ্গিজ খান (মঙ্গোলীয়: Чингис Хаан  আ-ধ্ব-ব: ...   \n",
              "4  రెయ్యలగడ్ద, విశాఖపట్నం జిల్లా, గంగరాజు మాడుగుల...   \n",
              "\n",
              "                                        document_url  \n",
              "0       https://fi.wikipedia.org/wiki/Charles%20Fort  \n",
              "1  https://ja.wikipedia.org/wiki/%E3%83%80%E3%83%...  \n",
              "2  https://te.wikipedia.org/wiki/%E0%B0%B5%E0%B1%...  \n",
              "3  https://bn.wikipedia.org/wiki/%E0%A6%9A%E0%A7%...  \n",
              "4  https://te.wikipedia.org/wiki/%E0%B0%B0%E0%B1%...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6e04fe78-c798-4a57-9e7c-31895ecc47ee\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question_text</th>\n",
              "      <th>document_title</th>\n",
              "      <th>language</th>\n",
              "      <th>annotations</th>\n",
              "      <th>document_plaintext</th>\n",
              "      <th>document_url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Milloin Charles Fort syntyi?</td>\n",
              "      <td>Charles Fort</td>\n",
              "      <td>finnish</td>\n",
              "      <td>{'answer_start': [18], 'answer_text': ['6. elo...</td>\n",
              "      <td>Charles Hoy Fort (6. elokuuta (joidenkin lähte...</td>\n",
              "      <td>https://fi.wikipedia.org/wiki/Charles%20Fort</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>“ダン” ダニエル・ジャドソン・キャラハンの出身はどこ</td>\n",
              "      <td>ダニエル・J・キャラハン</td>\n",
              "      <td>japanese</td>\n",
              "      <td>{'answer_start': [35], 'answer_text': ['カリフォルニ...</td>\n",
              "      <td>“ダン”こと、ダニエル・ジャドソン・キャラハンは1890年7月26日、カリフォルニア州サンフ...</td>\n",
              "      <td>https://ja.wikipedia.org/wiki/%E3%83%80%E3%83%...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>వేప చెట్టు యొక్క శాస్త్రీయ నామం ఏమిటి?</td>\n",
              "      <td>వేప</td>\n",
              "      <td>telugu</td>\n",
              "      <td>{'answer_start': [12], 'answer_text': ['Azadir...</td>\n",
              "      <td>వేప (లాటిన్ Azadirachta indica, syn. Melia aza...</td>\n",
              "      <td>https://te.wikipedia.org/wiki/%E0%B0%B5%E0%B1%...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>চেঙ্গিস খান কোন বংশের রাজা ছিলেন ?</td>\n",
              "      <td>চেঙ্গিজ খান</td>\n",
              "      <td>bengali</td>\n",
              "      <td>{'answer_start': [414], 'answer_text': ['বোরজি...</td>\n",
              "      <td>চেঙ্গিজ খান (মঙ্গোলীয়: Чингис Хаан  আ-ধ্ব-ব: ...</td>\n",
              "      <td>https://bn.wikipedia.org/wiki/%E0%A6%9A%E0%A7%...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>రెయ్యలగడ్ద గ్రామ విస్తీర్ణత ఎంత?</td>\n",
              "      <td>రెయ్యలగడ్ద</td>\n",
              "      <td>telugu</td>\n",
              "      <td>{'answer_start': [259], 'answer_text': ['27 హె...</td>\n",
              "      <td>రెయ్యలగడ్ద, విశాఖపట్నం జిల్లా, గంగరాజు మాడుగుల...</td>\n",
              "      <td>https://te.wikipedia.org/wiki/%E0%B0%B0%E0%B1%...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e04fe78-c798-4a57-9e7c-31895ecc47ee')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6e04fe78-c798-4a57-9e7c-31895ecc47ee button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6e04fe78-c798-4a57-9e7c-31895ecc47ee');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3502ca25-2e7c-43ec-91f6-e3780933f1b7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3502ca25-2e7c-43ec-91f6-e3780933f1b7')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3502ca25-2e7c-43ec-91f6-e3780933f1b7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "dataset = load_dataset(\"copenlu/answerable_tydiqa\")\n",
        "\n",
        "train_set = dataset[\"train\"]\n",
        "validation_set = dataset[\"validation\"]\n",
        "\n",
        "df_train = train_set.to_pandas()\n",
        "df_val = validation_set.to_pandas()\n",
        "\n",
        "print(len(df_train))\n",
        "print(len(df_val))\n",
        "\n",
        "df_train.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "15Hvm5s-Q38p"
      },
      "outputs": [],
      "source": [
        "# Get train and validation data for each language\n",
        "df_train_bengali = df_train[df_train['language'] == 'bengali']\n",
        "df_train_arabic = df_train[df_train['language'] == 'arabic']\n",
        "df_train_indonesian = df_train[df_train['language'] == 'indonesian']\n",
        "\n",
        "df_val_bengali = df_val[df_val['language'] == 'bengali']\n",
        "df_val_arabic = df_val[df_val['language'] == 'arabic']\n",
        "df_val_indonesian = df_val[df_val['language'] == 'indonesian']\n",
        "\n",
        "\n",
        "# For testing\n",
        "df_val_english = df_val[df_val['language'] == 'english']\n",
        "df_train_english = df_train[df_train['language'] == 'english']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WyIm3zKzQ38p",
        "outputId": "50486404-e1bc-480a-cab8-cf8dbb5591fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text  answerable\n",
              "30   Wound care encourages and speeds wound healing...           1\n",
              "47   Brothers Amos and Wilfrid Ayre founded Burntis...           1\n",
              "59   For species of mammals, larger brains (in abso...           1\n",
              "77   As from 31 March 1989, fishing vessel registra...           1\n",
              "106  When Quezon City was created in 1939, the foll...           1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7015da4e-063d-4bf0-a4ed-2f8508aa37fe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>answerable</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Wound care encourages and speeds wound healing...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Brothers Amos and Wilfrid Ayre founded Burntis...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>For species of mammals, larger brains (in abso...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>As from 31 March 1989, fishing vessel registra...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>When Quezon City was created in 1939, the foll...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7015da4e-063d-4bf0-a4ed-2f8508aa37fe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7015da4e-063d-4bf0-a4ed-2f8508aa37fe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7015da4e-063d-4bf0-a4ed-2f8508aa37fe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-99478615-2e65-4e82-8414-39c6b9c1cc4f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-99478615-2e65-4e82-8414-39c6b9c1cc4f')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-99478615-2e65-4e82-8414-39c6b9c1cc4f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Create a new dataframe with the combined documents and questions and add if they are answerable\n",
        "df_train_bengali_merged = pd.DataFrame({\n",
        "    'text':(df_train_bengali[\"document_plaintext\"] + df_train_bengali[\"question_text\"]),\n",
        "    'answerable':(df_train_bengali[\"annotations\"].apply(lambda x: 0 if x['answer_start'] == [-1] else 1))\n",
        "    })\n",
        "df_train_arabic_merged = pd.DataFrame({\n",
        "    'text': (df_train_arabic[\"document_plaintext\"] + df_train_arabic[\"question_text\"]),\n",
        "    'answerable': (df_train_arabic[\"annotations\"].apply(lambda x: 0 if x['answer_start'] == [-1] else 1))\n",
        "                                    })\n",
        "df_train_indonesian_merged = pd.DataFrame({\n",
        "    'text':(df_train_indonesian[\"document_plaintext\"] + df_train_indonesian[\"question_text\"]),\n",
        "    'answerable':(df_train_indonesian[\"annotations\"].apply(lambda x: 0 if x['answer_start'] == [-1] else 1))\n",
        "    })\n",
        "df_train_english_merged = pd.DataFrame({\n",
        "    'text':(df_train_english[\"document_plaintext\"] + df_train_english[\"question_text\"]),\n",
        "    'answerable':(df_train_english[\"annotations\"].apply(lambda x: 0 if x['answer_start'] == [-1] else 1))\n",
        "    })\n",
        "\n",
        "\n",
        "## Same for validation data\n",
        "df_val_bengali_merged = pd.DataFrame({\n",
        "    'text':(df_val_bengali[\"document_plaintext\"] + df_val_bengali[\"question_text\"]),\n",
        "    'answerable':(df_val_bengali[\"annotations\"].apply(lambda x: 0 if x['answer_start'] == [-1] else 1))\n",
        "    })\n",
        "df_val_arabic_merged = pd.DataFrame({\n",
        "    'text': (df_val_arabic[\"document_plaintext\"] + df_val_arabic[\"question_text\"]),\n",
        "    'answerable': (df_val_arabic[\"annotations\"].apply(lambda x: 0 if x['answer_start'] == [-1] else 1))\n",
        "                                    })\n",
        "df_val_indonesian_merged = pd.DataFrame({\n",
        "    'text':(df_val_indonesian[\"document_plaintext\"] + df_val_indonesian[\"question_text\"]),\n",
        "    'answerable':(df_val_indonesian[\"annotations\"].apply(lambda x: 0 if x['answer_start'] == [-1] else 1))\n",
        "    })\n",
        "df_val_english_merged = pd.DataFrame({\n",
        "    'text':(df_val_english[\"document_plaintext\"] + df_val_english[\"question_text\"]),\n",
        "    'answerable':(df_val_english[\"annotations\"].apply(lambda x: 0 if x['answer_start'] == [-1] else 1))\n",
        "    })\n",
        "\n",
        "df_val_english_merged.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "# Tokenize and encode the text data\n",
        "def tokenize_text(texts, max_length=128):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in texts:\n",
        "        encoded_text = tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        input_ids.append(encoded_text[\"input_ids\"])\n",
        "        attention_masks.append(encoded_text[\"attention_mask\"])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "train_input_ids, train_attention_masks = tokenize_text(df_train_english_merged[\"text\"].tolist())\n",
        "val_input_ids, val_attention_masks = tokenize_text(df_val_english_merged[\"text\"].tolist())\n",
        "train_labels = torch.tensor(df_train_english_merged[\"answerable\"].tolist())\n",
        "val_labels = torch.tensor(df_val_english_merged[\"answerable\"].tolist())\n"
      ],
      "metadata": {
        "id": "udS3DYSa06OW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_data = TensorDataset(train_input_ids.to('cuda'), train_attention_masks.to('cuda'), train_labels.to('cuda'))\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_input_ids.to('cuda'), val_attention_masks.to('cuda'), val_labels.to('cuda'))\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n"
      ],
      "metadata": {
        "id": "ucz_nOHB2Hpu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking if cuda is available\n",
        "print(torch.cuda.is_available())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T71fkMD29aY",
        "outputId": "cd474609-268d-4f90-a3b5-71a9ce02e3d1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2, output_attentions=True)\n",
        "model.cuda()  # Use GPU for training if available\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxJP_aEc2dPw",
        "outputId": "351a8030-c19d-485e-a74e-3718f693cb70"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the below is taken from the ASDS exam - check whether this is the way to do it or combine with the rest\n",
        "# first check for english version and then adapt for other languages\n",
        "!pip install transformers[torch] accelerate\n",
        "\n"
      ],
      "metadata": {
        "id": "4frZSJ6L2rMW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2868d54c-297c-4e4f-a7d7-73d09ca391a9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.34.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu118)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define parameters for the model\n",
        "training_args = TrainingArguments(output_dir=\"my_trainer\",\n",
        "                                  evaluation_strategy=\"steps\",\n",
        "                                  num_train_epochs=3.0,\n",
        "                                  per_device_train_batch_size=16,\n",
        "                                  eval_steps=500\n",
        "                                  )"
      ],
      "metadata": {
        "id": "pWD-6Sw1MZ4N"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the compute_metrics function for the trainer\n",
        "metric_f1 = load_metric('f1')\n",
        "metric_ac = load_metric('accuracy')\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    outputs, labels = eval_pred\n",
        "    predictions = np.argmax(outputs, axis=-1)\n",
        "    f1 = metric_f1.compute(predictions=predictions, references=labels)\n",
        "    ac = metric_ac.compute(predictions=predictions, references=labels)\n",
        "    return f1 | ac"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "3d310bb765214c37a2dae93a34281672",
            "01ac0a5bda474bffb7923a4b56851c1c",
            "9371bb918c7a4c76bf79793d8310a5eb",
            "9beb1ca53b4c46eea7a7371da21a4333",
            "cce2c3e42e2042d28be4d32dfa11cfe8",
            "d14078eeea3a4803b7d374a027858748",
            "22324476ef2147658a865f05cab3b10e",
            "223b58e0bbd44aad9ce21c333a80c7c0",
            "3b735dc9007a46a980c3b58b3c9cc2b2",
            "ba9b465ccd054485934e9333841e6a30",
            "1733b484527b47e7807c2d364175d31a",
            "eb0d68f2989c45379de87b4f20c681f7",
            "5859d5d8e89e4b0487b3a4c045702fb5",
            "91bb36d87c1e4dbf8bb5293a0af4fd4a",
            "e629d1c60f324defb72073acc30c9daf",
            "1bb9395ce92045998f72276742e32a50",
            "cfb920ed18544b73a5228cf3637ec439",
            "b7021a3ce51a430ca34171b0fb7c21d1",
            "aa320d71e2a443fc9fa7a17e3764a94e",
            "7dd0c488cf7c4b12a269cde8cb9896bd",
            "c8d71b08aa2441cbbce65b62138325fd",
            "6b896addf7154292bc73a992bff5545f"
          ]
        },
        "id": "rvB-DPQ22w0o",
        "outputId": "e9673273-1cca-4069-f343-fbd3bd963300"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-44264bb71349>:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric_f1 = load_metric('f1')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d310bb765214c37a2dae93a34281672"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb0d68f2989c45379de87b4f20c681f7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the trainer object\n",
        "trainer_eng = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_input_ids,\n",
        "    eval_dataset=val_input_ids,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "4iRSttSd7Sub"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f'Training loss:\\n {trainer.state.log_history[0][\"loss\"]}\\n {trainer.state.log_history[2][\"loss\"]}\\n {trainer.state.log_history[4][\"loss\"]}\\n')\n",
        "# print(f'Validation loss:\\n {trainer.state.log_history[1][\"eval_loss\"]}\\n {trainer.state.log_history[3][\"eval_loss\"]}\\n {trainer.state.log_history[5][\"eval_loss\"]}')"
      ],
      "metadata": {
        "id": "5wtbSst37X6q"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
        "epochs = 4\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n"
      ],
      "metadata": {
        "id": "PAourslR2gAy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a48e4dba-ffa6-4157-a83c-765be50d3923"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.device)\n",
        "print(train_input_ids[0].device)\n",
        "# print(attention_masks[0].device)\n",
        "print(train_labels.device)\n"
      ],
      "metadata": {
        "id": "GpmWsRHQ6ug8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82abbafd-bf77-4152-896d-981e9621f246"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "cpu\n",
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_ids.cuda()"
      ],
      "metadata": {
        "id": "qEJsKYlFfr8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af4eac63-4e27-447f-9f20-6a0fa98cee15"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   101,  56984,  13939,  ...,      0,      0,      0],\n",
              "        [   101,  10117,  16280,  ...,  10454, 106482,    102],\n",
              "        [   101,  18552,  42507,  ...,  10684,    119,    102],\n",
              "        ...,\n",
              "        [   101,  72447,  10133,  ...,      0,      0,      0],\n",
              "        [   101,  10167,  10105,  ...,  41654,    117,    102],\n",
              "        [   101,  10117,  16741,  ...,      0,      0,      0]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move input data to the GPU\n",
        "# inputs = [item.to(\"cuda\") for item in inputs]\n",
        "# attention_masks = [item.to(\"cuda\") for item in attention_masks]\n",
        "\n",
        "\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}\"):\n",
        "\n",
        "\n",
        "        inputs = batch[:2]\n",
        "        labels = batch[2]\n",
        "\n",
        "        model.zero_grad()\n",
        "        outputs = model(*inputs, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "    for batch in tqdm(val_dataloader, desc=f\"Evaluating Epoch {epoch + 1}\"):\n",
        "        inputs = batch[:2]\n",
        "        labels = batch[2]\n",
        "        with torch.no_grad():\n",
        "            outputs = model(*inputs)\n",
        "        logits = outputs.logits\n",
        "        predictions.extend(logits.argmax(dim=1).tolist())\n",
        "        true_labels.extend(labels.tolist())\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    report = classification_report(true_labels, predictions, target_names=[\"Not Answerable\", \"Answerable\"])\n",
        "    print(f\"Epoch {epoch + 1} - Accuracy: {accuracy:.4f}\")\n",
        "    print(report)\n",
        "\n",
        "# Saving to Google Drive\n",
        "    save_path = \"/content/drive/My Drive/Colab Notebooks/NLP/\"\n",
        "    with open(save_path + f\"results_epoch_{epoch}.txt\", 'w') as f:\n",
        "        f.write(f\"Epoch {epoch + 1} - Accuracy: {accuracy:.4f}\\n\")\n",
        "        f.write(report)\n",
        "\n"
      ],
      "metadata": {
        "id": "YSvNRwKT2nCp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5caa061b-0bb3-4cd0-fd43-f7b96518e9a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 231/231 [02:43<00:00,  1.42it/s]\n",
            "Evaluating Epoch 1: 100%|██████████| 31/31 [00:07<00:00,  4.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Accuracy: 0.8051\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Answerable       0.90      0.69      0.78       495\n",
            "    Answerable       0.75      0.92      0.83       495\n",
            "\n",
            "      accuracy                           0.81       990\n",
            "     macro avg       0.82      0.81      0.80       990\n",
            "  weighted avg       0.82      0.81      0.80       990\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 231/231 [02:42<00:00,  1.42it/s]\n",
            "Evaluating Epoch 2: 100%|██████████| 31/31 [00:07<00:00,  4.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 - Accuracy: 0.8323\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Answerable       0.87      0.78      0.82       495\n",
            "    Answerable       0.80      0.88      0.84       495\n",
            "\n",
            "      accuracy                           0.83       990\n",
            "     macro avg       0.84      0.83      0.83       990\n",
            "  weighted avg       0.84      0.83      0.83       990\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 231/231 [02:41<00:00,  1.43it/s]\n",
            "Evaluating Epoch 3: 100%|██████████| 31/31 [00:07<00:00,  4.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 - Accuracy: 0.8293\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Answerable       0.88      0.76      0.82       495\n",
            "    Answerable       0.79      0.90      0.84       495\n",
            "\n",
            "      accuracy                           0.83       990\n",
            "     macro avg       0.84      0.83      0.83       990\n",
            "  weighted avg       0.84      0.83      0.83       990\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 231/231 [02:42<00:00,  1.42it/s]\n",
            "Evaluating Epoch 4: 100%|██████████| 31/31 [00:07<00:00,  4.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 - Accuracy: 0.8313\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Answerable       0.87      0.78      0.82       495\n",
            "    Answerable       0.80      0.88      0.84       495\n",
            "\n",
            "      accuracy                           0.83       990\n",
            "     macro avg       0.83      0.83      0.83       990\n",
            "  weighted avg       0.83      0.83      0.83       990\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ...\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0  # Initialize the total loss for the epoch\n",
        "\n",
        "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}\"):\n",
        "        inputs = batch[:2]\n",
        "        labels = batch[2]\n",
        "\n",
        "        model.zero_grad()\n",
        "        outputs = model(*inputs, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()  # Accumulate the loss\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    average_loss = total_loss / len(train_dataloader)  # Compute the average loss for the epoch\n",
        "\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "    for batch in tqdm(val_dataloader, desc=f\"Evaluating Epoch {epoch + 1}\"):\n",
        "        inputs = batch[:2]\n",
        "        labels = batch[2]\n",
        "        with torch.no_grad():\n",
        "            outputs = model(*inputs)\n",
        "        logits = outputs.logits\n",
        "        predictions.extend(logits.argmax(dim=1).tolist())\n",
        "        true_labels.extend(labels.tolist())\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    report = classification_report(true_labels, predictions, target_names=[\"Not Answerable\", \"Answerable\"])\n",
        "    print(f\"Epoch {epoch + 1} - Accuracy: {accuracy:.4f} - Average Loss: {average_loss:.4f}\")\n",
        "    print(report)\n",
        "\n",
        "    # Saving to Google Drive\n",
        "    save_path = \"/content/drive/My Drive/Colab Notebooks/NLP/\"\n",
        "    with open(save_path + f\"results_epoch_{epoch}.txt\", 'w') as f:\n",
        "        f.write(f\"Epoch {epoch + 1} - Accuracy: {accuracy:.4f} - Average Loss: {average_loss:.4f}\\n\")\n",
        "        f.write(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9Gmsd6uX5Be",
        "outputId": "894dc909-a568-4431-ada6-ec82db91961b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 231/231 [02:42<00:00,  1.42it/s]\n",
            "Evaluating Epoch 1: 100%|██████████| 31/31 [00:07<00:00,  4.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Accuracy: 0.8313 - Average Loss: 0.1060\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Answerable       0.87      0.78      0.82       495\n",
            "    Answerable       0.80      0.88      0.84       495\n",
            "\n",
            "      accuracy                           0.83       990\n",
            "     macro avg       0.83      0.83      0.83       990\n",
            "  weighted avg       0.83      0.83      0.83       990\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 231/231 [02:41<00:00,  1.43it/s]\n",
            "Evaluating Epoch 2: 100%|██████████| 31/31 [00:07<00:00,  4.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 - Accuracy: 0.8313 - Average Loss: 0.1093\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Answerable       0.87      0.78      0.82       495\n",
            "    Answerable       0.80      0.88      0.84       495\n",
            "\n",
            "      accuracy                           0.83       990\n",
            "     macro avg       0.83      0.83      0.83       990\n",
            "  weighted avg       0.83      0.83      0.83       990\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 231/231 [02:42<00:00,  1.42it/s]\n",
            "Evaluating Epoch 3: 100%|██████████| 31/31 [00:07<00:00,  4.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 - Accuracy: 0.8313 - Average Loss: 0.1079\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Answerable       0.87      0.78      0.82       495\n",
            "    Answerable       0.80      0.88      0.84       495\n",
            "\n",
            "      accuracy                           0.83       990\n",
            "     macro avg       0.83      0.83      0.83       990\n",
            "  weighted avg       0.83      0.83      0.83       990\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 231/231 [02:41<00:00,  1.43it/s]\n",
            "Evaluating Epoch 4: 100%|██████████| 31/31 [00:07<00:00,  4.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 - Accuracy: 0.8313 - Average Loss: 0.1065\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Answerable       0.87      0.78      0.82       495\n",
            "    Answerable       0.80      0.88      0.84       495\n",
            "\n",
            "      accuracy                           0.83       990\n",
            "     macro avg       0.83      0.83      0.83       990\n",
            "  weighted avg       0.83      0.83      0.83       990\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing the above model\n",
        "\n",
        "# Load the pre-trained BERT model and tokenizer\n",
        "\n",
        "# Sample input text for testing\n",
        "input_text = \"Sample input text for testing the BERT model.\"\n",
        "\n",
        "# Tokenize the input text\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "# Run inference\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# Interpret the outputs\n",
        "predicted_class = torch.argmax(outputs.logits).item()\n",
        "predicted_probabilities = torch.softmax(outputs.logits, dim=1).tolist()[0]\n",
        "\n",
        "print(f\"Predicted Class: {predicted_class}\")\n",
        "print(f\"Predicted Probabilities: {predicted_probabilities}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "nHBrlIjaSnT1",
        "outputId": "bb45d99c-24ed-4319-9631-ec94e5d4c94c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-4fdc8dbad44e>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Run inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Interpret the outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1562\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1564\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1565\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1015\u001b[0;31m         embedding_output = self.embeddings(\n\u001b[0m\u001b[1;32m   1016\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2231\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2233\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a function for the training loop"
      ],
      "metadata": {
        "id": "sSwgwJzEjf4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For Indonesian\n",
        "\n",
        "train_input_ids_indonesian, train_attention_masks_indonesian = tokenize_text(df_train_indonesian_merged[\"text\"].tolist())\n",
        "val_input_ids_indonesian, val_attention_masks_indonesian = tokenize_text(df_val_indonesian_merged[\"text\"].tolist())\n",
        "train_labels_indonesian = torch.tensor(df_train_indonesian_merged[\"answerable\"].tolist())\n",
        "val_labels_indonesian = torch.tensor(df_val_indonesian_merged[\"answerable\"].tolist())\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_data_indonesian = TensorDataset(train_input_ids_indonesian.to('cuda'), train_attention_masks_indonesian.to('cuda'), train_labels_indonesian.to('cuda'))\n",
        "train_sampler_indonesian = RandomSampler(train_data_indonesian)\n",
        "train_dataloader_indonesian = DataLoader(train_data_indonesian, sampler=train_sampler_indonesian, batch_size=batch_size)\n",
        "\n",
        "val_data_indonesian = TensorDataset(val_input_ids_indonesian.to('cuda'), val_attention_masks_indonesian.to('cuda'), val_labels_indonesian.to('cuda'))\n",
        "val_sampler_indonesian = SequentialSampler(val_data_indonesian)\n",
        "val_dataloader_indonesian = DataLoader(val_data_indonesian, sampler=val_sampler_indonesian, batch_size=batch_size)\n",
        "\n"
      ],
      "metadata": {
        "id": "sEUUfCWN3p4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the trainer object\n",
        "trainer_indonesian = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_input_ids_indonesian,\n",
        "    eval_dataset=val_input_ids_indonesian,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "b1p4wc2PJsId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
        "epochs = 4\n",
        "total_steps = len(train_dataloader_indonesian) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsKw_Dh6Js3U",
        "outputId": "425429a3-7b6e-416a-9739-87b2a509d99c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(\"cuda\")\n",
        "\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0  # Initialize the total loss for the epoch\n",
        "\n",
        "    for batch in tqdm(train_dataloader_indonesian, desc=f\"Epoch {epoch + 1}\"):\n",
        "        inputs = batch[:2]\n",
        "        labels = batch[2]\n",
        "\n",
        "        model.zero_grad()\n",
        "        outputs = model(*inputs, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()  # Accumulate the loss\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    average_loss = total_loss / len(train_dataloader_indonesian)  # Compute the average loss for the epoch\n",
        "\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "    for batch in tqdm(val_dataloader_indonesian, desc=f\"Evaluating Epoch {epoch + 1}\"):\n",
        "        inputs = batch[:2]\n",
        "        labels = batch[2]\n",
        "        with torch.no_grad():\n",
        "            outputs = model(*inputs)\n",
        "        logits = outputs.logits\n",
        "        predictions.extend(logits.argmax(dim=1).tolist())\n",
        "        true_labels.extend(labels.tolist())\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    report = classification_report(true_labels, predictions, target_names=[\"Not Answerable\", \"Answerable\"])\n",
        "    print(f\"Epoch {epoch + 1} - Accuracy: {accuracy:.4f} - Average Loss: {average_loss:.4f}\")\n",
        "    print(report)\n",
        "\n",
        "    # Saving to Google Drive\n",
        "    save_path = \"/content/drive/My Drive/Colab Notebooks/NLP/\"\n",
        "    with open(save_path + f\"indonesian_results_epoch_{epoch}.txt\", 'w') as f:\n",
        "        f.write(f\"Epoch {epoch + 1} - Accuracy: {accuracy:.4f}\\n\")\n",
        "        f.write(report)"
      ],
      "metadata": {
        "id": "IpV_1rKN29Yr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e06b460-fd5c-4003-c4e7-900ab57c8edd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 357/357 [04:09<00:00,  1.43it/s]\n",
            "Evaluating Epoch 1: 100%|██████████| 38/38 [00:08<00:00,  4.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Accuracy: 0.8279 - Average Loss: 0.3813\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Answerable       0.90      0.74      0.81       594\n",
            "    Answerable       0.78      0.92      0.84       597\n",
            "\n",
            "      accuracy                           0.83      1191\n",
            "     macro avg       0.84      0.83      0.83      1191\n",
            "  weighted avg       0.84      0.83      0.83      1191\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 357/357 [04:09<00:00,  1.43it/s]\n",
            "Evaluating Epoch 2: 100%|██████████| 38/38 [00:08<00:00,  4.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 - Accuracy: 0.8657 - Average Loss: 0.2745\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Answerable       0.86      0.87      0.87       594\n",
            "    Answerable       0.87      0.86      0.87       597\n",
            "\n",
            "      accuracy                           0.87      1191\n",
            "     macro avg       0.87      0.87      0.87      1191\n",
            "  weighted avg       0.87      0.87      0.87      1191\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 357/357 [04:10<00:00,  1.43it/s]\n",
            "Evaluating Epoch 3: 100%|██████████| 38/38 [00:08<00:00,  4.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 - Accuracy: 0.8665 - Average Loss: 0.1866\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Answerable       0.86      0.87      0.87       594\n",
            "    Answerable       0.87      0.86      0.87       597\n",
            "\n",
            "      accuracy                           0.87      1191\n",
            "     macro avg       0.87      0.87      0.87      1191\n",
            "  weighted avg       0.87      0.87      0.87      1191\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 357/357 [04:08<00:00,  1.43it/s]\n",
            "Evaluating Epoch 4: 100%|██████████| 38/38 [00:08<00:00,  4.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 - Accuracy: 0.8623 - Average Loss: 0.1254\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Answerable       0.87      0.85      0.86       594\n",
            "    Answerable       0.86      0.87      0.86       597\n",
            "\n",
            "      accuracy                           0.86      1191\n",
            "     macro avg       0.86      0.86      0.86      1191\n",
            "  weighted avg       0.86      0.86      0.86      1191\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For Bengali\n",
        "\n",
        "train_input_ids_bengali, train_attention_masks_bengali = tokenize_text(df_train_bengali_merged[\"text\"].tolist())\n",
        "val_input_ids_bengali, val_attention_masks_bengali = tokenize_text(df_val_bengali_merged[\"text\"].tolist())\n",
        "train_labels_bengali = torch.tensor(df_train_bengali_merged[\"answerable\"].tolist())\n",
        "val_labels_bengali = torch.tensor(df_val_bengali_merged[\"answerable\"].tolist())\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_data_bengali = TensorDataset(train_input_ids_bengali.to('cuda'), train_attention_masks_bengali.to('cuda'), train_labels_bengali.to('cuda'))\n",
        "train_sampler_bengali = RandomSampler(train_data_bengali)\n",
        "train_dataloader_bengali = DataLoader(train_data_bengali, sampler=train_sampler_bengali, batch_size=batch_size)\n",
        "\n",
        "val_data_bengali = TensorDataset(val_input_ids_bengali.to('cuda'), val_attention_masks_bengali.to('cuda'), val_labels_bengali.to('cuda'))\n",
        "val_sampler_bengali = SequentialSampler(val_data_bengali)\n",
        "val_dataloader_bengali = DataLoader(val_data_bengali, sampler=val_sampler_bengali, batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "s2xosqFqlV1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the trainer object\n",
        "trainer_bengali = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_input_ids_bengali,\n",
        "    eval_dataset=val_input_ids_bengali,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "9QazchflKT1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
        "epochs = 4\n",
        "total_steps = len(train_dataloader_bengali) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSvXOuJ9KT1y",
        "outputId": "94533791-9364-4fa0-d05a-591a5f20c897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a list to store losses\n",
        "train_losses = []\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0  # Initialize the total loss for the epoch\n",
        "\n",
        "    for batch in tqdm(train_dataloader_bengali, desc=f\"Epoch {epoch + 1}\"):\n",
        "        inputs = batch[:2]\n",
        "        labels = batch[2]\n",
        "\n",
        "        model.zero_grad()\n",
        "        outputs = model(*inputs, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()  # Accumulate the loss\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    average_loss = total_loss / len(train_dataloader_bengali)  # Compute the average loss for the epoch\n",
        "\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "    for batch in tqdm(val_dataloader_bengali, desc=f\"Evaluating Epoch {epoch + 1}\"):\n",
        "        inputs = batch[:2]\n",
        "        labels = batch[2]\n",
        "        with torch.no_grad():\n",
        "            outputs = model(*inputs)\n",
        "        logits = outputs.logits\n",
        "        predictions.extend(logits.argmax(dim=1).tolist())\n",
        "        true_labels.extend(labels.tolist())\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    report = classification_report(true_labels, predictions, target_names=[\"Not Answerable\", \"Answerable\"])\n",
        "    print(f\"Epoch {epoch + 1} - Accuracy: {accuracy:.4f} - Average Loss: {average_loss:.4f}\")\n",
        "    print(report)\n"
      ],
      "metadata": {
        "id": "6AGlWGEU4a_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d3c5ac0-613a-41a1-97d4-bd1f8a9d838e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 150/150 [01:46<00:00,  1.41it/s]\n",
            "Evaluating Epoch 1: 100%|██████████| 7/7 [00:01<00:00,  4.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Accuracy: 0.7589 - Average Loss: 0.4754\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Answerable       0.80      0.70      0.74       112\n",
            "    Answerable       0.73      0.82      0.77       112\n",
            "\n",
            "      accuracy                           0.76       224\n",
            "     macro avg       0.76      0.76      0.76       224\n",
            "  weighted avg       0.76      0.76      0.76       224\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 150/150 [01:45<00:00,  1.42it/s]\n",
            "Evaluating Epoch 2: 100%|██████████| 7/7 [00:01<00:00,  4.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 - Accuracy: 0.7768 - Average Loss: 0.3639\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Answerable       0.94      0.59      0.73       112\n",
            "    Answerable       0.70      0.96      0.81       112\n",
            "\n",
            "      accuracy                           0.78       224\n",
            "     macro avg       0.82      0.78      0.77       224\n",
            "  weighted avg       0.82      0.78      0.77       224\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 150/150 [01:45<00:00,  1.42it/s]\n",
            "Evaluating Epoch 3: 100%|██████████| 7/7 [00:01<00:00,  4.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 - Accuracy: 0.7812 - Average Loss: 0.2605\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Answerable       0.90      0.63      0.74       112\n",
            "    Answerable       0.72      0.93      0.81       112\n",
            "\n",
            "      accuracy                           0.78       224\n",
            "     macro avg       0.81      0.78      0.78       224\n",
            "  weighted avg       0.81      0.78      0.78       224\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 150/150 [01:45<00:00,  1.42it/s]\n",
            "Evaluating Epoch 4: 100%|██████████| 7/7 [00:01<00:00,  4.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 - Accuracy: 0.7768 - Average Loss: 0.1953\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Answerable       0.87      0.65      0.74       112\n",
            "    Answerable       0.72      0.90      0.80       112\n",
            "\n",
            "      accuracy                           0.78       224\n",
            "     macro avg       0.80      0.78      0.77       224\n",
            "  weighted avg       0.80      0.78      0.77       224\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For Arabic\n",
        "\n",
        "train_input_ids_arabic, train_attention_masks_arabic = tokenize_text(df_train_arabic_merged[\"text\"].tolist())\n",
        "val_input_ids_arabic, val_attention_masks_arabic = tokenize_text(df_val_arabic_merged[\"text\"].tolist())\n",
        "train_labels_arabic = torch.tensor(df_train_arabic_merged[\"answerable\"].tolist())\n",
        "val_labels_arabic = torch.tensor(df_val_arabic_merged[\"answerable\"].tolist())\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_data_arabic = TensorDataset(train_input_ids_arabic.to('cuda'), train_attention_masks_arabic.to('cuda'), train_labels_arabic.to('cuda'))\n",
        "train_sampler_arabic = RandomSampler(train_data_arabic)\n",
        "train_dataloader_arabic = DataLoader(train_data_arabic, sampler=train_sampler_arabic, batch_size=batch_size)\n",
        "\n",
        "val_data_arabic = TensorDataset(val_input_ids_arabic.to('cuda'), val_attention_masks_arabic.to('cuda'), val_labels_arabic.to('cuda'))\n",
        "val_sampler_arabic = SequentialSampler(val_data_arabic)\n",
        "val_dataloader_arabic = DataLoader(val_data_arabic, sampler=val_sampler_arabic, batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "Gv3c87WBsjMf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_sampler_arabic)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGiQtU8_tmzT",
        "outputId": "a03d47d8-4124-4a0b-b981-67fd26add899"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29598"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the trainer object\n",
        "trainer_arabic = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_input_ids_arabic,\n",
        "    eval_dataset=val_input_ids_arabic,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "PlNmmKEWKVND"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
        "epochs = 4\n",
        "total_steps = len(train_dataloader_arabic) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n"
      ],
      "metadata": {
        "id": "v5j5uQw9KVNO"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(\"cuda\")\n",
        "\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0  # Initialize the total loss for the epoch\n",
        "\n",
        "    for batch in tqdm(train_dataloader_arabic, desc=f\"Epoch {epoch + 1}\"):\n",
        "        inputs = batch[:2]\n",
        "        labels = batch[2]\n",
        "\n",
        "        model.zero_grad()\n",
        "        outputs = model(*inputs, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()  # Accumulate the loss\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    average_loss = total_loss / len(train_dataloader_arabic)  # Compute the average loss for the epoch\n",
        "\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "    for batch in tqdm(val_dataloader_arabic, desc=f\"Evaluating Epoch {epoch + 1}\"):\n",
        "        inputs = batch[:2]\n",
        "        labels = batch[2]\n",
        "        with torch.no_grad():\n",
        "            outputs = model(*inputs)\n",
        "        logits = outputs.logits\n",
        "        predictions.extend(logits.argmax(dim=1).tolist())\n",
        "        true_labels.extend(labels.tolist())\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    report = classification_report(true_labels, predictions, target_names=[\"Not Answerable\", \"Answerable\"])\n",
        "    print(f\"Epoch {epoch + 1} - Accuracy: {accuracy:.4f} - Average Loss: {average_loss:.4f}\")\n",
        "    print(report)"
      ],
      "metadata": {
        "id": "V1r0WonD4gNv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31f20282-cf01-4414-d024-d64afc372e14"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 925/925 [10:17<00:00,  1.50it/s]\n",
            "Evaluating Epoch 1: 100%|██████████| 60/60 [00:12<00:00,  4.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Accuracy: 0.8891 - Average Loss: 0.3402\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Answerable       0.93      0.84      0.88       951\n",
            "    Answerable       0.85      0.94      0.89       951\n",
            "\n",
            "      accuracy                           0.89      1902\n",
            "     macro avg       0.89      0.89      0.89      1902\n",
            "  weighted avg       0.89      0.89      0.89      1902\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 925/925 [10:18<00:00,  1.50it/s]\n",
            "Evaluating Epoch 2: 100%|██████████| 60/60 [00:12<00:00,  4.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 - Accuracy: 0.8828 - Average Loss: 0.2418\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Answerable       0.94      0.82      0.87       951\n",
            "    Answerable       0.84      0.95      0.89       951\n",
            "\n",
            "      accuracy                           0.88      1902\n",
            "     macro avg       0.89      0.88      0.88      1902\n",
            "  weighted avg       0.89      0.88      0.88      1902\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 925/925 [10:18<00:00,  1.50it/s]\n",
            "Evaluating Epoch 3: 100%|██████████| 60/60 [00:12<00:00,  4.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 - Accuracy: 0.8938 - Average Loss: 0.1766\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Answerable       0.92      0.86      0.89       951\n",
            "    Answerable       0.87      0.93      0.90       951\n",
            "\n",
            "      accuracy                           0.89      1902\n",
            "     macro avg       0.90      0.89      0.89      1902\n",
            "  weighted avg       0.90      0.89      0.89      1902\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 925/925 [10:18<00:00,  1.49it/s]\n",
            "Evaluating Epoch 4: 100%|██████████| 60/60 [00:12<00:00,  4.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 - Accuracy: 0.8875 - Average Loss: 0.1314\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Answerable       0.91      0.86      0.88       951\n",
            "    Answerable       0.87      0.92      0.89       951\n",
            "\n",
            "      accuracy                           0.89      1902\n",
            "     macro avg       0.89      0.89      0.89      1902\n",
            "  weighted avg       0.89      0.89      0.89      1902\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# attempt for week 41 exercise\n",
        "\n",
        "# Assuming you want to visualize attention for a specific instance (e.g., the first instance in the validation dataset)\n",
        "instance_index = 0\n",
        "\n",
        "# Prepare input for the selected instance\n",
        "inputs = {\n",
        "    'input_ids': val_input_ids_arabic[instance_index].unsqueeze(0).to('cuda'),\n",
        "    'attention_mask': val_attention_masks_arabic[instance_index].unsqueeze(0).to('cuda')\n",
        "}\n",
        "\n",
        "# Pass the input through the model to get attentions\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "attentions_arabic = outputs.attentions  # This will contain attention scores for different layers"
      ],
      "metadata": {
        "id": "cLufZMzFmmEL"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you want to visualize attention for layer 3, head 0\n",
        "layer_idx = 3\n",
        "head_idx = 0\n",
        "\n",
        "# Get the attention scores for the selected layer and head\n",
        "attention_matrix = attentions_arabic[layer_idx][0][head_idx].cpu().numpy()\n",
        "\n",
        "# Create a heatmap\n",
        "plt.figure(figsize=(8, 8))\n",
        "sns.heatmap(attention_matrix, cmap='YlGnBu', xticklabels=False, yticklabels=False)\n",
        "plt.title(f'Attention Map for Layer {layer_idx}, Head {head_idx}')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "b9NxRxN13TQx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "16319735-85ba-4179-89e6-1380af0c9c12"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hg5yMH223eDf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}