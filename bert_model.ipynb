{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOV63UXilUu0lTB11/Da34A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f3dfad4277bf49179df5b01f8bd4687c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d4c04a80443418da3eeace329219344",
              "IPY_MODEL_fe79e5e730654372b5c6c6d102e9dc03",
              "IPY_MODEL_73c681de0aa4449c9268b091cae0e52d"
            ],
            "layout": "IPY_MODEL_315d768d24c147b9965bffad14ae42b5"
          }
        },
        "1d4c04a80443418da3eeace329219344": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8123bcc6aa6641f58acce823df8e05f6",
            "placeholder": "​",
            "style": "IPY_MODEL_89f57067bbf84d769f06053f4df7c785",
            "value": "Map: 100%"
          }
        },
        "fe79e5e730654372b5c6c6d102e9dc03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84d78e969a7f40eb9d588f342b522264",
            "max": 4779,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b73a08e3fdcf4c0da018eb4b077747f5",
            "value": 4779
          }
        },
        "73c681de0aa4449c9268b091cae0e52d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8859b9790d1a4cd181ec1c6772ef681c",
            "placeholder": "​",
            "style": "IPY_MODEL_1255aaaf5e7941c3a10c43e835b124f6",
            "value": " 4779/4779 [00:11&lt;00:00, 494.52 examples/s]"
          }
        },
        "315d768d24c147b9965bffad14ae42b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8123bcc6aa6641f58acce823df8e05f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89f57067bbf84d769f06053f4df7c785": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84d78e969a7f40eb9d588f342b522264": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b73a08e3fdcf4c0da018eb4b077747f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8859b9790d1a4cd181ec1c6772ef681c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1255aaaf5e7941c3a10c43e835b124f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MLFlexer/nlp-course/blob/malthe/bert_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Made with the help of this guide: https://huggingface.co/docs/transformers/tasks/question_answering\n"
      ],
      "metadata": {
        "id": "ZTpCe2R1L_yd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets transformers evaluate\n",
        "!pip install accelerate -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mAF--cPLf5y",
        "outputId": "3d58685d-935f-4662-927e-306f988b223e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.5)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.34.1)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.17.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "XB3XXwrpLZLp"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"copenlu/answerable_tydiqa\")\n",
        "\n",
        "train_set = dataset[\"train\"]\n",
        "validation_set = dataset[\"validation\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = train_set.to_dict()\n",
        "\n",
        "unique_ids = list(range(len(train_set['question_text'])))\n",
        "\n",
        "# Add the 'example_id' key to the dataset with the unique IDs\n",
        "train_set['example_id'] = unique_ids\n",
        "train_set = datasets.from_dict(train_set)"
      ],
      "metadata": {
        "id": "2u_IiImPAmsx",
        "outputId": "05acbf8d-cf85-4325-a10e-4e6341c07bcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-144-f66454c1eea1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0munique_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Add the 'example_id' key to the dataset with the unique IDs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'to_dict'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your dataset is a list of dictionaries\n",
        "\n",
        "\n",
        "# Create a set to store unique URLs\n",
        "unique_urls = set()\n",
        "\n",
        "# Iterate through the dataset and add document URLs to the set\n",
        "for data_point in train_set:\n",
        "    document_url = data_point.get('example_id', None)\n",
        "    if document_url:\n",
        "        unique_urls.add(document_url)\n",
        "\n",
        "# Count the number of unique document URLs\n",
        "num_unique_urls = len(unique_urls)\n",
        "\n",
        "print(f\"Number of unique document URLs: {num_unique_urls}\")\n",
        "print(len(train_set))\n"
      ],
      "metadata": {
        "id": "Z2mrHr_r_70x",
        "outputId": "9b35c831-ae95-43c4-abfd-83f24f1cec70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique document URLs: 35508\n",
            "116067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set"
      ],
      "metadata": {
        "id": "4TGNeidIAUle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeTDJL35LvwO",
        "outputId": "c129138a-a226-42ab-cddd-95c06d4f3c90"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question_text': 'Milloin Charles Fort syntyi?',\n",
              " 'document_title': 'Charles Fort',\n",
              " 'language': 'finnish',\n",
              " 'annotations': {'answer_start': [18],\n",
              "  'answer_text': ['6. elokuuta (joidenkin lähteiden mukaan 9.) 1874']},\n",
              " 'document_plaintext': 'Charles Hoy Fort (6. elokuuta (joidenkin lähteiden mukaan 9.) 1874 – 3. toukokuuta 1932) oli yhdysvaltalainen kirjailija ja paranormaalien ilmiöiden tutkija.',\n",
              " 'document_url': 'https://fi.wikipedia.org/wiki/Charles%20Fort'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"validation\"]"
      ],
      "metadata": {
        "id": "6QuC7vtIu_D8",
        "outputId": "10e5fff2-0895-4e81-c3c6-f7aa4ed963dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['question_text', 'document_title', 'language', 'annotations', 'document_plaintext', 'document_url'],\n",
              "    num_rows: 13325\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_dataset = dataset.filter(lambda entry: entry[\"language\"] in [\"bengali\"])\n",
        "filtered_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ycXYQaAP7LW",
        "outputId": "55a3bcf1-c6df-4bce-8538-e4ce3d572784"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['question_text', 'document_title', 'language', 'annotations', 'document_plaintext', 'document_url'],\n",
              "        num_rows: 4779\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['question_text', 'document_title', 'language', 'annotations', 'document_plaintext', 'document_url'],\n",
              "        num_rows: 224\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-uncased\")"
      ],
      "metadata": {
        "id": "gDVUq039L9aJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 384\n",
        "stride = 128\n",
        "\n",
        "\n",
        "def preprocess_training_examples(examples):\n",
        "    questions = [q.strip() for q in examples[\"question_text\"]]\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples[\"document_plaintext\"],\n",
        "        max_length=max_length,\n",
        "        truncation=\"only_second\",\n",
        "        stride=stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
        "    answers = examples[\"annotations\"]\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offset in enumerate(offset_mapping):\n",
        "        sample_idx = sample_map[i]\n",
        "        answer = answers[sample_idx]\n",
        "        start_char = answer[\"answer_start\"][0]\n",
        "        end_char = answer[\"answer_start\"][0] + len(answer[\"answer_text\"][0])\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "        # Find the start and end of the context\n",
        "        idx = 0\n",
        "        while sequence_ids[idx] != 1:\n",
        "            idx += 1\n",
        "        context_start = idx\n",
        "        while sequence_ids[idx] == 1:\n",
        "            idx += 1\n",
        "        context_end = idx - 1\n",
        "\n",
        "        # If the answer is not fully inside the context, label is (0, 0)\n",
        "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            # Otherwise it's the start and end token positions\n",
        "            idx = context_start\n",
        "            while idx <= context_end and offset[idx][0] <= start_char:\n",
        "                idx += 1\n",
        "            start_positions.append(idx - 1)\n",
        "\n",
        "            idx = context_end\n",
        "            while idx >= context_start and offset[idx][1] >= end_char:\n",
        "                idx -= 1\n",
        "            end_positions.append(idx + 1)\n",
        "\n",
        "    inputs[\"start_positions\"] = start_positions\n",
        "    inputs[\"end_positions\"] = end_positions\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "6Yhka9Uhzpfp"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = filtered_dataset[\"train\"].map(\n",
        "    preprocess_training_examples,\n",
        "    batched=True,\n",
        "    remove_columns=filtered_dataset[\"train\"].column_names,\n",
        ")\n",
        "len(filtered_dataset[\"train\"]), len(train_dataset)"
      ],
      "metadata": {
        "id": "mz8uofwjz9N5",
        "outputId": "867f2827-b019-471f-fa3f-61d81b4c4ac0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "f3dfad4277bf49179df5b01f8bd4687c",
            "1d4c04a80443418da3eeace329219344",
            "fe79e5e730654372b5c6c6d102e9dc03",
            "73c681de0aa4449c9268b091cae0e52d",
            "315d768d24c147b9965bffad14ae42b5",
            "8123bcc6aa6641f58acce823df8e05f6",
            "89f57067bbf84d769f06053f4df7c785",
            "84d78e969a7f40eb9d588f342b522264",
            "b73a08e3fdcf4c0da018eb4b077747f5",
            "8859b9790d1a4cd181ec1c6772ef681c",
            "1255aaaf5e7941c3a10c43e835b124f6"
          ]
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/4779 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3dfad4277bf49179df5b01f8bd4687c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4779, 5856)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_validation_examples(examples):\n",
        "    questions = [q.strip() for q in examples[\"question_text\"]]\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples[\"document_plaintext\"],\n",
        "        max_length=max_length,\n",
        "        truncation=\"only_second\",\n",
        "        stride=stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
        "    example_ids = []\n",
        "\n",
        "    for i in range(len(inputs[\"input_ids\"])):\n",
        "        sample_idx = sample_map[i]\n",
        "        example_ids.append(examples[\"document_url\"][sample_idx])\n",
        "\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "        offset = inputs[\"offset_mapping\"][i]\n",
        "        inputs[\"offset_mapping\"][i] = [\n",
        "            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
        "        ]\n",
        "\n",
        "    inputs[\"example_id\"] = example_ids\n",
        "\n",
        "    offset_mapping = inputs[\"offset_mapping\"]\n",
        "    answers = examples[\"annotations\"]\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offset in enumerate(offset_mapping):\n",
        "        sample_idx = sample_map[i]\n",
        "        answer = answers[sample_idx]\n",
        "        start_char = answer[\"answer_start\"][0]\n",
        "        end_char = answer[\"answer_start\"][0] + len(answer[\"answer_text\"][0])\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "        # Find the start and end of the context\n",
        "        idx = 0\n",
        "        while sequence_ids[idx] != 1:\n",
        "            idx += 1\n",
        "        context_start = idx\n",
        "        while sequence_ids[idx] == 1:\n",
        "            idx += 1\n",
        "        context_end = idx - 1\n",
        "\n",
        "        # If the answer is not fully inside the context, label is (0, 0)\n",
        "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            # Otherwise it's the start and end token positions\n",
        "            idx = context_start\n",
        "            while idx <= context_end and offset[idx][0] <= start_char:\n",
        "                idx += 1\n",
        "            start_positions.append(idx - 1)\n",
        "\n",
        "            idx = context_end\n",
        "            while idx >= context_start and offset[idx][1] >= end_char:\n",
        "                idx -= 1\n",
        "            end_positions.append(idx + 1)\n",
        "\n",
        "    inputs[\"start_positions\"] = start_positions\n",
        "    inputs[\"end_positions\"] = end_positions\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "DQGNg-_I0bqh"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_dataset = filtered_dataset[\"validation\"].map(\n",
        "    preprocess_validation_examples,\n",
        "    batched=True,\n",
        "    remove_columns=filtered_dataset[\"validation\"].column_names,\n",
        ")\n",
        "len(filtered_dataset[\"validation\"]), len(validation_dataset)"
      ],
      "metadata": {
        "id": "Vyo1wQOf0kr1",
        "outputId": "9e4261d6-fc36-410c-cc86-c006bb4e5ad7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224, 267)"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_dataset[\"validation\"].column_names"
      ],
      "metadata": {
        "id": "TynrhQ8V-_dy",
        "outputId": "5075ae20-fcfd-41d8-d8e1-5d106057ca14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['question_text',\n",
              " 'document_title',\n",
              " 'language',\n",
              " 'annotations',\n",
              " 'document_plaintext',\n",
              " 'document_url']"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "small_eval_set = filtered_dataset[\"validation\"].select(range(100))\n",
        "\n",
        "eval_set = small_eval_set.map(\n",
        "    preprocess_validation_examples,\n",
        "    batched=True,\n",
        "    remove_columns=filtered_dataset[\"validation\"].column_names,\n",
        ")"
      ],
      "metadata": {
        "id": "vKfQ7hpK1gsU"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForQuestionAnswering\n",
        "\n",
        "eval_set_for_model = eval_set.remove_columns([\"example_id\", \"offset_mapping\", 'start_positions', 'end_positions'])\n",
        "eval_set_for_model.set_format(\"torch\")\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "batch = {k: eval_set_for_model[k].to(device) for k in eval_set_for_model.column_names}\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**batch)"
      ],
      "metadata": {
        "id": "oSl6el2G1rkh"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_logits = outputs.start_logits.cpu().numpy()\n",
        "end_logits = outputs.end_logits.cpu().numpy()"
      ],
      "metadata": {
        "id": "TmJzeCdB1ux_"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "example_to_features = collections.defaultdict(list)\n",
        "for idx, feature in enumerate(eval_set):\n",
        "    example_to_features[feature[\"example_id\"]].append(idx)"
      ],
      "metadata": {
        "id": "ReBl5Ant1wyM"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_to_features"
      ],
      "metadata": {
        "id": "MKMvFXS8_c5E",
        "outputId": "5451c16b-91b3-458c-ee94-80ad8b08639f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(list,\n",
              "            {'https://bn.wikipedia.org/wiki/%E0%A6%97%E0%A7%87%E0%A6%9F%E0%A6%93%E0%A6%AF%E0%A6%BC%E0%A7%87%20%E0%A6%85%E0%A6%AC%20%E0%A6%87%E0%A6%A8%E0%A7%8D%E0%A6%A1%E0%A6%BF%E0%A6%AF%E0%A6%BC%E0%A6%BE': [0],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AE%E0%A6%B9%E0%A6%BE%E0%A6%B6%E0%A7%8D%E0%A6%AC%E0%A7%87%E0%A6%A4%E0%A6%BE%20%E0%A6%A6%E0%A7%87%E0%A6%AC%E0%A7%80': [1,\n",
              "              34,\n",
              "              61],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%95%E0%A6%B2%E0%A6%95%E0%A6%BE%E0%A6%A4%E0%A6%BE%20%E0%A6%AE%E0%A7%87%E0%A6%9F%E0%A7%8D%E0%A6%B0%E0%A7%8B': [2,\n",
              "              3],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%A8%E0%A6%BF%E0%A6%95%E0%A7%8B%E0%A6%B2%E0%A6%BE%E0%A6%89%E0%A6%B8%20%E0%A6%95%E0%A7%8B%E0%A6%AA%E0%A7%87%E0%A6%B0%E0%A7%8D%E0%A6%A8%E0%A6%BF%E0%A6%95%E0%A7%81%E0%A6%B8': [4,\n",
              "              75,\n",
              "              120],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%B8%E0%A6%B0%E0%A7%8D%E0%A6%AC%E0%A7%8B%E0%A6%9A%E0%A7%8D%E0%A6%9A%20%E0%A6%89%E0%A6%B2%E0%A6%BE%E0%A6%AE%E0%A6%BE%20%E0%A6%AA%E0%A6%B0%E0%A6%BF%E0%A6%B7%E0%A6%A6%20%28%E0%A6%B8%E0%A7%8C%E0%A6%A6%E0%A6%BF%20%E0%A6%86%E0%A6%B0%E0%A6%AC%29': [5],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%9A%E0%A6%BF%E0%A6%A4%E0%A7%8D%E0%A6%B0%E0%A6%BE%20%E0%A6%AC%E0%A6%A8%E0%A7%8D%E0%A6%A6%E0%A7%8D%E0%A6%AF%E0%A7%8B%E0%A6%AA%E0%A6%BE%E0%A6%A7%E0%A7%8D%E0%A6%AF%E0%A6%BE%E0%A6%AF%E0%A6%BC%20%E0%A6%A6%E0%A6%BF%E0%A6%AC%E0%A6%BE%E0%A6%95%E0%A6%B0%E0%A7%82%E0%A6%A3%E0%A7%80': [6],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%97%E0%A7%81%E0%A6%97%E0%A6%B2': [7,\n",
              "              8,\n",
              "              65,\n",
              "              66,\n",
              "              108,\n",
              "              111,\n",
              "              112],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%B8%E0%A7%82%E0%A6%B0%E0%A7%8D%E0%A6%AF%20%E0%A6%B8%E0%A7%87%E0%A6%A8': [9],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AA%E0%A6%B9%E0%A7%87%E0%A6%B2%E0%A6%BE%20%E0%A6%AC%E0%A7%88%E0%A6%B6%E0%A6%BE%E0%A6%96': [10],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AE%E0%A6%BE%E0%A6%93%E0%A6%B2%E0%A6%BE%E0%A6%A8%E0%A6%BE%20%E0%A6%AD%E0%A6%BE%E0%A6%B8%E0%A6%BE%E0%A6%A8%E0%A7%80%20%E0%A6%AC%E0%A6%BF%E0%A6%9C%E0%A7%8D%E0%A6%9E%E0%A6%BE%E0%A6%A8%20%E0%A6%93%20%E0%A6%AA%E0%A7%8D%E0%A6%B0%E0%A6%AF%E0%A7%81%E0%A6%95%E0%A7%8D%E0%A6%A4%E0%A6%BF%20%E0%A6%AC%E0%A6%BF%E0%A6%B6%E0%A7%8D%E0%A6%AC%E0%A6%AC%E0%A6%BF%E0%A6%A6%E0%A7%8D%E0%A6%AF%E0%A6%BE%E0%A6%B2%E0%A6%AF%E0%A6%BC': [11,\n",
              "              128],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AE%E0%A6%A6%E0%A6%BF%E0%A6%A8%E0%A6%BE': [12],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AE%E0%A7%8B%E0%A6%B0%E0%A6%B6%E0%A7%87%E0%A6%A6%E0%A7%81%E0%A6%B2%20%E0%A6%87%E0%A6%B8%E0%A6%B2%E0%A6%BE%E0%A6%AE': [13,\n",
              "              14],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AE%E0%A7%81%E0%A6%B0%E0%A7%8D%E0%A6%B6%E0%A6%BF%E0%A6%A6%E0%A6%BE%E0%A6%AC%E0%A6%BE%E0%A6%A6%20%E0%A6%9C%E0%A7%87%E0%A6%B2%E0%A6%BE': [15],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%85%E0%A6%A6%E0%A7%8D%E0%A6%AC%E0%A7%88%E0%A6%A4%20%E0%A6%AE%E0%A6%B2%E0%A7%8D%E0%A6%B2%E0%A6%AC%E0%A6%B0%E0%A7%8D%E0%A6%AE%E0%A6%A3': [16],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AE%E0%A7%87%E0%A6%98%E0%A7%87%E0%A6%B0%20%E0%A6%95%E0%A7%8B%E0%A6%B2%E0%A7%87%20%E0%A6%B0%E0%A7%8B%E0%A6%A6': [17],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%A4%E0%A7%80%E0%A6%B0%E0%A7%8D%E0%A6%A5%E0%A6%99%E0%A7%8D%E0%A6%95%E0%A6%B0': [18],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%B2%E0%A6%BF%E0%A6%96%E0%A6%A8%20%E0%A6%AA%E0%A6%A6%E0%A7%8D%E0%A6%A7%E0%A6%A4%E0%A6%BF': [19],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%86%E0%A6%B2%E0%A6%9A%E0%A6%BF%20%E0%A6%AC%E0%A7%8C%E0%A6%A6%E0%A7%8D%E0%A6%A7%E0%A6%AC%E0%A6%BF%E0%A6%B9%E0%A6%BE%E0%A6%B0': [20],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%97%E0%A6%BE%E0%A6%AF%E0%A6%BC%E0%A6%BE%E0%A6%A8%E0%A6%BE': [21,\n",
              "              110],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%8F%E0%A6%B6%E0%A6%BF%E0%A6%AF%E0%A6%BC%E0%A6%BE%20%E0%A6%95%E0%A6%BE%E0%A6%AA': [22,\n",
              "              53,\n",
              "              124],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AE%E0%A6%AF%E0%A6%BC%E0%A7%81%E0%A6%96%20%E0%A6%9A%E0%A7%8C%E0%A6%A7%E0%A7%81%E0%A6%B0%E0%A7%80': [23],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AE%E0%A6%B2%E0%A6%AF%E0%A6%BC%20%E0%A6%B0%E0%A6%BE%E0%A6%AF%E0%A6%BC%E0%A6%9A%E0%A7%8C%E0%A6%A7%E0%A7%81%E0%A6%B0%E0%A7%80': [24,\n",
              "              25],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AE%E0%A6%BE%E0%A6%A8%E0%A7%81%E0%A6%B7': [26,\n",
              "              27,\n",
              "              28],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AC%E0%A7%81%E0%A6%B0%E0%A7%8D%E0%A6%9C%20%E0%A6%86%E0%A6%B2%20%E0%A6%86%E0%A6%B0%E0%A6%AC': [29],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%A8%E0%A6%BE%E0%A6%B0%E0%A7%80%E0%A6%AC%E0%A6%BE%E0%A6%A6': [30,\n",
              "              31],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%B8%E0%A7%8D%E0%A6%AC%E0%A6%BE%E0%A6%AE%E0%A7%80%20%E0%A6%AC%E0%A6%BF%E0%A6%AC%E0%A7%87%E0%A6%95%E0%A6%BE%E0%A6%A8%E0%A6%A8%E0%A7%8D%E0%A6%A6': [32,\n",
              "              91,\n",
              "              95,\n",
              "              96,\n",
              "              97,\n",
              "              98],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%9C%E0%A7%87%E0%A6%B2%20%E0%A6%B9%E0%A6%A4%E0%A7%8D%E0%A6%AF%E0%A6%BE%20%E0%A6%A6%E0%A6%BF%E0%A6%AC%E0%A6%B8': [33],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%86%E0%A6%A8%E0%A7%8D%E0%A6%A4%E0%A6%B0%E0%A7%8D%E0%A6%9C%E0%A6%BE%E0%A6%A4%E0%A6%BF%E0%A6%95%20%E0%A6%95%E0%A7%8D%E0%A6%B0%E0%A6%BF%E0%A6%95%E0%A7%87%E0%A6%9F%20%E0%A6%95%E0%A6%BE%E0%A6%89%E0%A6%A8%E0%A7%8D%E0%A6%B8%E0%A6%BF%E0%A6%B2%E0%A7%87%E0%A6%B0%20%E0%A6%B8%E0%A6%A6%E0%A6%B8%E0%A7%8D%E0%A6%AF%E0%A6%A6%E0%A7%87%E0%A6%B0%20%E0%A6%A4%E0%A6%BE%E0%A6%B2%E0%A6%BF%E0%A6%95%E0%A6%BE': [35],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AA%E0%A7%82%E0%A6%B0%E0%A7%8D%E0%A6%A3%E0%A6%BF%E0%A6%AE%E0%A6%BE%20%28%E0%A6%85%E0%A6%AD%E0%A6%BF%E0%A6%A8%E0%A7%87%E0%A6%A4%E0%A7%8D%E0%A6%B0%E0%A7%80%29': [36,\n",
              "              39,\n",
              "              52],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%A6%E0%A6%9C%E0%A6%B2%E0%A6%BE': [37],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%B9%E0%A6%BF%E0%A6%A8%E0%A7%8D%E0%A6%A6%E0%A6%BF%20%E0%A6%AD%E0%A6%BE%E0%A6%B7%E0%A6%BE': [38],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AA%E0%A6%B0%E0%A6%AE%E0%A6%BE%E0%A6%A3%E0%A7%81%20%E0%A6%85%E0%A6%B8%E0%A7%8D%E0%A6%A4%E0%A7%8D%E0%A6%B0%20%E0%A6%AA%E0%A6%B0%E0%A7%80%E0%A6%95%E0%A7%8D%E0%A6%B7%E0%A6%BE': [40],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AE%E0%A7%81%E0%A6%B9%E0%A6%BE%E0%A6%AE%E0%A7%8D%E0%A6%AE%E0%A6%A6%20%E0%A6%A6%E0%A6%BE%E0%A6%89%E0%A6%A6%20%E0%A6%96%E0%A6%BE%E0%A6%A8': [41],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AC%E0%A6%99%E0%A7%8D%E0%A6%97%E0%A6%AD%E0%A6%99%E0%A7%8D%E0%A6%97%20%28%E0%A7%A7%E0%A7%AF%E0%A7%A6%E0%A7%AB%29': [42],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%95%E0%A6%BE%E0%A6%B2%E0%A7%80%E0%A6%AA%E0%A7%8D%E0%A6%B0%E0%A6%B8%E0%A6%A8%E0%A7%8D%E0%A6%A8%20%E0%A6%B8%E0%A6%BF%E0%A6%82%E0%A6%B9': [43,\n",
              "              44],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%A7%E0%A7%81%E0%A6%AA%E0%A6%BF': [45],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%B9%E0%A7%81%E0%A6%97%E0%A6%B2%E0%A7%80%20%E0%A6%9C%E0%A7%87%E0%A6%B2%E0%A6%BE': [46],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%A4%E0%A7%81%E0%A6%B0%E0%A6%B8%E0%A7%8D%E0%A6%95': [47],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%86%E0%A6%A8%E0%A6%BE%E0%A6%B8%20%E0%A6%87%E0%A6%AC%E0%A6%A8%E0%A7%87%20%E0%A6%AE%E0%A6%BE%E0%A6%B2%E0%A6%BF%E0%A6%95': [48],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%A8%E0%A6%B0%E0%A7%8D%E0%A6%B8%20%E0%A6%AA%E0%A7%81%E0%A6%B0%E0%A6%BE%E0%A6%A3': [49],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%9C%E0%A6%A8%20%E0%A6%AD%E0%A6%A8%20%E0%A6%A8%E0%A6%BF%E0%A6%89%E0%A6%AE%E0%A7%8D%E0%A6%AF%E0%A6%BE%E0%A6%A8': [50],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%95%E0%A6%AE%E0%A7%8D%E0%A6%AC%E0%A7%8B%E0%A6%A1%E0%A7%80%E0%A6%AF%E0%A6%BC%20%E0%A6%9C%E0%A6%A8%E0%A6%A4%E0%A6%BE%20%E0%A6%AA%E0%A6%BE%E0%A6%B0%E0%A7%8D%E0%A6%9F%E0%A6%BF': [51],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AC%E0%A6%BE%E0%A6%82%E0%A6%B2%E0%A6%BE%E0%A6%A6%E0%A7%87%E0%A6%B6%E0%A7%87%E0%A6%B0%20%E0%A6%87%E0%A6%A4%E0%A6%BF%E0%A6%B9%E0%A6%BE%E0%A6%B8': [54],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%95%E0%A6%B0%E0%A7%8D%E0%A6%A3%20%28%E0%A6%AE%E0%A6%B9%E0%A6%BE%E0%A6%AD%E0%A6%BE%E0%A6%B0%E0%A6%A4%29': [55],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%97%E0%A6%A3%E0%A7%87%E0%A6%B6': [56,\n",
              "              57,\n",
              "              58,\n",
              "              59,\n",
              "              85,\n",
              "              86,\n",
              "              87,\n",
              "              88,\n",
              "              89,\n",
              "              90],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AD%E0%A7%8D%E0%A6%B2%E0%A6%BE%E0%A6%A6%E0%A6%BF%E0%A6%AE%E0%A6%BF%E0%A6%B0%20%E0%A6%B2%E0%A7%87%E0%A6%A8%E0%A6%BF%E0%A6%A8': [60],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AD%E0%A6%BE%E0%A6%B0%E0%A6%A4%E0%A7%87%E0%A6%B0%20%E0%A6%B0%E0%A6%BE%E0%A6%B7%E0%A7%8D%E0%A6%9F%E0%A7%8D%E0%A6%B0%E0%A6%AA%E0%A6%A4%E0%A6%BF': [62,\n",
              "              63],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AC%E0%A7%8D%E0%A6%B0%E0%A6%B9%E0%A7%8D%E0%A6%AE%E0%A6%AA%E0%A7%81%E0%A6%A4%E0%A7%8D%E0%A6%B0%20%E0%A6%A8%E0%A6%A6': [64,\n",
              "              84],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AA%E0%A7%8D%E0%A6%AF%E0%A6%BE%E0%A6%B0%E0%A6%BF%E0%A6%B8%20%E0%A6%B6%E0%A6%BE%E0%A6%A8%E0%A7%8D%E0%A6%A4%E0%A6%BF%20%E0%A6%B8%E0%A6%AE%E0%A7%8D%E0%A6%AE%E0%A7%87%E0%A6%B2%E0%A6%A8%2C%20%E0%A7%A7%E0%A7%AF%E0%A7%A7%E0%A7%AF': [67],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%B0%E0%A6%BE%E0%A6%9C%E0%A7%8D%E0%A6%9C%E0%A6%BE%E0%A6%95': [68,\n",
              "              69],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%86%E0%A6%B2%E0%A7%80%E0%A6%AC%E0%A6%B0%E0%A7%8D%E0%A6%A6%E0%A7%80%20%E0%A6%96%E0%A6%BE%E0%A6%A8': [70],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AC%E0%A6%BE%E0%A6%82%E0%A6%B2%E0%A6%BE%E0%A6%A6%E0%A7%87%E0%A6%B6%20%E0%A6%B8%E0%A7%81%E0%A6%AA%E0%A7%8D%E0%A6%B0%E0%A7%80%E0%A6%AE%20%E0%A6%95%E0%A7%8B%E0%A6%B0%E0%A7%8D%E0%A6%9F': [71],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%B0%E0%A6%BE%E0%A6%B7%E0%A7%8D%E0%A6%9F%E0%A7%8D%E0%A6%B0%E0%A6%95%E0%A7%82%E0%A6%9F%20%E0%A6%B0%E0%A6%BE%E0%A6%9C%E0%A6%AC%E0%A6%82%E0%A6%B6': [72,\n",
              "              73],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%95%E0%A6%BE%E0%A6%A4%E0%A6%BE%E0%A6%B2%E0%A7%8B%E0%A6%A8%E0%A6%BF%E0%A6%AF%E0%A6%BC%E0%A6%BE': [74],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%93%E0%A6%AC%E0%A6%BE%E0%A6%87%E0%A6%A6%E0%A7%81%E0%A6%B2%E0%A7%8D%E0%A6%B2%E0%A6%BE%E0%A6%B9': [76],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%B0%E0%A6%BE%E0%A6%97%E0%A6%AC%E0%A6%BF': [77],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%95%E0%A7%81%E0%A6%A6%E0%A6%BE%E0%A6%A8%E0%A6%95%E0%A7%81%E0%A6%B2%E0%A6%BE%E0%A6%AE%20%E0%A6%AA%E0%A6%BE%E0%A6%B0%E0%A6%AE%E0%A6%BE%E0%A6%A3%E0%A6%AC%E0%A6%BF%E0%A6%95%20%E0%A6%AC%E0%A6%BF%E0%A6%A6%E0%A7%8D%E0%A6%AF%E0%A7%81%E0%A7%8E%20%E0%A6%95%E0%A7%87%E0%A6%A8%E0%A7%8D%E0%A6%A6%E0%A7%8D%E0%A6%B0': [78],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AA%E0%A6%B6%E0%A7%8D%E0%A6%9A%E0%A6%BF%E0%A6%AE%E0%A6%AC%E0%A6%99%E0%A7%8D%E0%A6%97%E0%A7%87%E0%A6%B0%20%E0%A6%9C%E0%A7%87%E0%A6%B2%E0%A6%BE': [79],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%9C%E0%A6%BE%E0%A6%B8%E0%A7%8D%E0%A6%9F%E0%A6%BF%E0%A6%A8%20%E0%A6%AC%E0%A6%BF%E0%A6%AC%E0%A6%BE%E0%A6%B0': [80],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AA%E0%A7%8D%E0%A6%B2%E0%A7%87%E0%A6%9F%E0%A7%8B': [81],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AC%E0%A6%BE%E0%A6%82%E0%A6%B2%E0%A6%BE%E0%A6%B0%20%E0%A6%87%E0%A6%A4%E0%A6%BF%E0%A6%B9%E0%A6%BE%E0%A6%B8': [82],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%95%E0%A6%BE%E0%A6%AE%E0%A6%B0%E0%A7%82%E0%A6%AA%20%E0%A6%B0%E0%A6%BE%E0%A6%9C%E0%A7%8D%E0%A6%AF': [83],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AC%E0%A6%BE%E0%A6%B8%E0%A7%8D%E0%A6%A4%E0%A7%81%E0%A6%A4%E0%A6%A8%E0%A7%8D%E0%A6%A4%E0%A7%8D%E0%A6%B0': [92],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%87%E0%A6%B8%E0%A6%B2%E0%A6%BE%E0%A6%AE%E0%A6%BF%20%E0%A6%A6%E0%A6%B0%E0%A7%8D%E0%A6%B6%E0%A6%A8': [93,\n",
              "              94],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AC%E0%A6%BE%E0%A6%82%E0%A6%B2%E0%A6%BE%E0%A6%A6%E0%A7%87%E0%A6%B6-%E0%A6%AD%E0%A6%BE%E0%A6%B0%E0%A6%A4%20%E0%A6%AE%E0%A7%88%E0%A6%A4%E0%A7%8D%E0%A6%B0%E0%A7%80%20%E0%A6%9A%E0%A7%81%E0%A6%95%E0%A7%8D%E0%A6%A4%E0%A6%BF%20%E0%A7%A7%E0%A7%AF%E0%A7%AD%E0%A7%A8': [99],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%86%E0%A6%B8%E0%A6%AB%E0%A6%BE%E0%A6%95%E0%A6%89%E0%A6%B2%E0%A7%8D%E0%A6%B2%E0%A6%BE%20%E0%A6%96%E0%A6%BE%E0%A6%A8': [100],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AA%E0%A7%8D%E0%A6%B0%E0%A6%A3%E0%A6%AC%20%E0%A6%AE%E0%A7%81%E0%A6%96%E0%A7%8B%E0%A6%AA%E0%A6%BE%E0%A6%A7%E0%A7%8D%E0%A6%AF%E0%A6%BE%E0%A6%AF%E0%A6%BC': [101],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AE%E0%A6%BE%E0%A6%A6%E0%A7%8D%E0%A6%B0%E0%A6%BE%E0%A6%B8%E0%A6%BE': [102],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%85%E0%A6%95%E0%A7%8D%E0%A6%B7%E0%A6%B0%E0%A6%A7%E0%A6%BE%E0%A6%AE%20%28%E0%A6%A6%E0%A6%BF%E0%A6%B2%E0%A7%8D%E0%A6%B2%E0%A6%BF%29': [103,\n",
              "              104],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%A4%E0%A6%BE%E0%A6%AE%E0%A6%BE%E0%A6%95': [105],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%85%E0%A6%B0%E0%A7%8D%E0%A6%9C%E0%A7%81%E0%A6%A8': [106],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AE%E0%A6%A7%E0%A7%81%E0%A6%AA%E0%A7%81%E0%A6%B0%20%E0%A6%89%E0%A6%AA%E0%A6%9C%E0%A7%87%E0%A6%B2%E0%A6%BE': [107],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%85%E0%A7%8D%E0%A6%AF%E0%A6%BE%E0%A6%A8%E0%A7%8D%E0%A6%9F%E0%A6%BF%E0%A6%AC%E0%A6%BE%E0%A6%AF%E0%A6%BC%E0%A7%8B%E0%A6%9F%E0%A6%BF%E0%A6%95': [109],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%B0%E0%A6%BE%E0%A6%A7%E0%A6%BE%E0%A6%97%E0%A7%8B%E0%A6%AC%E0%A6%BF%E0%A6%A8%E0%A7%8D%E0%A6%A6%20%E0%A6%9A%E0%A6%A8%E0%A7%8D%E0%A6%A6%E0%A7%8D%E0%A6%B0': [113],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AE%E0%A6%BE%E0%A6%95%E0%A7%8D%E0%A6%B8%20%E0%A6%AE%E0%A7%81%E0%A6%B2%E0%A6%BE%E0%A6%B0': [114],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%97%E0%A6%A3%E0%A6%9A%E0%A7%80%E0%A6%A8': [115],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AE%E0%A6%BE%E0%A6%B2%E0%A6%AF%E0%A6%BC%E0%A7%87%E0%A6%B6%E0%A6%BF%E0%A6%AF%E0%A6%BC%E0%A6%BE%20%E0%A6%8F%E0%A6%AF%E0%A6%BC%E0%A6%BE%E0%A6%B0%E0%A6%B2%E0%A6%BE%E0%A6%87%E0%A6%A8%E0%A7%8D%E0%A6%B8%20%E0%A6%AB%E0%A7%8D%E0%A6%B2%E0%A6%BE%E0%A6%87%E0%A6%9F%20%E0%A7%A9%E0%A7%AD%E0%A7%A6': [116],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%B2%E0%A6%BE%E0%A6%B2%20%E0%A6%AE%E0%A7%8D%E0%A6%AF%E0%A6%BE%E0%A6%AA%E0%A7%87%E0%A6%B2': [117,\n",
              "              118,\n",
              "              119],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%A6%E0%A7%8D%E0%A6%AF%20%E0%A6%AE%E0%A6%BE%E0%A6%B0%E0%A6%AE%E0%A7%87%E0%A6%87%E0%A6%A1%20%28%E0%A7%A7%E0%A7%AF%E0%A7%A7%E0%A7%A6-%E0%A6%8F%E0%A6%B0%20%E0%A6%9A%E0%A6%B2%E0%A6%9A%E0%A7%8D%E0%A6%9A%E0%A6%BF%E0%A6%A4%E0%A7%8D%E0%A6%B0%29': [121,\n",
              "              122],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AC%E0%A6%BF%E0%A6%B6%E0%A7%8D%E0%A6%AC%E0%A6%AD%E0%A6%BE%E0%A6%B0%E0%A6%A4%E0%A7%80%20%E0%A6%AC%E0%A6%BF%E0%A6%B6%E0%A7%8D%E0%A6%AC%E0%A6%AC%E0%A6%BF%E0%A6%A6%E0%A7%8D%E0%A6%AF%E0%A6%BE%E0%A6%B2%E0%A6%AF%E0%A6%BC': [123],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AC%E0%A6%BF%E0%A6%B6%E0%A7%8D%E0%A6%AC%E0%A7%87%E0%A6%B0%20%E0%A6%87%E0%A6%A4%E0%A6%BF%E0%A6%B9%E0%A6%BE%E0%A6%B8': [125,\n",
              "              126],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%AB%E0%A6%BE%E0%A6%B0%E0%A7%8D%E0%A6%B8%E0%A6%BF%20%E0%A6%AD%E0%A6%BE%E0%A6%B7%E0%A6%BE': [127],\n",
              "             'https://bn.wikipedia.org/wiki/%E0%A6%A4%E0%A6%BF%E0%A6%A4%E0%A6%BE%E0%A6%B8%20%E0%A6%8F%E0%A6%95%E0%A6%9F%E0%A6%BF%20%E0%A6%A8%E0%A6%A6%E0%A7%80%E0%A6%B0%20%E0%A6%A8%E0%A6%BE%E0%A6%AE': [129]})"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "n_best = 20\n",
        "max_answer_length = 30\n",
        "predicted_answers = []\n",
        "\n",
        "for example in small_eval_set:\n",
        "    example_id = example[\"document_url\"]\n",
        "    context = example[\"document_plaintext\"]\n",
        "    answers = []\n",
        "\n",
        "    for feature_index in example_to_features[example_id]:\n",
        "        start_logit = start_logits[feature_index]\n",
        "        end_logit = end_logits[feature_index]\n",
        "        offsets = eval_set[\"offset_mapping\"][feature_index]\n",
        "\n",
        "        start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
        "        end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
        "        for start_index in start_indexes:\n",
        "            for end_index in end_indexes:\n",
        "                # Skip answers that are not fully in the context\n",
        "                if offsets[start_index] is None or offsets[end_index] is None:\n",
        "                    continue\n",
        "                # Skip answers with a length that is either < 0 or > max_answer_length.\n",
        "                if (\n",
        "                    end_index < start_index\n",
        "                    or end_index - start_index + 1 > max_answer_length\n",
        "                ):\n",
        "                    continue\n",
        "\n",
        "                answers.append(\n",
        "                    {\n",
        "                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n",
        "                        \"indexes\": (offsets[start_index][0], offsets[end_index][1]),\n",
        "                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n",
        "                    }\n",
        "                )\n",
        "\n",
        "    best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
        "    predicted_answers.append({\"id\": example_id, \"prediction_text\": best_answer[\"text\"], \"indexes\": best_answer[\"indexes\"]})"
      ],
      "metadata": {
        "id": "eblwmGA31xyr"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theoretical_answers = [\n",
        "    {\"id\": ex[\"document_url\"], \"answers\": ex[\"annotations\"][\"answer_text\"][0], \"indexes\": ex[\"annotations\"]} for ex in small_eval_set\n",
        "]"
      ],
      "metadata": {
        "id": "WWYSnxz22Fmc"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predicted_answers[1])\n",
        "print(theoretical_answers[1])"
      ],
      "metadata": {
        "id": "nHJbr7rZ2fPp",
        "outputId": "d2609125-1875-418a-cbb0-9523ae37b37e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'document_url': 'https://bn.wikipedia.org/wiki/%E0%A6%AE%E0%A6%B9%E0%A6%BE%E0%A6%B6%E0%A7%8D%E0%A6%AC%E0%A7%87%E0%A6%A4%E0%A6%BE%20%E0%A6%A6%E0%A7%87%E0%A6%AC%E0%A7%80', 'prediction_text': 'ঝাঁসির রানি', 'indexes': (209, 220)}\n",
            "{'document_url': 'https://bn.wikipedia.org/wiki/%E0%A6%AE%E0%A6%B9%E0%A6%BE%E0%A6%B6%E0%A7%8D%E0%A6%AC%E0%A7%87%E0%A6%A4%E0%A6%BE%20%E0%A6%A6%E0%A7%87%E0%A6%AC%E0%A7%80', 'answers': 'ঝাঁসির রানি', 'indexes': {'answer_start': [209], 'answer_text': ['ঝাঁসির রানি']}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def calculate_f1_score(predictions, references):\n",
        "    # Extract the 'answer' values from the dictionaries\n",
        "    predicted_answers = [item['prediction_text'] for item in predictions]\n",
        "    reference_answers = [item['answers'] for item in references]\n",
        "    # print(predicted_answers)\n",
        "    # print(reference_answers)\n",
        "    # Calculate the F1 score\n",
        "    f1 = f1_score(reference_answers, predicted_answers, average='micro')\n",
        "\n",
        "    return f1"
      ],
      "metadata": {
        "id": "Ma02KlS_3mEp"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score = calculate_f1_score(predicted_answers, theoretical_answers)\n",
        "print(f\"F1 Score: {f1_score}\")"
      ],
      "metadata": {
        "id": "ZM0PWuhT3t-P",
        "outputId": "805e7d11-a8fb-46e4-a82e-38b274db20a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_exact_match(predictions, references):\n",
        "    exact_match_count = 0\n",
        "\n",
        "    for pred, ref in zip(predictions, references):\n",
        "      #print(\"\")\n",
        "      #print(pred['prediction_text'])\n",
        "      #print(ref['answers'])\n",
        "      if pred['prediction_text'] == ref['answers']:\n",
        "            exact_match_count += 1\n",
        "\n",
        "    exact_match_score = exact_match_count / len(predictions)\n",
        "\n",
        "    return exact_match_score"
      ],
      "metadata": {
        "id": "y7b-5Ftt4Ajd"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exact_match_score = calculate_exact_match(predicted_answers, theoretical_answers)\n",
        "print(f\"Exact Match Score: {exact_match_score}\")"
      ],
      "metadata": {
        "id": "n-UnR-o24BeB",
        "outputId": "ae7e4148-35c3-4ebd-f1de-ad52cb563ffc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exact Match Score: 0.39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Old:"
      ],
      "metadata": {
        "id": "i1xw7CJczlTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    questions = [q.strip() for q in examples[\"question_text\"]]\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples[\"document_plaintext\"],\n",
        "        max_length=384,\n",
        "        truncation=\"only_second\",\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "    answers = examples[\"annotations\"]\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offset in enumerate(offset_mapping):\n",
        "        answer = answers[i]\n",
        "        start_char = answer[\"answer_start\"][0]\n",
        "        end_char = answer[\"answer_start\"][0] + len(answer[\"answer_text\"][0])\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "        # Find the start and end of the context\n",
        "        idx = 0\n",
        "        while sequence_ids[idx] != 1:\n",
        "            idx += 1\n",
        "        context_start = idx\n",
        "        while sequence_ids[idx] == 1:\n",
        "            idx += 1\n",
        "        context_end = idx - 1\n",
        "\n",
        "        # If the answer is not fully inside the context, label it (0, 0)\n",
        "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            # Otherwise it's the start and end token positions\n",
        "            idx = context_start\n",
        "            while idx <= context_end and offset[idx][0] <= start_char:\n",
        "                idx += 1\n",
        "            start_positions.append(idx - 1)\n",
        "\n",
        "            idx = context_end\n",
        "            while idx >= context_start and offset[idx][1] >= end_char:\n",
        "                idx -= 1\n",
        "            end_positions.append(idx + 1)\n",
        "\n",
        "    inputs[\"start_positions\"] = start_positions\n",
        "    inputs[\"end_positions\"] = end_positions\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "64y2OEb4Xz1f"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_data = filtered_dataset.map(preprocess_function, batched=True, remove_columns=filtered_dataset[\"train\"].column_names)"
      ],
      "metadata": {
        "id": "KtuiQeNTPTkZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DefaultDataCollator\n",
        "\n",
        "data_collator = DefaultDataCollator()"
      ],
      "metadata": {
        "id": "NdFegLR6j7ps"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"bert-base-multilingual-uncased\")"
      ],
      "metadata": {
        "id": "3QhlYheFkDSq",
        "outputId": "5bafddec-f820-4006-ed6e-9161110f19e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\".\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_data[\"train\"],\n",
        "    eval_dataset=tokenized_data[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "m_lbm80MkOy6",
        "outputId": "646d0ee2-c235-4cca-b6e0-4c3853ef0418",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='299' max='299' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [299/299 06:07, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.016305</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=299, training_loss=1.4772137798194502, metrics={'train_runtime': 368.9804, 'train_samples_per_second': 12.952, 'train_steps_per_second': 0.81, 'total_flos': 936552900331008.0, 'train_loss': 1.4772137798194502, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results = trainer.evaluate(tokenized_data[\"validation\"])\n",
        "\n",
        "# Print the evaluation results\n",
        "print(evaluation_results)"
      ],
      "metadata": {
        "id": "sMIArCiZCVu7",
        "outputId": "3bcf2eea-779c-44f6-f944-e7796701a0e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='34' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [17/17 02:31]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-147-758bbd84cc6c>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Print the evaluation results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"predictions\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: 'predictions'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k6bMe9EHDAjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForQuestionAnswering\n",
        "\n",
        "eval_set = filtered_dataset[\"validation\"]\n",
        "eval_set_for_model = tokenized_data[\"validation\"]\n",
        "eval_set_for_model.set_format(\"torch\")\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "batch = {k: eval_set_for_model[k].to(device) for k in eval_set_for_model.column_names}\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**batch)"
      ],
      "metadata": {
        "id": "F5kd1pRkrmJK"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_logits = outputs.start_logits.cpu().numpy()\n",
        "end_logits = outputs.end_logits.cpu().numpy()"
      ],
      "metadata": {
        "id": "Cz6bfe5tuME4"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "example_to_features = collections.defaultdict(list)\n",
        "for idx, feature in enumerate(eval_set):\n",
        "    example_to_features[feature[\"document_url\"]].append(idx) # document url is like an id for the entry"
      ],
      "metadata": {
        "id": "5XMc4_yox9-H"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "n_best = 20\n",
        "max_answer_length = 30 # TODO: tjek hvad max længden er\n",
        "predicted_answers = []\n",
        "\n",
        "for example in eval_set:\n",
        "    example_id = example[\"document_url\"]\n",
        "    context = example[\"document_plaintext\"]\n",
        "    answers = []\n",
        "\n",
        "    for feature_index in example_to_features[example_id]:\n",
        "        start_logit = start_logits[feature_index]\n",
        "        end_logit = end_logits[feature_index]\n",
        "        offsets = eval_set[\"offset_mapping\"][feature_index]\n",
        "\n",
        "        start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
        "        end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
        "        for start_index in start_indexes:\n",
        "            for end_index in end_indexes:\n",
        "                # Skip answers that are not fully in the context\n",
        "                if offsets[start_index] is None or offsets[end_index] is None:\n",
        "                    continue\n",
        "                # Skip answers with a length that is either < 0 or > max_answer_length.\n",
        "                if (\n",
        "                    end_index < start_index\n",
        "                    or end_index - start_index + 1 > max_answer_length\n",
        "                ):\n",
        "                    continue\n",
        "\n",
        "                answers.append(\n",
        "                    {\n",
        "                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n",
        "                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n",
        "                    }\n",
        "                )\n",
        "\n",
        "    best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
        "    predicted_answers.append({\"id\": example_id, \"prediction_text\": best_answer[\"text\"]})"
      ],
      "metadata": {
        "id": "qD87LARqyRa5",
        "outputId": "c5c10ada-278d-4cc9-cd93-4961a4d9496e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-91caf16da99f>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mstart_logit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_logits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mend_logit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_logits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moffsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"offset_mapping\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mstart_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_logit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mn_best\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2801\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: F811\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m         \u001b[0;34m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2803\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2805\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2785\u001b[0m         \u001b[0mformat_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_kwargs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mformat_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2786\u001b[0m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mformat_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2787\u001b[0;31m         \u001b[0mpa_subtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2788\u001b[0m         formatted_output = format_table(\n\u001b[1;32m   2789\u001b[0m             \u001b[0mpa_subtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_all_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_all_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mquery_table\u001b[0;34m(table, key, indices)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0m_raise_bad_key_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0m_check_valid_column_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_rows\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36m_check_valid_column_key\u001b[0;34m(key, columns)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_valid_column_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Column {key} not in the dataset. Current columns in the dataset: {columns}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"Column offset_mapping not in the dataset. Current columns in the dataset: ['question_text', 'document_title', 'language', 'annotations', 'document_plaintext', 'document_url']\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensorflow:"
      ],
      "metadata": {
        "id": "tzqpZxKyj_Iw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DefaultDataCollator\n",
        "\n",
        "data_collator = DefaultDataCollator(return_tensors=\"tf\")"
      ],
      "metadata": {
        "id": "IXvJi2TybLjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import create_optimizer\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "num_epochs = 2\n",
        "\n",
        "total_train_steps = (len(tokenized_data[\"train\"]) // batch_size) * num_epochs\n",
        "\n",
        "optimizer, schedule = create_optimizer(\n",
        "\n",
        "    init_lr=2e-5,\n",
        "\n",
        "    num_warmup_steps=0,\n",
        "\n",
        "    num_train_steps=total_train_steps,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "zmVnbky0bNkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoConfig, TFAutoModelForQuestionAnswering\n",
        "\n",
        "config = AutoConfig.from_pretrained(\"bert-base-multilingual-uncased\")\n",
        "model = TFAutoModelForQuestionAnswering.from_config(config)"
      ],
      "metadata": {
        "id": "MTbUJ8GtbuhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_train_set = model.prepare_tf_dataset(\n",
        "    tokenized_data[\"train\"],\n",
        "    shuffle=True,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "\n",
        "tf_validation_set = model.prepare_tf_dataset(\n",
        "    tokenized_data[\"validation\"],\n",
        "    shuffle=False,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")"
      ],
      "metadata": {
        "id": "MKCthYrucIDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model.compile(optimizer=optimizer)"
      ],
      "metadata": {
        "id": "oCta0LEVcVrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=1) # TODO: change number of epochs"
      ],
      "metadata": {
        "id": "AbCwtsxBcW_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_dataset[\"validation\"][0]"
      ],
      "metadata": {
        "id": "ADZEnmun_fhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_validation = tokenizer(filtered_dataset[\"validation\"][\"question_text\"],\n",
        "                              filtered_dataset[\"validation\"][\"document_plaintext\"],\n",
        "                              max_length=384,\n",
        "                              truncation=\"only_second\",\n",
        "                              padding=\"max_length\",\n",
        "                              return_tensors=\"tf\")"
      ],
      "metadata": {
        "id": "-kjtwJYp_b2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**inputs_validation)\n",
        "start_scores = outputs.start_logits\n",
        "end_scores = outputs.end_logits\n",
        "print(start_scores)\n",
        "print(end_scores)"
      ],
      "metadata": {
        "id": "z0ZBmiyR7u2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_answers = []\n",
        "predicted_answer_indexes = []\n",
        "\n",
        "for context, question in zip(validation_data[\"document_plaintext\"], validation_data[\"question_text\"]):\n",
        "    inputs = tokenizer(question, context, return_tensors=\"tf\", padding=True, truncation=True)\n",
        "    # Model expects input_ids and attention_mask\n",
        "    input_ids = inputs[\"input_ids\"]\n",
        "    attention_mask = inputs[\"attention_mask\"]\n",
        "\n",
        "    # Make predictions\n",
        "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    start_scores = outputs.start_logits\n",
        "    end_scores = outputs.end_logits\n",
        "\n",
        "    start_index = tf.argmax(start_scores, axis=1).numpy()[0]\n",
        "    end_index = tf.argmax(end_scores, axis=1).numpy()[0]\n",
        "    #predicted_answer = tokenizer.decode(input_ids[0][start_index:end_index + 1])\n",
        "    #predicted_answers.append(predicted_answer)"
      ],
      "metadata": {
        "id": "E11own-bsYgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids"
      ],
      "metadata": {
        "id": "8HNH85txuS6g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}